<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[算法岗面试常见问题大集合]]></title>
    <url>%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E7%AE%97%E6%B3%95%E5%B2%97%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%A4%A7%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[1.参考博客 算法岗面试常见问题大集合 算法工程师手册 2.模型过拟合的解决方法 L1/L2正则化（原理奥卡姆剃刀）:L2正则化也叫作权重衰减，目标函数中增加所有权重w参数的平方之和，迫使所有w可能趋向0但不为0；L1正则化在损失函数中加入所有权重参数w的绝对值之和，迫使更多的w为0，使特征变得稀疏。 Batch Normalization（对神经网络中下一层的输入进行归一化处理，使得输入量的均值为0，方差为1，即通过特征归一化，加速模型的训练） shortcut-connect(使用残差网络Residual network) 数据增强(增加样本的数量) early stopping Dropout：在训练过程中，让神经元以超参数p的概率被激活(也就是说1-p的概率被设置为0)，类似于bagging算法 3.如何解决样本类别的不均衡问题？ a.过采样/上采样：增加类别少的样本数量实现样本数量的均衡。具体是通过复制类别上的样本构成多条数据。此方法的缺点是当样本的特征很少时，容易出现过拟合。需要对过采样方法进行改进，改进的方法是：在类别少的样本中加入噪声、干扰数据或通过一定的规则产生新合成的样本，如smote算法。 b.欠采样/下采样：减少类别多的样本数量，一般的方法是随机地去掉一些类别多的样本。 c.调整正负样本的惩罚权重：对类别少的样本赋予高的权重，对类别多的样本赋予低的权重。 d.通过集成学习的方法：每次生成训练集时，使用所有类别少的样本，同时从类别多的样本中随机抽取数据与类别少的样本合并起来，构成一个新的训练集。 e.使用特征选择：一般样本不均衡也会导致特征不均衡。但如果类别少的样本量具有一定的规模时，则意味着其特征的分布较为均匀，可以选择出具有显著特征配合参与解决样本不均衡的问题。 4.在神经网络训练过程中，为什么会出现梯度消失的问题？如何防止？ 原因：使用了不合适的激活函数，例如sigmoid函数。此时，当神经网络的层数很深时，利用链式求导法则计算梯度时，损失函数的梯度连乘，导致乘积会变得越来越小接近于0，从而神经网络无法学习到新的信息。 解决方法： 预训练加微调 梯度剪切 权重正则化 使用不同的激活函数 使用Batch Normalization 使用残差网络ResNet 使用LSTM网络 5.介绍一下TensorFlow中的计算图 TensorFlow是一个通过计算图的形式来表述计算的编程系统，计算图也叫作数据流图。可以把计算图看做是一种有向图，TensorFlow中的每个节点都是计算图上的一个张量Tensor，而节点之间的边描述了计算之间的依赖关系和数学运算。 6.K-Means或KNN中，通常使用欧式距离来表示最近的数据点之间的距离，有时候也使用曼哈度距离，对比两者的区别。 欧式距离最常见的是两个或多个点之间的距离表示法，又称为欧几里得距离。也就是通常所说的L2范数，公式如下。欧式距离的缺点是它将样本的不同属性之间的差别等同看待，这一点有时候不能满足实际要求。 d(x, y) :=\sqrt{\left(x_{1}-y_{1}\right)^{2}+\left(x_{2}-y_{2}\right)^{2}+\cdots+\left(x_{n}-y_{n}\right)^{2}}=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}} 曼哈顿距离，也就是欧式空间中的在直角坐标系上两个点所形成的线段对轴产生的投影的距离总和。也就是我们所说的L1距离。例如，坐标(x1,y1)的点P1与坐标(x2, y2)的点P2的曼哈顿距离计算公式为： \left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right| 7.参数模型与非参数模型 参数模型：根据预先设计的规则，例如方差损失最小，进行学习，参数模型例子：回归（线性回归、逻辑回归）模型；最好可以看一下或者直接进行一下相关的推导；根据规则，拥有少部分数据就可以； 非参数模型：不需要事先假设规则，直接挖掘潜在数据中的规则；非参数模型例子：KNN，决策树，挖掘数据潜在的特征，所以比较灵活； 8.生成模型与判别模型 生成模型：根据数据学习联合概率分布P(x,y)，从而计算出条件概率分布P(y|x)作为预测的模型。常用于含有隐变量的模型，例如HMM，朴素贝叶斯算法、高斯混合模型GMM、文档主题生成模型LDA、限制玻尔兹曼机等 判别模型：根据数据直接学习条件概率分布P(x|y)或者决策函数Y=f(X)作为预测模型。例如：逻辑回归、RF、SVM、神经网络、感知机、KNN、CRF等 两者的对比： 使用生成式方法得到的模型，可以还原出模型的联合概率分布，而判别模型不可以； 生成式方法得到的模型收敛速度更快。当样本数增加时，生成式方法得到的模型能更快的收敛到真实模型； 存在隐变量时，只能使用生成模型； 使用判别式方法学习得到的模型，直接面对预测，学习的准确率通常更高，可以简化学习问题。 9.LR和SVM的联系和区别？ 联系： LR和SVM都可以处理分类问题，且一般都用于处理线性二分类问题 两个方法都可以增加不同的正则化项，如L1、L2正则化项 区别： LR是参数模型，SVM是非参数模型 从损失函数来看，LR使用的是交叉熵损失函数，SVM使用的hinge损失函数，这两个损失函数的目的都是增加对分类影响较大的样本点的权重，减小与分类关系比较小的数据点的权重。 SVM的处理方法只考虑支持向量，也就是只考虑和分类最相关的少数样本点来学习分类器。而逻辑回归通过非线性映射，大大减小了离分离超平面远的样本点权重，相对提升了与分类最相关的样本点的权重。 LR模型相对来说简单好理解，一般用于大规模的线性分类。SVM的理解和优化比较复杂，在处理复制非线性分类时，使用核技巧来计算优势明显。 LR能做的SVM也能做，但可能准确率是上有问题，但SVM能做的LR做不了。 10.神经网络中参数量parameters和FLOPs计算 CNN中的parameters分为两种：W和b，对于某一个卷积层，它的parameters的个数为: \left(K_{h} * K_{w} * C_{i n}\right) * C_{o u t}+C_{o u t}其中，$K{h}$是卷积核的高度，$K{w}$是卷积核的宽度,$C{in}$是输入的通道数，$C{out}$是输出的通道数 对于某个全连接层，如果输入的数据有$N{in}$个节点，输出的数据有$N{out}$个节点，它的参数个数为： N_{i n} * N_{o u t}+N_{o u t} FLOPs：全称是floating point operations per second，指的是每秒浮点运算次数，即用来衡量硬件的计算性能 对于某个卷积层,它的FLOPs数量是： \left[\left(K_{h} * K_{w} * C_{i n}\right) * C_{o u t}+C_{o u t}\right] *(H * W)=n u m_{-} \text { params } *(H * W)其中，$num_{params}$表示该层参数的数量，H是输出图片的高，W是输出图片的宽 例题1：假设你的输入是一个300×300的彩色（RGB）图像，而你没有使用卷积神经网络。 如果第一个隐藏层有100个神经元，每个神经元与输入层进行全连接，那么这个隐藏层有多少个参数（包括偏置参数）？ A1：因为输入的节点数量是300*300*3,输出的节点数量是100。然后加上偏置项b，因为隐藏层有100个节点，每个节点都有一个偏置，所以b=100。利用上面计算全连接网络的公式，故3*300*300*100+100 例题2：假设你的输入是300×300彩色（RGB）图像，并且你使用卷积层和100个过滤器，每个过滤器都是5×5的大小，请问这个隐藏层有多少个参数（包括偏置参数）？ A2：首先，参数和输入的图片大小是没有关系的，无论你给的图像像素有多大，参数值都是不变的，在这个题中，参数值只与过滤器有关。单个过滤器的大小是5*5,由于输入的是RGB图像，所以输入通道数目是3。因此一个过滤器的组成是5*5*3,每一过滤器只有一个偏置项b,因此一个过滤器所拥有的参数是5*5*3+1=76，一共用了100个过滤器，所以隐藏层含有76*100=7600个参数。其实，也就是上面的公式计算CNN的参数量。 11.SVM中常见的几种核函数 线性核函数：内积公式 \kappa\left(x_{1}, x_{2}\right)=\left\langle x_{1}, x_{2}\right\rangle 多项式核函数 K(x, z)=(x \cdot z+1)^{p} 高斯核函数 K(x, z)=\exp \left(-\frac{\|x-z\|^{2}}{2 \sigma^{2}}\right) 字符串核函数：详见李航统计学习方法 12.逻辑回归与线性回归的联系与区别 联系：逻辑回归和线性回归首先都是广义的线性回归；逻辑回归的模型本质上是一个对数线性回归模型，逻辑回归都是以线性回归为理论支持的。但线性回归模型无法做到sigmoid的非线性形式，sigmoid可以轻松处理0/1分类问题。 区别： 线性模型的优化目标函数是最小二乘，而逻辑回归则是似然函数 线性回归在整个实数域范围内进行预测，敏感度一致；而分类范围，需要在[0,1]。逻辑回归就是一种减小预测范围，将预测值限定为[0,1]间的一种回归模型，因而对于这类问题来说，逻辑回归的鲁棒性比线性回归的要好。 13.XGBoost为什么要用泰勒公式展开，优势在哪? XGBoost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准。使用泰勒展开取得二阶倒数形式, 可以在不选定损失函数具体形式的情况下用于算法优化分析.本质上也就把损失函数的选取和模型算法优化和参数选择分开了，这种去耦合增加了XGBoost的适用性。 14.XGBoost如何寻找最优特征？是有放回还是无放回？ XGBoost在训练过程中给各个特征的增益评分，最大增益的特征会被选出来作为分裂的依据，从而记忆了每个特征对在模型训练时的重要性。XGBoost属于boosting的集成学习方法，样本是无放回的，因此每轮计算样本不重复。XGBoost支持子采样，即每轮计算不使用全部样本，以减少过拟合。 15.决策树、随机森林RF、Boosting、Adaboost、GBDT、XGBoost的区别？ bagging与boosting的区别： bagging方法有放回的采样相同数量样本训练学习器，然后再一起投票。学习器之间不存在强的依赖关系，学习器可以并行训练生成。集成方式一般为投票法。随机森林属于Bagging的代表，放回抽样，每个学习器随机选择部分特征去优化。 Boosting方法使用全部样本，依次训练每个学习器，迭代集成。学习器之间不存在强依赖关系，学习器可并行训练生成，集成方式为加权和；Adaboost属于Boosting，采用指数损失函数代替原本分类任务中的0-1损失函数；GBDT属于Boosting的优秀代表，对函数残差近似值进行梯度下降，用CRAT树作为基本的学习器，集成模型为回归模型。XGBoost属于Boosting的集大成者，对函数残差近似值进行梯度下降，迭代时利用二阶梯度信息，集成模型可用于分类也可以用于回归。 决策树的学习过程：从根开始建立树，也就是如何选择特征进行分裂。ID3算法使用信息增益、C4.5使用信息增益比、CART树采用基尼系数计算最优分类点，XGBoost使用二阶泰勒展开系数计算最优分裂点。 16.GBDT与XGBoost的对比，XGBoost的优点 损失函数用泰勒展开二项逼近，而不是像GBDT中用的就是一阶导数 对树的结构进行了正则化约束，防止模型过于复杂，降低了过拟合的可能性 节点的分裂方式不同，GBDT使用的是基尼系数，XGBoost使用的是经过优化推导后的算法(穷举法选择最佳的分裂节点、通过加权分位数方法近似选择最佳的分裂节点、针对稀疏特征的分裂点选择法) 17.L1和L2范数的区别 L1 norm:向量中各个元素绝对值之和，也称为稀疏规则算子，L1范数可以使权重稀疏，方便特征提取；L1正则化先验服从拉普拉斯分布 L2 norm:向量中各个元素平方和的1/2次方，又称为Frobenius范数，L2范数可以防止过拟合，提升模型的泛化能力；L2正则化先验服从高斯分布 18.阐述Adaboost算法的流程，并写出权重更新的公式 详细原理 19.LSTM的结构推导，为什么比普通的RNN好？ 详细原理 20.为什么朴素贝叶斯算法如此朴素？ 因为它假设所有的特征在数据集中的作用都是同样重要的，而且相互独立的。这个假设在现实中基本上是不存在的，但特征相关性很小的实际情况还很多，岁月这个模型还可以工作的很好。 21.EM算法原理说明 有时候样本的产生和隐含变量有关(隐变量是不能观察的)，而求模型的参数时一般都采用极大似然估计，由于含有隐变量，所以对似然函数的参数求导数是求不出来的，这时候用EM算法来求模型的参数，典型的用法是用在GMM和HMM中。步骤如下： E步：选择一组参数，求出在此参数下隐变量的条件概率值 Q_{i}\left(z^{(i)}\right) :=p\left(z^{(i)} | x^{(i)} ; \theta\right) M步：结合E步求出的隐变量的条件概率值，求出似然函数的下界函数(即某个期望函数)最大值。 \theta :=\arg \max _{\theta} \sum_{i} \sum_{z^{(i)}} Q_{i}\left(z^{(i)}\right) \log \frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_{i}\left(z^{(i)}\right)} 重复进行上面的两步，直至收敛为止。 M步中下界函数的推导过程： \begin{aligned} \sum_{i} \log p\left(x^{(i)} ; \theta\right) &=\sum_{i} \log \sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ; \theta\right) \\ &=\sum_{i} \log \sum_{z^{(i)}} Q_{i}\left(z^{(i)}\right) \frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_{i}\left(z^{(i)}\right)} \\ & \geq \sum_{i} \sum_{z^{(i)}} Q_{i}\left(z^{(i)}\right) \log \frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_{i}\left(z^{(i)}\right)} \end{aligned} 22.GMM算法原理说明 EM算法的常用例子是高斯混合模型GMM，每个样本都有可能由K个高斯模型产生，只不过每个高斯模型的产生概率不同，因此每个样本都有对应的高斯分布(K个模型中的一个)，此时的隐变量就是每个样本对应的某个高斯分布。 GMM算法的E步(计算每个样本对应每个高斯模型的概率) w_{j}^{(i)} :=p\left(z^{(i)}=j | x^{(i)} ; \phi, \mu, \Sigma\right)具体的计算公式为： p\left(z^{(i)}=j | x^{(i)} ; \phi, \mu, \Sigma\right)=\frac{p\left(x^{(i)} | z^{(i)}=j ; \mu, \Sigma\right) p\left(z^{(i)}=j ; \phi\right)}{\sum_{l=1}^{k} p\left(x^{(i)} | z^{(i)}=l ; \mu, \Sigma\right) p\left(z^{(i)}=l ; \phi\right)} M步计算公式(计算每个高斯模型的权重，均值，方差3个参数)： \begin{aligned} \phi_{j} & :=\frac{1}{m} \sum_{i=1}^{m} w_{j}^{(i)} \\ \mu_{j} & :=\frac{\sum_{i=1}^{m} w_{j}^{(i)} x^{(i)}}{\sum_{i=1}^{m} w_{j}^{(i)}} \\ \Sigma_{j} & :=\frac{\sum_{i=1}^{m} w_{j}^{(i)}\left(x^{(i)}-\mu_{j}\right)\left(x^{(i)}-\mu_{j}\right)^{T}}{\sum_{i=1}^{m} w_{j}^{(i)}} \end{aligned} 23.KNN算法中K是如何选择的? 如果选择较小的K值，就相当于用较小的邻域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大。换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合； 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。 K=N，此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。 实际中，使用交叉验证的方法选择最优的K的取值。 24.机器学习中，为什么经常需要对数据进行归一化？ 归一化能提高梯度下降算法求解的速度 归一化有可能提高精度 25.神经网络中的批量归一化Batch Normalization(BN)原理 详细原理 26.哪些机器学习算法不需要进行归一化操作？ 概率模型不需要做归一化操作，因为它们不关心变量的值，而关心的是变量分布和变量之间的条件概率，如决策树。但是，像Adaboost、SVM、LR、KNN、Kmeans等最优化问题就需要归一化。 27.为什么树形结构不需要归一化？ 数值缩放，不影响分裂点位置。因为第一步都是按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会变。对于线性模型，比如说LR，假设有两个特征，一个是(0,1)的，一个是(0,10000)的，这样运用梯度下降时候，损失等高线是一个椭圆的形状，这样想迭代到最优点，就需要很多次迭代，但是如果进行了归一化，那么等高线就是圆形的，那么SGD就会往原点迭代，需要的迭代次数较少。另外，注意树模型是不能进行梯度下降的，因为树模型是阶跃的，阶跃点是不可导的，并且求导没意义，所以树模型（回归树）寻找最优点是通过寻找最优分裂点完成的。 28.一个完整机器学习项目的流程 抽象成数学问题、获取数据、特征预处理与特征选择、训练模型与调优、模型诊断、模型融合、上线运行 29.条件随机场CRF模型相对于HMM模型(隐马尔科夫模型)和MEMM模型(最大熵隐马尔科夫模型)的优势。 HMM模型中一个最大的缺点即其输出独立性假设，由于输出独立性假设的缺点导致HMM模型不能考虑上下文的特征，限制了特征的选择。 MEMM模型则解决了HMM模型的最大的缺点，可以任意选择特征，但是由于其每一个节点都要进行归一化，所以只能找到局部最优值。同时，也带来了标记偏见的问题即凡是在训练语料库中未出现的情况都被忽略掉了。CRF模型很好的解决了这个问题，它并不在每一节点进行归一化，而是所有特征进行全局归一化，因此可以求出全局的最优值。 30.什么是熵？ 熵的定义：离散随机事件的出现概率。一个系统越是有序，信息熵就越低。信息熵可以被认为是系统有序化程度的一个度量。 31.BP反向传播算法推导及python实现 python代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152import numpy as npimport matplotlib.pyplot as pltclass MLP(): def __init__(self, name='nn', layer_structure=[], task_model=None, batch_size=1, load_model=None): """layer_number : 神经网络的层数 layer_structure = [输入的特征个数，第1层神经元个数，第2层神经元个数，...，最后一层神经元个数输出层特征个数]， 如网络层数设为layer_number=3, layer_structure=[20,10,5,1]：输入特征是20个，第一层有10个神经元，第二层5个，第三层1个. output_model = 'regression'/'logistic' """ self.name = name self.layer_number = len(layer_structure) - 1 self.layer_structure = layer_structure self.task_model = task_model self.W = [] self.B = [] self.batch_size = batch_size self.total_loss = [] if self.task_model == 'logistic' or self.task_model == 'multi': self.total_accuracy = [] if load_model == None: print("Initializing the network from scratch ...") for index in range(self.layer_number): self.W.append(np.random.randn(self.layer_structure[index], self.layer_structure[index+1])) self.B.append(np.random.randn(1, self.layer_structure[index+1])) else: print("Initializing the network from trained model ...") for index in range(self.layer_number): self.W.append(np.loadtxt(load_model + self.name + "_layer_" + str(index) + "_W.txt").reshape(self.layer_structure[index], self.layer_structure[index+1])) self.B.append(np.loadtxt(load_model + self.name + "_layer_" + str(index) + "_B.txt").reshape(1, self.layer_structure[index+1])) def normal_parameters(self, means, sigmas): self.means = means self.sigams = sigmas def sigmoid(self, x): return 1/(1+np.exp(-x)) def sigmoid_gradient(self, x): return self.sigmoid(x)*(1-self.sigmoid(x)) def softmax(self, x): return np.exp(x)/np.sum(np.exp(x), axis = 1, keepdims = True) def forward(self, x): """ intput : x = [batch_size, features] """ self.before_activation = [] self.activations = [x] for index in range(self.layer_number): if index &lt; self.layer_number - 1: Z = np.dot(self.activations[index], self.W[index]) + self.B[index] self.before_activation.append(Z) self.activations.append(self.sigmoid(Z)) else: if self.task_model == 'logistic': Z = np.dot(self.activations[index], self.W[index]) + self.B[index] self.before_activation.append(Z) self.activations.append(self.sigmoid(Z)) elif self.task_model == 'regression': Z = np.dot(self.activations[index], self.W[index]) + self.B[index] self.before_activation.append(Z) self.activations.append(Z) elif self.task_model == 'multi': Z = np.dot(self.activations[index], self.W[index]) + self.B[index] self.before_activation.append(Z) self.activations.append(self.softmax(Z)) return self.activations[-1] def __call__(self, x): return self.forward(x) def lossfunction(self, inputs, target): if self.task_model == 'regression': return(np.mean(np.sum((inputs - target)**2, 1))) elif self.task_model == 'logistic': return np.mean(np.sum(-target*np.log(inputs+1e-14) - (1-target)*np.log(1-inputs+1e-14), 1)) elif self.task_model == 'multi': return np.mean(np.sum(-target*np.log(inputs+1e-14), 1)) def back_forward(self, targets=None, loss=None, regularization=False): self.dWs = [] self.dBs = [] self.dAs = [] W_reverse = self.W[::-1] activations_reverse = self.activations[::-1] before_activation_reverse = self.before_activation[::-1] # 从最后一层开始往回传播 for k in range(self.layer_number): if(k == 0): if loss == 'MSE' or loss == 'CE' or loss == 'BE': dZ = activations_reverse[k] - targets dW = 1/self.batch_size*np.dot(activations_reverse[k+1].T, dZ) dB = 1/self.batch_size*np.sum(dZ, axis = 0, keepdims = True) dA_before = np.dot(dZ, W_reverse[k].T) self.dWs.append(dW) self.dBs.append(dB) self.dAs.append(dA_before) else: dZ = self.dAs[k-1]*self.sigmoid_gradient(before_activation_reverse[k]) dW = 1/self.batch_size*np.dot(activations_reverse[k+1].T,dZ) dB = 1/self.batch_size*np.sum(dZ, axis = 0, keepdims = True) dA_before = np.dot(dZ, W_reverse[k].T) self.dWs.append(dW) self.dBs.append(dB) self.dAs.append(dA_before) self.dWs = self.dWs[::-1] self.dBs = self.dBs[::-1] def steps(self, lr=0.001, lr_decay=False): for index in range(len(self.dWs)): self.W[index] -= lr*self.dWs[index] self.B[index] -= lr*self.dBs[index] def train(self, train_datas=None, train_targets=None, train_epoch=1, lr=0.001, lr_decay=False, loss='MSE', regularization=False, display=False): train_counts = 0 for epoch in range(train_epoch): if epoch == int(train_epoch * 0.7) and lr_decay == True: lr *= 0.1 train_steps = train_datas.shape[0] // self.batch_size for i in range(train_steps): input_data = train_datas[self.batch_size*i : self.batch_size*(i+1), :].reshape(self.batch_size, train_datas.shape[1]) targets = train_targets[self.batch_size*i : self.batch_size*(i+1), :].reshape(self.batch_size, train_targets.shape[1]) prediction = self.forward(input_data) forward_loss = self.lossfunction(prediction, targets) if self.task_model=='logistic': accuracy = np.sum((prediction&gt;0.6) == targets) / targets.shape[0] self.total_accuracy.append(accuracy) elif self.task_model=='multi': accuracy = np.sum(np.argmax(prediction,1) == np.argmax(targets,1)) / targets.shape[0] self.total_accuracy.append(accuracy) self.total_loss.append(forward_loss) if display: if train_counts % 10 == 0: if self.task_model == 'logistic' or self.task_model == 'multi': print("After " + str(train_counts) + ", loss is ", forward_loss, ", accuracy is ", accuracy) else: print("After " + str(train_counts) + ", loss is ", forward_loss) self.back_forward(targets=targets, loss=loss, regularization=regularization) self.steps(lr=lr, lr_decay=lr_decay) train_counts += 1 def save_model(self, path): print("Saving the " + self.name + " model ...") for i in range(self.layer_number): np.savetxt(path + self.name + "_layer_" + str(i) + "_W.txt", self.W[i]) np.savetxt(path + self.name + "_layer_" + str(i) + "_B.txt", self.B[i]) print("Model saved !!!") 32.K_Means算法的原理 聚类算法综述：聚类算法是一种无监督学习算法，它是将相似的对象归到同一个簇中。K均值算法中的K可以理解用户想要聚类成K个不同的簇，K是一个用户可以自行定义的超参数。 K均值聚类的优缺点： 优点：容易实现 缺点：可能收敛到局部最小值，在大规模的数据上收敛慢 适用场合：数值型数据 K_Means算法的基本流程： 1.随机选择K个点作为起始的聚类中心 2.遍历每个样本，计算每个样本到K个聚类中心的距离，找出”距离”聚类中心最近的样本，并将此样本聚集到离它最近的那一个簇中。注：K_Means算法的性能会受到所选距离计算方法的影响。 3.所有样本都聚集到K个簇完成后，计算K个簇的均值，并将聚类中心移动到K个簇的均值处作为新的聚类中心。 4.重复上述步骤2~3，直到最大迭代次数就停止。 K_Means算法的优化(为了克服收敛于局部最小值提出)：如何知道生成的簇比较好？一种用来衡量K_Means算法聚类效果的指标是SSE误差平方和(预测数据与原始数据之间误差的平方和),SSE越小表示样本点越接近于聚类中心点，聚类效果越好。因为对误差取了平方，因此更加重视那些远离聚类中心的点(未理解)。降低SSE值的方法是增加簇的个数，但是簇的个数K在算法一开始运行时就固定了，不能改变。聚类的目标是在保持原有簇数目不变的条件下，提高簇的质量。常用思想是：对生成的簇进行后处理，将具有最大SSE值的簇划分成两个簇。为了保持簇的总数不变，可以将某两个簇进行合并。可以有下面两种方法合并： 1.合并最近的聚类中心：计算所有聚类中心之间的距离，合并距离最近的两个聚类中心点。 2.合并两个使得SSE增加最小的聚类中心：合并两个簇，然后计算总的SSE。必须在所有可能的两个簇上重复上述处理过程，直到找到合并最佳的两个簇。 33.常见的距离函数总结 闵可夫斯基距离：给定样本$\overrightarrow{\mathbf{x}}{i}=\left(x{i, 1}, x{i, 2}, \cdots, x{i, n}\right)^{T}$,$\overrightarrow{\mathbf{x}}{j}=\left(x{j, 1}, x{j, 2}, \cdots, x{j, n}\right)^{T}$，则闵可夫斯基距离定义为： \text { distance( }\left(\overrightarrow{\mathbf{x}}_{i}, \overrightarrow{\mathbf{x}}_{j}\right)=\left(\sum_{d=1}^{n}\left|x_{i, d}-x_{j, d}\right|^{p}\right)^{1 / p} 当p=2时，闵可夫斯基距离就是欧式距离： \operatorname{distance}\left(\overrightarrow{\mathbf{x}}_{i}, \overrightarrow{\mathbf{x}}_{j}\right)=\left\|\overrightarrow{\mathbf{x}}_{i}-\overrightarrow{\mathbf{x}}_{j}\right\|_{2}=\sqrt{\sum_{d=1}^{n}\left|x_{i, d}-x_{j, d}\right|^{2}} 当p=1时，闵可夫斯基距离就是曼哈顿距离： \text { distance }\left(\overrightarrow{\mathbf{x}}_{i}, \overrightarrow{\mathbf{x}}_{j}\right)=\left\|\overrightarrow{\mathbf{x}}_{i}-\overrightarrow{\mathbf{x}}_{j}\right\|_{1}=\sum_{d=1}^{n}\left|x_{i, d}-x_{j, d}\right|]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统知识点总结]]></title>
    <url>%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.进程与线程 对于有线程系统： 进程是资源分配的独立单位 线程是资源调度的独立单位 对无无线程系统： 进程是资源调度、分配的独立单位 2.进程间的通信方式及优缺点 管道 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信。 优点：可以实现任意关系的进程间的通信 缺点： a.长期存于系统中，使用不当容易出错 b.缓冲区有限 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程） 优点：简单方便 缺点： a.局限于单向通信 b.只能创建在它的进程以及其有亲缘关系的进程之间 c.缓冲区有限 信号量：一个计数器，可以用来控制多个线程对共享资源的访问 优点：可以同步进程 缺点：信号量有限 信号: 一种比较复杂的通信方式，用于通知接收进程某个事件已经发生 消息队列: 是消息的链表，存放在内核中并由消息队列标识符标识 优点： 可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合 共享内存：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问 优点：无须复制，快捷，信息量大 缺点： a.通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题 b.利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信 套接字：可用于不同及其间的进程通信 优点： a.传输数据为字节级，传输数据可自定义，数据量小效率高 b.传输数据时间短，性能高 c.适合于客户端和服务器端之间信息实时交互 d.可以加密,数据安全性强 缺点：需对传输的数据进行解析，转化成应用级的数据。 3.线程之间的通信方式 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition） 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。 自旋锁（spin lock）：与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 信号量机制 无名线程信号量 有名线程信号量 信号机制(Signal)：类似进程间的信号处理 屏障：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。 4.进程之间私有和共享的资源 私有：地址空间、堆、全局变量、栈、寄存器 共享：代码段，公共数据，进程目录，进程 ID 5.线程之间私有和共享的资源 私有：线程栈，寄存器，程序寄存器 共享：堆，地址空间，全局变量，静态变量 6.多进程与多线程间的对比、优劣与选择 线程与进程选用规则： 需要频繁创建销毁的优先用线程 需要进行大量计算的优先使用线程 强相关的处理用线程，弱相关的处理用进程 可能要扩展到多机分布的用进程，多核分布的用线程 都满足需求的情况下，用你最熟悉、最拿手的方式 7.Linux的内核同步方式 为什么需要内核同步？：在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实像多进程、多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。 内核同步方式: 原子操作 信号量（semaphore） 读写信号量（rw_semaphore） 自旋锁（spinlock） 大内核锁（BKL，Big Kernel Lock） 读写锁（rwlock） 大读者锁（brlock-Big Reader Lock） 读-拷贝修改(RCU，Read-Copy Update) 顺序锁（seqlock） 8.死锁 定义：是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。 死锁产生的条件： 互斥 请求和保持 不可剥夺 环路等待 预防死锁： 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。 打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。 打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。 有序资源分配法 银行家算法 9.页面置换算法 页面置换：在地址映射过程中，如果在页面中发现所要访问的页面不存在于内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。 分类： 全局置换：在整个内存空间置换 工作集算法 缺失率置换算法 局部置换：在本进程中进行置换 最佳置换算法(OPT) 原理：从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。于所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。 详见原理 先进先出置换算法(FIFO) 原理：该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。该算法实现简单，只需把一个进程已调入内存的页面按先后次序链接成一个队列，并设置一个指针，称为替换指针，使它总是指向最老的页面。但该算法与进程实际运行的规律不相适应，因为在进程中，有些页面经常被访问，比如，含有全局变量、常用函数、例程等的页面，FIFO算法并不能保证这些页面不被淘汰。详见原理 最近最久未使用算法(LRU) 原理：根据页面调入内存后的使用情况做出决策的。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU置换算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有也面中t值最大的，即最近最久未使用的页面予以淘汰。详见原理 时钟置换算法(Clock) 原理：淘汰访问位为0的页框中的页面，被访问过的页面将其页框的访问位数值置1。详见原理 局部置换的三种算法C++代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175#include&lt;iostream&gt;using namespace std;int page[] = &#123; 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1,-1 &#125;;void FIFO();void OPT();void RLU();bool inArray(int* a, int n, int p);int main(void) &#123; FIFO(); OPT(); RLU(); system("pause");&#125;// FIFO算法void FIFO() &#123; int temp[3] = &#123; -1,-1,-1 &#125;; int time[3] = &#123; 0,0,0 &#125;; int num = 0; int error = 0; cout &lt;&lt; "FIFO:" &lt;&lt; endl; while (page[num] != -1) &#123; if (inArray(temp, 3, page[num])) &#123; std::cout &lt;&lt; page[num] &lt;&lt; ','; std::cout &lt;&lt; endl; &#125; else &#123; error++; bool hasChanged = false; for (int i = 0; i &lt; 3; i++) &#123; if (time[i] == 0 &amp;&amp; hasChanged == false) &#123; time[i] = 2; temp[i] = page[num]; hasChanged = true; &#125; if (time[i] != 0) &#123; time[i]--; &#125; &#125; std::cout &lt;&lt; page[num] &lt;&lt; ',' &lt;&lt; ' '; for (size_t i = 0; i &lt; 3; i++) &#123; if (temp[i] == -1) &#123; std::cout &lt;&lt; '*' &lt;&lt; ' '; &#125; else &#123; std::cout &lt;&lt; temp[i] &lt;&lt; ' '; &#125; &#125; std::cout &lt;&lt; endl; &#125; num++; &#125; cout &lt;&lt; "错误率:" &lt;&lt; error &lt;&lt; endl;&#125;bool inArray(int* a, int n, int p) &#123; for (int i = 0; i &lt; n; i++) &#123; if (p == a[i]) &#123; return true; &#125; &#125; return false;&#125;// OPT算法void OPT() &#123; int temp[3] = &#123; -1,-1,-1 &#125;; int num = 0; int error = 0; //OPT已知未来的页数为20 cout &lt;&lt; "OPT:" &lt;&lt; endl; while (page[num] != -1) &#123; int a = page[num]; if (inArray(temp, 3, page[num])) &#123; std::cout &lt;&lt; page[num] &lt;&lt; ','; std::cout &lt;&lt; endl; &#125; else &#123; error++; bool fuck = false; for (size_t i = 0; i &lt; 3; i++)&#123; if (temp[i] == -1) &#123; temp[i] = page[num]; fuck = true; break; &#125; &#125; if (fuck == false) &#123; int distance[3] = &#123; 20,20,20 &#125;; for (int i = 19; i &gt;= num; i--) &#123; for (int j = 0; j &lt; 3; j++) &#123; if (temp[j] == page[i] &amp;&amp; (i - num) &lt; distance[j]) &#123; distance[j] = i - num; &#125; &#125; &#125; int k = 0; int max = -1; for (size_t i = 0; i &lt; 3; i++) &#123; if (max &lt; distance[i]) &#123; max = distance[i]; k = i; &#125; &#125; temp[k] = page[num]; &#125; std::cout &lt;&lt; page[num] &lt;&lt; ',' &lt;&lt; ' '; for (size_t i = 0; i &lt; 3; i++) &#123; if (temp[i] == -1) &#123; std::cout &lt;&lt; '*' &lt;&lt; ' '; &#125; else &#123; std::cout &lt;&lt; temp[i] &lt;&lt; ' '; &#125; &#125; std::cout &lt;&lt; endl; &#125; num++; &#125; cout &lt;&lt; "错误率:" &lt;&lt; error &lt;&lt; endl;&#125;// RLU算法void RLU()&#123; int temp[3] = &#123; -1,-1,-1 &#125;; int time[3] = &#123; -1,-1,-1 &#125;; int num = 0; int error = 0; cout &lt;&lt; "RLU:" &lt;&lt; endl; while (page[num] != -1) &#123; int a = page[num]; if (inArray(temp, 3, page[num])) &#123; std::cout &lt;&lt; page[num] &lt;&lt; ','; std::cout &lt;&lt; endl; //bool Changed = false; for (int i = 0; i &lt; 3; i++) &#123; if (temp[i] == page[num]) &#123; time[i] = 2; //Changed = true; &#125; if (temp[i] != page[num]&amp;&amp;time[i]!=0) &#123; time[i]--; &#125; &#125; &#125; else &#123; error++; //bool hasChange = false; for (size_t i = 0; i &lt; 3; i++)&#123; if (temp[i] == -1) &#123; temp[i] = page[num]; time[i] = 2; break; &#125; if(time[i] == 0) &#123; temp[i] = page[num]; time[i] = 2; &#125; else &#123; time[i]--; &#125; &#125; std::cout &lt;&lt; page[num] &lt;&lt; ',' &lt;&lt; ' '; for (size_t i = 0; i &lt; 3; i++) &#123; if (temp[i] == -1) &#123; std::cout &lt;&lt; '*' &lt;&lt; ' '; &#125; else &#123; std::cout &lt;&lt; temp[i] &lt;&lt; ' '; &#125; &#125; std::cout &lt;&lt; endl; &#125; num++; &#125; cout &lt;&lt; "错误率:" &lt;&lt; error &lt;&lt; endl;&#125; 10.进程状态转换图 进程的五种基本状态： 创建状态：进程正在被创建 就绪状态：进程被加入到就绪队列中等待CPU调度运行 执行状态：进程正在被运行 等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行 终止状态：进程运行完毕 11.软链接和硬链接的区别 软链接也叫符号链接，软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。 硬链接：通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 12.协程 定义：又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。例如： 12345678def A() : print '1' print '2' print '3'def B() : print 'x' print 'y' print 'z' 上面协程运行结果可能是12x3yz。在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A。但协程的特点在于是一个线程执行。 13.协程与线程的区别 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制。因此，没有线程切换的开销。协程和多线程相比，线程数量越多，协程的性能优势就越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突。在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 14.进程同步的几种方式 信号量：用于进程间传递信号的一个整数值。 在信号量上只有三种操作可以进行：初始化、P操作、V操作，这三种操作都是原子操作。P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。 原理：两个或多个进程可以通过简单的信号进行合作，一个进程可以被迫在某一位置停止，直到它接收到一个特定的信号。该信号即为信号量s。为通过信号量s传送信号，进程可执行原语semSignal(s);为通过信号量s接收信号，进程可执行原语semWait(s);如果相应的信号仍然没有发送，则进程被阻塞，直到发送完为止。可把信号量视为一个具有整数值的变量，在它之上定义三个操作： 一个信号量可以初始化为非负数； semWait操作使信号量s减1.若值为负数，则执行semWait的进程被阻塞。否则进程继续执行； semSignal操作使信号量加1，若值大于或等于零，则被semWait操作阻塞的进程被解除阻塞 管程：由一个或多个过程、一个初始化序列和局部数据组成的软件模块，其主要特点如下： 局部数据变量只能被管程的过程访问，任何外部过程都不能访问； 一个进程通过调用管程的一个过程进入管程； 在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用； 消息传递：是进程间进程消息传递所需要的最小操作集。一个进程以消息的形式给另一个指定的目标进程发送消息；进程通过执行receive原语接收消息，receive原语中指明发送消息的源进程和消息。 15.线程同步的几种方式 临界区:通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。 互斥量:采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享。 信号量:它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。 事件:通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中的文件打包与压缩方法总结]]></title>
    <url>%2FLinux%2FLinux%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E6%89%93%E5%8C%85%E4%B8%8E%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一、文件打包和解压缩 在windows系统上最常见的压缩文件不外乎这三种*.zip,*.rar,*.7z后缀的压缩文件，而在Linux系统上常见常用的除了以上的三种之外，还有*.gz,*.xz,*.bz2,*.tar,*tar.gz,*tar.xz,*.tar.bz2等后缀的压缩文件。 1..zip压缩打包程序 1.1 打包文件夹zip -r -q -o njust.zip /home/cdl 参数说明: -r：表示递归打包包含子目录的全部内容 -q：表示为安静模式，即不向屏幕输出信息 -o：表示输出文件，需要在其后紧跟打包输出文件名 查看压缩文件的信息： 12du -h njust.zipfile njust.zip 1.2 设置压缩等级(9最小,1最大) zip -r 9 -q -o njust_9.zip /home/cdl -x ~/*.zip zip -r -1 -q -o njust_1.zip /home/cdl -x ~/*.zip这里添加了一个参数用于设置压缩级别[1-9],1表示最快压缩但体积大，9表示体积最小但耗时最久。最后那个-x是为了排除上一次创建的zip文件，否则又会被打包进这一次的压缩文件中。这里只能使用绝对路径！！！ 再使用du命令分别查看默认压缩等级、最低和最高压缩级别及未压缩的文件的大小： 1du -h -d 0 *.zip | sort 通过man手册可知： -h：输入人类可以解释的信息 -d：所查看文件的深度 1.3 创建加密zip包(使用-e参数可以创建加密压缩包) zip -r -e -o njust_encryption.zip /home/cdl 注意：关于zip命令，因为windows系统与Linux在文本文件格式上的兼容问题，比如换行符(为不可见字符)，在windows为回车加换行，Linux上为换行；所以如果不加处理的话，在Linux上编辑的文本文件，在windows系统上打开可能看起来是没有换行的。如果想让在Linux创建的zip压缩文件在Windows系统上解压后没有任何问题，那么还需要对命令进行修改： zip -r -l -o njust.zip /home/cdl 需要加上-l参数将换行转为回车加换行 2.使用unzip命令解压缩zip文件 将njust.zip解压到当前目录下： unzip njust.zip 使用安静模式，将文件解压到指定目录，指定目录不存在，会自动创建： unzip -q njust.zip -d ziptest 如果不想解压只想查看压缩包的内容，可以使用-l参数： unzip -l njust.zip 注意：使用unzip解压文件时同样应该注意兼容问题，不过这里此时关心的不再是上面的问题，而是中文编码的问题。通常windows系统上创建的压缩文件，如果有包含中文的文档或以中文作为文件名的文件时，默认会采用GBK或其他编码，而Linux上默认使用utf-8编码，如果不加任何处理，直接解压的话可能会出现中文乱码的问题(有时候它会帮你自动处理)。为了解决这个问题，可以在解压时指定编码类型。 使用-O(大写的字母O)参数指定编码类型： 1unzip -O GBK 中文压缩文件.zip 3..rar文件打包压缩命令 rar也是windows上常用的一种压缩文件的格式，在Linux上可以使用rar和unrar工具分别创建和解压rar压缩包 首先使用需要安装rar和unrar工具： sudo apt-get update sudo apt-get install rar unrar 在使用rar、unrar命令时，应该注意命令参数前不加-，否则会报错！ rm *.zip rar a njust.rar上面的命令使用a参数添加一个目录~到一个归档文件中，如果该文件不存在就会自动创建。 如果不解压只是查看文件，可以使用参数l： rar l njust.rar 全路径解压： unrar x njust.rar 去掉全路径解压： mkdir temp unrar e njust.rar temp/ 4..tar打包工具 在Linux上面更常用的是tar工具，tar原本只是一个打包工具，只是同时还实现了对7z，gizp，xz，bzip2等工具的支持 创建一个tar包：tar -cf njust.tar ~ (此命令会自动去掉表示绝对路径的/，也可以使用-P保留绝对路径符) 参数说明： -c：创建一个tar包文件 -f：指定创建文件的名，注意文件名必须紧跟在-f参数后，不能写成tar -fc njust.tar!可以写成tar -f njust.tar -c ~ -v：以可视的方式输出打包的文件 解压一个文件(-x参数)到指定路径的已存在目录(-C参数)：mkdir tardirtar -xf njust.tar -C tardir 只查看不解压文件-t参数：tar -tf njust.tar 对于创建不同压缩格式的文件时，对于tar来说是非常简单，需要的只是换一个参数，这里以使用gzip工具创建.tar.gz文件为例来说明。只需要在创建tar文件的基础上加一个-z参数，使用gzip来压缩文件：tar -czf njust.tar.gz ~ 解压*.tar.gz文件到当前文件夹：tar -xzf njust.tar.gz 现在要使用其他的压缩工具创建或解压相应文件时，只需要更改一个参数即可： 此外，还有gzip和gunzip(相当于gzip -d)：压缩和解压命令，解压文件为.gz后缀]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow中的RNNCell基本单元使用]]></title>
    <url>%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2FTensorFlow%E4%B8%AD%E7%9A%84RNNCell%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[0.charRNN基础介绍 charRNN 是N vs N的循环神经网络，要求输入序列长度等于输出序列长度。原理：用已经输入的字母去预测下一个字母的概率。一个句子是hello!,例如输入序列是hello,则输出序列是ello!预测时：首先选择一个x1当作起始的字符，然后用训练好的模型得到下一个字符出现的概率。根据这个概率选择一个字符输出，然后将此字符当作下一步的x2输入到模型中。依次递推，得到任意长度的文字。注意：输入的单个字母是以one-hot形式进行编码的！ 对中文进行建模时，每一步输入模型的是一个汉字，由于汉字的种类太多，导致模型太大，一般采用下面的方法进行优化： 1.取最常用的N个汉字，将剩下的汉字变成单独的一类，用一个\字符来进行标注 2.在输入时，可以加入一个embedding层，将汉字的one-hot编码转为稠密的词嵌入表示。对单个字母不使用embedding是由于单个字母不具备任何的含义，只需要使用one-hot编码即可。单个汉字是具有一定的实际意义的，所以使用embedding层 1.实现RNN的基本单元RNNCell抽象类————有两种直接使用的子类:BasicRNNCell(基本的RNN)和LSTMCell(基本的LSTM) RNNCell有三个属性: 1.类方法call:所有的子类都会实现一个call函数，可以实现RNN的单步计算，调用形式：(output,nextstate)=\_call__(input, state) 2.类属性statesize:隐藏层的大小，输入数据是以batch_size的形式进行输入的即input=(batch_size, input_size),调用\_call__函数时隐藏层的形状是(batch_size, state_size),输出层的形状是(batch_size, output_size) 3.类属性output_size:输出向量的大小 2.定义一个基本的RNN单元12345import tensorflow as tfimport numpy as nprnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=128)print("rnn_cell.state_size:", rnn_cell.state_size) 3.定义一个基本的LSTM的基本单元123456789lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=128)print("lstm_cell.state_size:", lstm_cell.state_size)lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units=128) # batch_size=32, input_size=100inputs = tf.placeholder(np.float32, shape=(32, 100))h0 = lstm_cell.zero_state(32, np.float32) # 通过zero_state得到一个全0的初始状态output, h1 = lstm_cell.__call__(inputs, h0)print(h1.c)print(h1.h) 4.对RNN进行堆叠：MultiRNNCell1234567891011121314# 每次调用这个函数返回一个BasicRNNCelldef get_a_cell(): return tf.nn.rnn_cell.BasicRNNCell(num_units=128)# 使用MultiRNNCell创建3层RNNcell = tf.nn.rnn_cell.MultiRNNCell([get_a_cell() for _ in range(3)])# 得到的RNN也是RNNCell的子类,state_size=(128, 128, 128):三个隐层状态，每个隐层状态的大小是128print(cell.state_size)# 32是batch_size, 100是input_sizeinputs = tf.placeholder(np.float32, shape=(32, 100))h0 = cell.zero_state(32, np.float32)output, h1 = cell.__call__(inputs, h0)print(h1) 5.使用tf.nn.dunamic_rnn按时间展开：相当于增加了一个时间维度time_steps,通过{h0,x1,x2…,xn}得到{h1,h2,h3,…hn}12345inputs: shape=(batch_size, time_steps, input_size) # 输入数据的格式是(batch_size, time_steps, input_size)initial_state: shape(batch_size,cell.state_size) # 初始状态,一般可以取零矩阵outputs, state = tf.nn.dynamic_rnn(cell,inputs,initial_state)# outputs是time_steps中所有的输出，形状是(batch_size, time_steps, cell.output_size)# state是最后一步的隐状态，形状是(batch_size,cell.state_size) 注意：输入数据的形状是(time_steps,batch_size, input_size),可以调用tf.nn.dynamic_rnn()函数中设定参数time_major=True。此时，得到的outputs的形状是(time_steps, batch_size, cell.output_size);state的形状不变化]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas中iloc、loc、ix三者的区别]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2FPandas%E4%B8%ADiloc%E3%80%81loc%E3%80%81ix%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[一、综述：iloc、loc、ix可以用来索引数据、抽取数据二、iloc、loc、ix三者对比 iloc和loc的区别 iloc主要使用数字来索引数据，不能使用字符型的标签来索引数据。 loc只能使用字符型标签来索引数据，不能使用数字来索引数据。特殊情况：当dataframe的行标签或列标签为数字时，loc就可以来索引 行标签和列标签都是数字的情况1234567891011a = np.arange(12).reshape(3, 4)print("a: \n", a)df = pd.DataFrame(a)print("df: \n", df)print("df.loc[0]: \n", df.loc[0])print("df.iloc[0]: \n", df.iloc[0])print("df.loc[:,[0,3]]: \n", df.loc[:, [0, 3]])print("df.iloc[:, [0,3]]: \n", df.iloc[:, [0, 3]]) 将行标签[0, 1, 2]改为[‘a’,’b’,’c’]时的情况 123456789df.index = ['a', 'b', 'c']print("df: \n", df)# print(df.loc[0]) 报错！TypeError: cannot do label indexing on &lt;class 'pandas.core.indexes.base.Index'&gt; with these indexers [0] of &lt;class 'int'&gt;print("df.iloc[0]: \n", df.iloc[0])print("df.loc['a']: \n", df.loc['a'])# print("df.iloc['a']: \n", df.iloc['a']) 报错！ 将列标签[0, 1, 2]改为[‘A’, ‘B’, ‘C’]时的情况 12345df.columns = ['A', 'B', 'C']print("df: \n", df)print("df.loc[:, 'A']: \n", df.loc[:, 'A'])# print("df.iloc[:, 'A']: \n", df.iloc[:, 'A']) 报错！ ix是一种混合索引，字符型标签和整型索引都可以使用1234print("df.ix[0]: \n", df.ix[0])print("df.ix['a']: \n", df.ix['a'])print("df.ix[:, 0]: \n", df.ix[:, 0])print("df.ix[:, 'A']: \n", df.ix[:, 'A']) 三、参考博客CSDN博客链接]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络基础知识点总结]]></title>
    <url>%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[0.互联网的组成 边缘部分：所有连接在互联网上的主机（主机指的是所有与网络直接相连的计算机）组成，用户可以直接使用，用来进行主机之间的通信和资源共享。 核心部分：大量的网络与连接这些网络所使用的路由器构成，为边缘部分提供服务。 边缘部分总结 边缘部分主要使用核心部分所提供的服务，使得许多主机之间能够互相通信并进行交换或共享信息。计算机之间的通信指的是主机A上的一个进程与主机B上的另一个进程之间进行通信。通信的方式主要有两种： 客户-服务器方式：即C /S方式。客户端发送服务的请求，服务器是服务的提供方。 P2P：对等连接方式。两台通信的主机之间不区分哪个是客户，哪个是服务端，只要两台主机都运行了对等连接软件就可以进行平等、对等的连接通信。 核心部分总结 核心部分起到特殊作用的是路由器，它是一个专用的计算机，主要作用是分组交换和存储转发的功能。 电路交换：使用在电话机之间的通信，使用电话交换机解决了多个电话机之间通信需要大量的电线的问题。电路交换的过程是：建立连接(开始占用通信资源)—-通话(一直占用通信资源)——释放连接(归还通信资源)。电路交换的特点是：通话期间，通话的两个用户会始终占用通信资源。使用电路交换传输计算机数据时，传输效率往往会很低。因为计算机数据具有突变式的特点，线路上真正用来传输数据的时间往往不到10%,大部分通信线路资源绝大部分时间都被浪费了。整个报文的比特流连续的从源点直达终点 分组交换：采用存储转发的技术，把一个报文（需要发生出去的整块数据）划分成几组分组后再进行传输。将报文划分成更小的等长数据段，然后加上首部(包含一些控制信息)，构成了一个分组，分组的首部称为一个包头。单个分组（只是整个报文的一部分）传送到相邻结点，存储下来后查找转发表，转发到下一个结点。 报文交换：整个报文先传送到相邻结点，全部存储下来后查找转发表，转发到下一个结点。 路由器的工作流程：路由器接收到一个分组后，暂存数据到路由器自己的缓存中即自身的存储器中，然后检查其首部，查找转发表。按照首部中的目的地址，找到合适的接口转发除去，把分组交给下一个路由器。这样一步一步以存储转发的方式，把分组交给最终的目的主机。路由器只是暂存一个分组，不是整个报文。分组在哪段链路上传送时才会占用此段链路上的通信资源，在各分组传输之间的空闲时间，此链路也是可以被其他主机发送的分组使用。计算机网络中的常见硬件设备介绍： 物理层：实现网络互连的主要设备有中继器和HUB(集线器)。中继器的主要功能是对接收到的信号进行再生整形放大以扩大网络的传输距离；集线器在此基础上将所有的节点集中在以它为中心的节点中，可组成星型拓扑结构。 数据链路层：实现网络互联的主要设备有二层交换机和网桥。交换机是一种基于MAC识别，能完成封装转发数据包功能的网络设备。它可以“学习”MAC地址，并把其存放在内部地址表中，当一个数据帧的目的地址在MAC地址表中有映射时，它被转发到连接目的节点的端口而不是所有端口。 交换机将局域网分为多个冲突域，每个冲突域都是有独立的宽带，因此大大提高了局域网的带宽。网桥是数据链路层互联的设备，在网络互联中可起到数据接收、地址过滤与数据转发的作用，可用来实现多个不同网络系统之间的数据交换。 网络层：实现网络互连的主要设备有三层交换机和路由器。路由器用于连接多个逻辑上分开的网络，具有判断网络地址和选择IP路径的功能，它能在多网络互联环境中，建立灵活的连接，可用完全不同的数据分组和介质访问方法连接各种子网。 传输层（包括传输层）以上：实现网络互连的设备有网关。网关在网络层以上实现网络互连，用于两个高层协议不同的网络互连。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。 1.计算机网络体系结构 应用层：应用层是体系结构中的最高层。应用层直接为用户的应用进程程序提供服务。这里的进程就是指正在运行的程序。在因特网中的应用层协议很多，如支持万维网应用的http协议支持电子邮件的SMTP协议，支持文件传送的FTP协议等。 运输层：运输层的任务就是负责向两个主机中进程之间的通信提供服务。由于一个主机可以同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可以同时使用下面运输层的服务，分用就是运输层把收到的信息分别交付给上面应用层中的相应进程。 运输层主要使用下面两个协议： 传输控制协议TCP：面向连接的，数据传输的基本单位是报文段，能够提供可靠的交付 用户数据包协议UDP：无连接的，数据传输的基本单位是用户数据报，不能保证提供可靠的交付，只能提供尽最大努力交付。 网络层： 负责为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫作IP数据报。 数据链路层：两个主机之间的数据传输，总是在一段一段的链路上传送的。在两个相邻结点之间传送数据时，数据链路层将网络层交下来的IP数据报组装成帧，在两个相邻结点间的链路上透明地传送帧中的数据，每一帧包括数据和必要的控制信息。 物理层：在物理层上传送的数据单位是比特。物理层的任务就是透明地传送比特流。 2.各层的作用和支持的协议 3.物理层 传输数据的基本单位：比特流0和1 数据传输系统：源系统（源点、发送器） —&gt; 传输系统 —&gt; 目的系统（接收器、终点） 通道： 单向通道（单工通道）：只有一个方向通信，没有反方向交互，如广播 双向交替通信（半双工通信）：通信双方都可发消息，但不能同时发送或接收 双向同时通信（全双工通信）：通信双方可以同时发送和接收信息 通道复用技术： 频分复用（FDM，Frequency Division Multiplexing）：不同用户在不同频带，所用用户在同样时间占用不同带宽资源 时分复用（TDM，Time Division Multiplexing）：不同用户在同一时间段的不同时间片，所有用户在不同时间占用同样的频带宽度 波分复用（WDM，Wavelength Division Multiplexing）：光的频分复用 码分复用（CDM，Code Division Multiplexing）：不同用户使用不同的码，可以在同样时间使用同样频带通信 4.数据链路层 主要信道： 点对点信道 广播信道 点对点信道： 数据单元：帧 三个基本问题： 封装成帧：把网络层的 IP 数据报封装成帧，SOH - 数据部分 - EOT 透明传输：不管数据部分什么字符，都能传输出去；可以通过字节填充方法解决（冲突字符前加转义字符） 差错检测：降低误码率（BER，Bit Error Rate），广泛使用循环冗余检测（CRC，Cyclic Redundancy Check） 点对点协议（Point-to-Point Protocol）：用户计算机和 ISP 通信时所使用的协议 广播信道： 硬件地址（物理地址、MAC 地址） 单播（unicast）帧（一对一）：收到的帧的 MAC 地址与本站的硬件地址相同 广播（broadcast）帧（一对全体）：发送给本局域网上所有站点的帧 多播（multicast）帧（一对多）：发送给本局域网上一部分站点的帧 5.网络层 IP（Internet Protocol，网际协议）是为计算机网络相互连接进行通信而设计的协议。 ARP（Address Resolution Protocol，地址解析协议） ICMP（Internet Control Message Protocol，网际控制报文协议） IGMP（Internet Group Management Protocol，网际组管理协议） 5.1 IP网际协议 IP地址({&lt;网络号&gt;,&lt;主机号&gt;})分类： IP数据报格式： 5.2 ICMP网际控制报文协议 ICMP报文格式： 应用： PING（Packet InterNet Groper，分组网间探测）测试两个主机之间的连通性 TTL（Time To Live，生存时间）该字段指定 IP 包被路由器丢弃之前允许通过的最大网段数量 5.3 内部网关协议 RIP（Routing Information Protocol，路由信息协议） OSPF（Open Sortest Path First，开放最短路径优先） 5.4 外部网关协议 BGP（Border Gateway Protocol，边界网关协议） 5.5 IP多播 IGMP（Internet Group Management Protocol，网际组管理协议） 多播路由选择协议 5.6 VPN和NAT VPN（Virtual Private Network，虚拟专用网） NAT（Network Address Translation，网络地址转换） 5.7 路由表包含什么？ 网络 ID（Network ID, Network number）：就是目标地址的网络 ID。 子网掩码（subnet mask）：用来判断 IP 所属哪个子网络 下一跳地址/接口（Next hop / interface）：就是数据在发送到目标地址的旅途中下一站的地址。其中 interface 指向 next hop（即为下一个 route）。一个自治系统（AS, Autonomous system）中的 route 应该包含区域内所有的子网络，而默认网关（Network id: 0.0.0.0, Netmask: 0.0.0.0）指向自治系统的出口。 根据应用和执行的不同，路由表可能含有如下附加信息： 花费（Cost）：就是数据发送过程中通过路径所需要的花费 路由的服务质量 路由中需要过滤的出/入连接列表 6.传输层 支持的协议： TCP（Transmission Control Protocol，传输控制协议） UDP（User Datagram Protocol，用户数据报协议） 端口号： 6.1 TCP（Transmission Control Protocol，传输控制协议） TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，其传输的单位是报文段。 特征： 面向连接 只能点对点（一对一）通信 可靠交互 全双工通信 面向字节流 TCP如何保证可靠传输？ 确认和超时重传 数据合理分片和排序 流量控制 拥塞控制 数据校验 TCP报文结构 TCP首部 TCP：状态控制码（Code，Control Flag），占 6 比特，含义如下： URG：紧急比特（urgent），当 URG＝1 时，表明紧急指针字段有效，代表该封包为紧急封包。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)， 且上图中的 Urgent Pointer 字段也会被启用。 ACK：确认比特（Acknowledge）。只有当 ACK＝1 时确认号字段才有效，代表这个封包为确认封包。当 ACK＝0 时，确认号无效。 PSH：（Push function）若为 1 时，代表要求对方立即传送缓冲区内的其他对应封包，而无需等缓冲满了才送。 RST：复位比特(Reset)，当 RST＝1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 SYN：同步比特(Synchronous)，SYN 置为 1，就表示这是一个连接请求或连接接受报文，通常带有 SYN 标志的封包表示『主动』要连接到对方的意思。 FIN：终止比特(Final)，用来释放一个连接。当 FIN＝1 时，表明此报文段的发送端的数据已发送完毕，并要求释放传输连接。 6. 2 UDP（User Datagram Protocol，用户数据报协议） UDP是 OSI（Open System Interconnection 开放式系统互联） 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，其传输的单位是用户数据报。 特征： 无连接 尽最大努力交付 面向报文 没有拥塞控制 支持一对一、一对多、多对多的交互通信 首部开销小 UDP报文结构 UDP首部 6.3 TCP与UDP的区别 TCP面向连接、UDP是无连接的； TCP提供可靠的服务、也就是说，通过TCP连接传输的数据是无差错、不丢失、不重复且按序到达；UDP尽最大努力交付，即不保证可靠交付 TCP的逻辑通信信息是全双工的可靠信息；UDP则是不可靠信息 每一条TCP连接只能是点对点的；UDP支持一对多、多对一、多对多的交互通信 TCP面向字节流(可能会出现黏包问题)，实际上是TCP白数据看成一连串无结构的字节流；UDP是面向报文的(不会出现黏包问题) UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低(对实时应用很有用，如IP电话，实时视频会议等) TCP首部开销20字节；UDP的首部开销小，只有8字节 6.4 TCP的黏包问题 出现黏包问题的原因：TCP 是一个基于字节流的传输服务（UDP 基于报文的），“流” 意味着 TCP 所传输的数据是没有边界的，所以可能会出现两个数据包黏在一起的情况。 解决方法： 发送定长包。如果每个消息的大小都是一样的，那么在接收对等方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。 包头加上包体长度。包头是定长的 4 个字节，说明了包体的长度。接收对等方先接收包头长度，依据包头长度来接收包体。 在数据包之间设置边界，如添加特殊符号 \r\n 标记。FTP 协议正是这么做的。但问题在于如果数据正文中也含有 \r\n，则会误判为消息的边界。 使用更加复杂的应用层协议6.5 TCP流量控制 概念：流量控制（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。 方法：利用可变窗口进行流量控制 6.6 TCP拥塞控制 概念：拥塞控制就是防止过多的数据注入到网络中，可以使网络中的路由器或链路不致过载。 解决方法： 慢启动( slow-start ) 拥塞避免( congestion avoidance ) 快重传( fast retransmit ) 快恢复( fast recovery ) 6.7 TCP传输连接管理(重点) 一.TCP建立连接：三次握手 TCP 建立连接全过程解释： 1.客户端发生SYN给服务器，表示客户端向服务器请求建立连接； 2.服务端收到客户端的SYN，并回复SYN+ACK给客户端(同意建立连接)； 3.客户端收到来自服务器的SYN+ACK后，回复ACK给服务端(表示客户端收到了服务端发的同意报文)； 4.服务端收到客户端的ACK，连接已建立，可以进行数据传输。 建立连接的详细过程： a.B的TCP服务器进程首先创建传输控制块TCB,准备接受客户进程的连接请求。然后服务器进程就处于LISTEN(收听)状态，等待客户的连接请求。如有，就做出响应。 b.A的TCP客户进程也是首先创建传输控制模块TCB，然后向B发出连接请求报文段，这时首部中的同步位SYN=1，同时选择一个初始序号seq=x。TCP规定，SYN报文段(即SYN=1的报文段)不能携带数据，但是要消耗一个序号。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。 c.B收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN和ACK位都置1，确认号是ack=x+1,同时也为自己选择一个初始序号seq=y。注意：这个报文段也不能携带数据，但同样要消耗一个序号。这时TCP服务器进程进入SYN-RECV(同步收到)状态。 d.TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP标准规定，ACK报文段可以携带数据。但如果不携带数据则不消耗序号。在这种情况下，下一个数据报文段的序号仍然是seq=x+1。这时，TCP的连接已经建立，A进入ESTABLISHED(已建立连接)状态。当B接收到A的确认后，B也进入ESTABLISHED(已建立连接)状态。 Q1：TCP为什么要进行三次握手？ 因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。(而 UDP 则不需建立可靠传输，因此 UDP 不需要三次握手) 因为双方都需要确认对方收到了自己发送的序列号，确认过程最少要进行三次通信 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误 二.TCP断开连接：四次挥手 TCP 断开连接全过程解释： 1.客户端发送 FIN 给服务器，说明客户端不必发送数据给服务器了（请求释放从客户端到服务器的连接）； 2.服务器接收到客户端发的 FIN，并回复 ACK 给客户端（同意释放从客户端到服务器的连接）； 3.客户端收到服务端回复的 ACK，此时从客户端到服务器的连接已释放（但服务端到客户端的连接还未释放，并且客户端还可以接收数据）； 4.服务端继续发送之前没发完的数据给客户端； 5.服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）； 6.服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）； 7.服务端收到客户端的 ACK 后，断开从服务端到客户端的连接 释放连接的详细过程： a.A和B都处于ESTABLISHED状态，A的应用进程首先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的FIN置1，其序列号seq=u，它等于前面已经传送过的数据的最后一个字节的序号加1。这时，A进入FIN-WAIT-1(终止等待1)状态，等待B的确认。注意：TCP规定：FIN报文段即使不携带数据，它也会消耗一个序号。 b.B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等待B前面已经传送过的数据的最后一个字节的序号加1。然后B就进入CLOSE-WAIT(关闭等待)状态。TCP服务器进程这时应通知高层应用进程，因而从A到B这个方向的连接就释放了，这时的TCP连接处于半关闭状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并没有关闭，这个连接可能会持续一段时间。 c.A收到来自B的确认后，就进入FIN-WAIT-2(终止等待2)状态，等待B发出的连接释放报文段。如果B已经没有要向A发送的数据，其应用进程就会通知TCP释放连接。这时B发出的连接释放报文段必须使FIN=1。现假定B的序号为w(在半关闭状态B可能又发送了一些数据)。B还必须重复上次已经发送过的确认号ack=u+1。这时，B就进入LAST-ACK(最后确认状态)，等待A的确认。 d.A在收到B的释放连接报文段后，必须对此发出一个确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1(根据TCP标准，前面发送过的FIN报文段要消耗一个序号)。然后经过时间等待计时器(TIME-WAIT)设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做最长报文段寿命 Q2：TCP 为什么要进行四次挥手？ 因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）。所以 TCP 释放连接时服务器的 ACK 和 FIN 是分开发送的（中间隔着数据传输），而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。 Q3：为什么 TCP 建立连接时可以 ACK 和 SYN 一起发送，而断开连接时则 ACK 和 FIN 分开发送呢？（ACK 和 FIN 分开是指第二次和第三次挥手） 因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。 Q4：为什么客户端断开连接时，最后需要 TIME-WAIT 等待 2MSL 呢？ 1.为了保证客户端发送的最后一个 ACK 报文能够到达服务端。若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时。 2.防止已失效的连接请求报文段出现在本连接中。TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。6.8 TCP有限状态机 7.应用层7.1 DNS(Domain Name System，域名系统) DNS是互联网的一项服务。它作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS 使用 TCP 和 UDP 端口 53。当前，对于每一级域名长度的限制是 63 个字符，域名总长度则不能超过 253 个字符。 域名 ::= {&lt;三级域名&gt;.&lt;二级域名&gt;.&lt;顶级域名&gt;}，如：blog.huihut.com 7.2 FTP(File Transfer Protocol，文件传输协议) FTP是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式，使用 TCP 数据报，提供交互式访问，双向传输。 TFTP（Trivial File Transfer Protocol，简单文件传输协议）一个小且易实现的文件传输协议，也使用客户-服务器方式，使用UDP数据报，只支持文件传输而不支持交互，没有列目录，不能对用户进行身份鉴定 7.3 TELNET TELNET 协议是 TCP/IP 协议族中的一员，是 Internet 远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。 7.4 HTTP（HyperText Transfer Protocol，超文本传输协议） HTTP是用于从 WWW（World Wide Web，万维网）服务器传输超文本到本地浏览器的传送协议。 7.5 SMTP（Simple Mail Transfer Protocol，简单邮件传输协议） SMTP是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。SMTP 协议属于 TCP/IP 协议簇，它帮助每台计算机在发送或中转信件时找到下一个目的地。它是在 Internet 传输 Email 的标准，是一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。可以很简单地通过 Telnet 程序来测试一个 SMTP 服务器，SMTP 使用 TCP 端口 25。 7.6 DHCP（Dynamic Host Configuration Protocol，动态主机设置协议） DHCP是一个局域网的网络协议，使用 UDP 协议工作，主要有两个用途： 用于内部网络或网络服务供应商自动分配 IP 地址给用户 用于内部网络管理员作为对所有电脑作中央管理的手段 7.7 SNMP（Simple Network Management Protocol，简单网络管理协议） SNMP构成了互联网工程工作小组（IETF，Internet Engineering Task Force）定义的 Internet 协议族的一部分。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。 8.相关概念8.1 Socket（套接字） Socket 建立网络通信连接至少要一对端口号（Socket）。Socket 本质是编程接口（API），对 TCP/IP 的封装，TCP/IP 也要提供可供程序员做网络开发所用的接口，这就是 Socket 编程接口。 8.2 WWW（World Wide Web，环球信息网，万维网） WWW是一个由许多互相链接的超文本组成的系统，通过互联网访问8.3 URL（Uniform Resource Locator，统一资源定位符） 概念：URL是因特网上标准的资源的地址（Address） 标准格式：协议类型:[//服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID] 完整格式：协议类型:[//[访问资源需要的凭证信息@]服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID] 注意：其中[访问凭证信息@；:端口号；?查询；#片段ID]都属于选填项,可以省略，如：https://github.com/cdlwhm1217096231 9.HTTP详解 概念：HTTP（HyperText Transfer Protocol，超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP 是万维网的数据通信的基础。 请求方法： 状态码： 1xx：表示通知信息，如请求收到了或正在进行处理 100 Continue：继续，客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议 2xx：表示成功，如接收或知道了 200 OK: 请求成功 3xx：表示重定向，如要完成请求还必须采取进一步的行动 301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替 4xx：表示客户的差错，如请求中有错误的语法或不能完成 400 Bad Request: 客户端请求的语法错误，服务器无法理解 401 Unauthorized: 请求要求用户的身份认证 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够） 404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面 408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时 5xx：表示服务器的差错，如服务器失效无法完成请求 500 Internal Server Error: 服务器内部错误，无法完成请求 503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中 504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求 10.DNS(域名解析协议) 域名的来由：我们可以通过IP地址去访问网站，但是对大多数用户来说，访问每个网站都需要记住一串数字是不现实的，所以用户可以通过域名来访问网站。域名，其实是具有一定含义的字符组合。域名系统是因特网上作为域名和IP地址相互映射的一个分布式数据库，能让用户更方便使用互联网。 DNS劫持：指用户访问一个被标记的地址时，DNS服务器故意将此地址指向一个错误的IP地址的行为。范例：收到各种推送广告等网站 DNS污染：指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。比如不能访问Google、YouTube等。 域名表达式为，在地址表达式中，最右边的是最高层次的域名，最左边的是主机名，域与域之间用圆点隔开； 域名解析：通过主机最终得到该主机名对应的IP地址； 11.Http协议格式 HTTP请求报文与响应报文格式 请求报文包含三部分： 请求行：包含请求方法、URI、HTTP版本信息 请求首部字段 请求内容实体 响应报文包含三部分： 状态行：包含HTTP版本、状态码、状态码的原因短语 响应首部字段 响应内容实体 HTTP（超文本传输协议）是一个基于请求与响应模式的、无状态的、应用层的协议，常基于TCP的连接方式，HTTP1.1版本中给出一种持续连接的机制，绝大多数的Web开发，都是构建在HTTP协议之上的Web应用。 常用的HTTP方法有哪些？ GET：用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器。 POST：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。 PUT：传输文件，报文主体中包含文件内容，保存到对应URI位置。 HEAD：获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。 DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。 OPTIONS：查询相应URI支持的HTTP方法。 GET方法与POST方法的区别 get重点在从服务器上获取资源，post重点在向服务器发送数据； get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用”?”连接，多个请求数据间用”&amp;”连接，如http://127.0.0.1/Test/login.action?name=admin&amp;password=admin，这个过程用户是可见的；post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的； get传输的数据量小，因为受URL长度限制，但效率较高；Post可以传输大量数据，所以上传文件时只能用Post方式； get是不安全的，因为URL是可见的，可能会泄露私密信息，如密码等；post较get安全性较高； get方式只能支持ASCII字符，向服务器传的中文字符可能会乱码。post支持标准字符集，可以正确传递中文字符。 HTTP1.1版本新特性 默认持久连接节省通信量，只要客户端服务端任意一端没有明确提出断开TCP连接，就一直保持连接，可以发送多次HTTP请求 管线化，客户端可以同时发出多个HTTP请求，而不用一个个等待响应 断点续传原理 常见HTTP首部字段 通用首部字段（请求报文与响应报文都会使用的首部字段） Date：创建报文时间 Connection：连接的管理 Cache-Control：缓存的控制 Transfer-Encoding：报文主体的传输编码方式 请求首部字段（请求报文会使用的首部字段） Host：请求资源所在服务器 Accept：可处理的媒体类型 Accept-Charset：可接收的字符集 Accept-Encoding：可接受的内容编码 Accept-Language：可接受的自然语言 响应首部字段（响应报文会使用的首部字段） Accept-Ranges：可接受的字节范围 Location：令客户端重新定向到的 URI Server：HTTP服务器的安装信息 实体首部字段（请求报文与响应报文的的实体部分使用的首部字段） Allow：资源可支持的HTTP方法 Content-Type：实体主类的类型 Content-Encoding：实体主体适用的编码方式 Content-Language：实体主体的自然语言 Content-Length：实体主体的的字节数 Content-Range：实体主体的位置范围，一般用于发出部分请求时使用 HTTP的缺点与HTTPS 通信使用明文不加密，内容可能被窃听 不验证通信方身份，可能遭到伪装 无法验证报文完整性，可能被篡改 HTTPS就是HTTP加上加密处理（一般是SSL安全通信线路）+认证+完整性保护 12.当你输入一个网址/点击一个链接，发生了什么？（以www.baidu.com为例） 1.点击网址后，应用层的DNS协议会将网址解析为IP地址； DNS查找过程：浏览器会检查缓存中有没有这个域名对应的解析过的IP地址，如果缓存中有，这个解析过程就将结束。如果用户的浏览器缓存中没有，浏览器会查找操作系统缓存（hosts文件）中是否有这个域名对应的DNS解析结果。若还没有，此时会发送一个数据包给DNS服务器，DNS服务器找到后将解析所得IP地址返回给用户。 2.在应用层，浏览器会给web服务器发送一个HTTP请求； 请求头为：GET http://www.baidu.com/HTTP/1.1 3.在传输层，（上层的传输数据流分段）HTTP数据包会嵌入在TCP报文段中； TCP报文段需要设置端口，接收方（百度）的HTTP端口默认是80，本机的端口是一个1024-65535之间的随机整数，这里假设为1025，这样TCP报文段由TCP首部（包含发送方和接收方的端口信息）+ HTTP数据包组。 4.在网络层中，TCP报文段再嵌入IP数据包中； IP数据包需要知道双方的IP地址，本机IP地址假定为192.168.1.5，接受方IP地址为220.181.111.147（百度），这样IP数据包由IP头部（IP地址信息）+TCP报文段组成。 5.在网络接口层，IP数据包嵌入到数据帧（以太网数据包）中在网络上传送； 数据帧中包含源MAC地址和目的MAC地址（通过ARP地址解析协议得到的）。这样数据帧由头部（MAC地址）+IP数据包组成。 6.数据包经过多个网关的转发到达百度服务器，请求对应端口的服务； 服务接收到发送过来的以太网数据包开始解析请求信息，从以太网数据包中提取IP数据包—&gt;TCP报文段—&gt;HTTP数据包，并组装为有效数据交与对应线程池中分配的线程进行处理，在这个过程中，生成相应request、response。 7.请求处理完成之后，服务器发回一个HTTP响应； 请求处理程序会阅读请求及它的参数和cookies。它会读取也可能更新一些数据，并将数据存储在服务器上。处理完毕后，数据通过response对象给客户输出信息，输出信息也需要拼接HTTP协议头部分，关闭后断开连接。断开后，服务器端自动注销request、response对象，并将释放对应线程的使用标识（一般一个请求单独由一个线程处理，部分特殊情况有一个线程处理多个请求的情况）。响应头为：HTTP/1.1200 OK 8.浏览器以同样的过程读取到HTTP响应的内容（HTTP响应数据包），然后浏览器对接收到的HTML页面进行解析，把网页显示出来呈现给用户。 客户端接收到返回数据，去掉对应头信息，形成也可以被浏览器认识的页面HTML字符串信息，交与浏览器翻译为对应页面规则信息展示为页面内容。 13.计算机的OSI和TCP/IP网络模型 1.计算机的网络模型分为两种OSI模型和TCP/IP模型，它们的对应关系如下： 2.针对OSI模型，每一层都有各自的功能。 应用层 应用层是OSI模型中最靠近用户的一层，负责为用户的应用程序提供网络服务 。包括为相互通信的应用程序或进程之间建立连接，进行同步建立关于错误纠正和控制同时还包含大量的应用协议，例如远程登录（talent）、简单的邮件传输协议（SMTP）、简单的网络管理协议（SNMP），超文本传输协议（HTTP）。所有能超声网络流量的程序都在应用层。 表示层 表示层负责在不同的数据格式之间进行转换操作，以实现不同的计算机系统间的信息交换。还负责数据的加密，在传输的过程中进行保护，在发送端加密，在接收端解密，使用加密秘钥来对数据进行加密和解密。 会话层 会话层的主要功能是在两个节点间建立连接、维护、释放面向用户的连接，并对会话进行管理和控制，保证会话数据可靠传输，在会话的过程中决定到底使用全双工还是使用半双工模式传输。 传输层 传输层是OSI模型中唯一负责端到端节点数据传输和控制的层，传输层是在OSI模型中起承上启下的作用，它下面的三层主要主要面向网络通信，以确保信息准确有效的传输，上面的三层树妖面向主机用户，为用户提供各种服务。 传输层为了向会话层提供可靠的端到端传输服务，也使用差错控制和流量控制等机制。4层的协议有传输控制协议（TCP），用户数据报协议（UDP），顺序包交换协议（SPX）。 网络层 负责选择最佳的路径，规划IP(Internet Protocol)地址。 数据链路层 数据帧的开始和结束，同时提供透明传输，差错校验。 物理层 是OSI模型的最底层，它面向原始的比特流的传输，同时规范了接口标准。 3.针对TCP/IP模型，每一层都有各自的功能。 物理层：对应OSI模型的低两层，物理层和数据链路层；常用协议：Ethernet、FDDI、令牌环 网络层：对应OSI模型的网络层；常用协议：IP、ARP、RAR、ICMP 传输层：对应OSI模型的传输层；常用协议：TCP、UDP 应用层：对应OSI模型的高三层，会话层、表示层、应用层；常用协议：DNS、HTTP、SMTP、POP、TELNET、FTP 14.TCP/FTP 简析 1.TCP/FTP简析 TCP/IP是个协议组，可分为三个层次：网络层、传输层和应用层： 网络层：IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议 传输层：TCP协议与UDP协议 应用层：FTP、HTTP、TELNET、SMTP、DNS等协议 2.TCP连接的三次握手 第一次握手：客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务端接收到客户端的请求后，给出一个确认ACK(ack=j+1),同时自己也发送出一个SYN包(syn=k),此时服务器进入SYN_RECV状态。 第三次握手：客户端接收到服务端的SYN+ACK包后，向服务器发出一个确认ACK(ack=k+1)，此包发送完毕，客户端和服务端进入ESTABLIST状态，完成三次握手。 3.FTP 文件传输协议（File Transfer Protocol, FTP）是TCP/IP网络上两台计算机传送文件的协议，FTP是在TCP/IP网络和INTERNET上最早使用的协议之一，它属于网络协议组的应用层。FTP客户机可以给服务器发出命令来下载文件，上载文件，创建或改变服务器上的目录。 15.IP地址与子网掩码 1.IP地址：Internet上每台主机都必须有一个唯一的地址以区别于其他主机，这个地址就是Internet地址，也称作IP地址；IPv4（第四版本的IP协议）是构成现今互联网技术的基石协议； 2.IP地址的构成：IP地址由32位二进制构成，共约40亿个，由网络地址和主机地址构成；一个IP地址分为四段：a.b.c.d ，段与段之间用原点分开。IP地址表示方法：二进制形式和点分十进制形式； 3.IP地址的分类：5类(A类地址，B类地址，C类地址，D类地址，E类地址) IP地址的分类是根据第一段（a字段，前8位）的取值范围来划分的； A类地址：以0开头，前8位为网络地址，后24位为主机地址。A类地址第一段a字段的取值范围1~126。每一个A类地址中可以容纳的主机的数目约为1600万。地址范围：1.0.0.0~126.255.255.255 B类地址：以10开头，前16位为网络地址，后16位为主机地址。B类地址第一段a字段取值范围为128~191。每一个B类地址中可以容纳主机数目约为65000。地址范围：128.0.0.0~191.255.255.255 C类地址：以110开头，前24位为网络地址，后8位为主机地址。C类地址第一段a字段的取值范围是192~223。每一个C类地址可容纳主机的数目约为254。地址范围：192.0.0.0~223.255.255.255 4.IPv6（第六版IP协议）：一个IP地址由128位二进制组成，采用冒分16进制。 5.特殊的IP地址： a.专用IP地址：三类网络号，这些地址不会被Internet分配因此也不能被路由。 A类：1.0.0.0~10.255.255.255 （长度相当于1个A类IP地址） B类：172.16.0.0~172.31.255.255 （长度相当于16个连续的B类IP地址） C类：192.168.0.0~192.168.255.255 （长度相当于256个连续的C类IP地址） b. 特殊IP地址： 0.0.0.0 是全零网络代表默认网络，帮助路由器发送路由表中无法查询的包。如果设置了全零网络路由，路由器中无法查询的包都会被送到全零网络的路由中去； 127.0.0.1 称作回送地址，属于环回地址，IP从127.0.0.0到127.255.255.255都将环回到本地主机中； 255.255.255.255 限制广播地址，对本机来说，这个地址指本网段内（同一广播域）所有主机； 6.子网掩码 子网掩码：是一个32位二进制的值，可以将IP地址分离出网络地址和主机地址，采用点分十进制的形式。子网掩码不能单独存在它必须结合IP地址一起使用。 子网掩码由1和0组成，且1和0分别连续。子网掩码的长度也是32位。左边是网络位，用二进制数字1表示，1的数目等于网络位的长度；右边是主机位用2进制数字0表示，0的数目等于主机位的长度；这样做的目的是为了让掩码与IP地址做与运算时用0遮住原主机数，而不改变网络段的数字；而且很容易通过0的位数确定子网的主机数；将32位IP地址与32位的子网掩码各位进制进行 ‘与’ 运算，得到的是该IP地址的网络地址； 方法：子网掩码可以判断两台计算机是否属于同一网段，将计算机10进制的IP地址和子网掩码转换为2进制的形式，然后进行‘与’运算，如果网络地址是相同的，那么两台计算机就属于同一网段； 子网掩码可分为缺省子网掩码和自定义子网掩码： a.缺省（默认）子网掩码：即为划分子网，对应的网络号都是1，主机号位都是0； A类网络缺省（默认）子网掩码：255.0.0.0 B类网络缺省（默认）子网掩码：255.255.0.0 C类网络缺省（默认）子网掩码：255.255.255.0 b.自定义子网掩码是将一个网络划分为几个子网，需要每一段使用不同的网络号或者子网号，实际上我们可以认为是将主机号分为两个部分：子网号和子网主机号。形式如下： 未做子网划分的IP地址：网络号+主机号 做子网划分的IP地址：网络号+子网号+子网主机号。也就是说，IP地址在子网划分后，以前的主机号一部分给了子网号，剩下的是子网主机号； 子网掩码通常有两种格式的表示方式： 点分十进制格式，如：255.255.255.128 IP地址后面加上‘/’符号以及1-32位的数字，其中1-32的数字表示子网掩码中网络标识位的长度；例如：192.168.1.1/24的子网掩码也可以表示为255.255.255.0 16.路由器 路由器：属于网络层，是连接因特网中的各局域网、广域网的设备，它会根据信道的情况自动选择和设定路由，以最佳路径，按照前后顺序发送信号。连接不同的网络，所谓不同的网络就是网络地址不同；路由器工作在IP协议网络层，用于实现子网之间转发数据，路由器一般包含多个网络接口，包括局域网和广域网接口，每个网络接口连接不同的网络；路由器记录着每个网络端口连接的网络信息；路由器中还包含路由表：记录了去往不同的网络地址应该送往的端口号； 作用：为每个数据帧寻找最佳的传输路径，并将其有效的传送到目的站点，在路由器中通过路由表保存着各种传输路径的相关数据，供路由选择时使用。 路由表：保存各种传输路径的相关数据，供路由选择时使用；路由表中保存着子网的标志信息、网上路由器的个数和下一个路由器的名字等内容； 静态路由表：由系统管理员事先设定好的路由表； 动态路由表：路由器根据网络系统的运行情况动态调整的路由表； 工作流程：数据包送到路由器后，通过数据包首部的目的主机IP地址和子网掩码计算出网络地址，即目的主机所在的网络，查找当前路由器的路由表，选择端口进行转发;下一台IP路由器收到数据包后继续转发，直到目的地；路由转发策略称为路由选择； 路由器和交换机之间的主要区别是：交换机发生在OSI参考模型的第二层（数据链路层），而路由器发生在第三层（网络层）。路由器是不同网络之间相互连接的枢纽，路由器构成了Internet的骨架；路由器具有判断网路地址，选择IP路径的功能； 17.MAC地址(物理地址、硬件地址)的概念和作用 概念：MAC地址就是在媒体接入层上使用的地址，也叫物理地址、硬件地址或链路地址，其被固化在适配器的ROM中。可见，MAC地址实际上就是适配器地址或适配器标识符。当某台计算机使用某块适配器后，适配器上的标识符就成为该计算机的MAC地址。MAC地址长度为6字节（48比特），由IEEE的注册管理结构RA进行管理分配。 作用：MAC地址是计算机的唯一标识，在数据链路层中，交换机通过识别MAC地址进行数据包的传输。 18.路由表中的内容 Network Destination：目标网段；Netmask：子网掩码，IP地址与子网掩码按位与，可以得出该IP地址的网络号，IP地址与子网掩码取反后按位与，可以得出该IP地址的主机号。Interface：达到该目标网段的本地路由器的出口IP；Gateway：网关IP，下一跳路由器的入口IP，通常情况下，interface和gateway是同一网段的。Metric：跳数，该条路由记录的质量，一般情况下，如果有多条到达相同目的地的路由记录，路由器会采用metric值小的那条路由。 19.分组转发算法流程 1.从数据报的首部提取目的主机的IP地址D，得出目的网络地址N（子网掩码和IP地址做与运算可得出网络地址）。 2.若N就是于此路由器直接相连的某个网络地址，则进行直接交付，不需要在经过其他路由器，直接把数据报交付给目的主机（这里包括把目的IP地址D转换为具体的MAC地址（ARP协议），把数据报封装成MAC帧，在发送此帧）；否则就是间接交付。 3.若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器。 4.若路由表中有达到网络N的路由，则把数据报传送给路由表中所指明的下一跳路由器。 5.若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器。 6.报告转发分组出错。 20.TFTP与FTP的区别 FTP（File Transfer Protocol，文件传输协议）协议在TCP/IP协议族中属于应用层协议，用于在远端服务器和本地客户端之间传输文件，使用TCP端口20和21进行传输。端口20用于传输数据，端口21用于传输控制消息。 TFTP（Trivial File Transfer Protocol，简单文件传输协议）也是用于在远端服务器和本地主机之间传输文件的，相对于FTP，TFTP没有复杂的交互存取接口和认证控制，适用于客户端和服务器之间不需要复杂交互的环境。 TFTP协议的运行基于UDP协议，使用UDP端口69进行数据传输。 区别： 基于的传输协议不一样：FTP是基于TCP TFTP是基于UDP 端口号不一样：FTP是用21.20 TFTP是69 速度和安全方面：FTP在速度方面没有TFTP快但是FTP安全好 21.MTU的概念，什么是路径MTU？ MTU发现机制，TraceRoute MTU：即Maximum Transmission Unit 最大传输单元。它是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。 路径MTU：路径MTU是指一条因特网传输路径中，从源地址到目的地址所经过的“路径”上的所有IP跳的最大传输单元的最小值。或者从另外一个角度来看，就是无需进行分片处理就能穿过这条“路径”的最大传输单元的最大值。 路径MTU的发现方法：这是确定两个IP主机之间路径最大传输单元的技术，其目的就是为了避免IP分片。首先源地址将数据报的DF位置位，在逐渐增大发送的数据报的大小——路径上任何需要将分组进行分片的设备都会将这种数据报丢弃并返回“数据报过大“的ICMP响应到源地址——这样源主机就”学习“到了无需分片就能通过这条路径的最大的最大传输单元。 Traceroute:用来侦测主机到目的主机之间所经路由情况的重要工具。原理如下：它受到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包（每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签），而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器ip。Traceroute提取发送 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 22.ICMP协议 概念：ICMP的全称是 Internet Control Message Protocol ，它是一种“错误侦测与回报机制”，不传输用户数据，其目的就是让我们能够检测网路的连线状况。ICMP数据包由一个8字节长的包头，其中前四个字节是固定格式，包括8位类型字段、8位代码字段个16位校验和；后4个字节根据ICMP类型的不同而取不同的值； 作用： 侦测远端主机是否存在 建立及维护路由资料 重导数据传送路径 数据流量控制 Internet 控制报文协议，负责发送消息，报告错误；属于TCP/IP协议族；主要用在主机和路由器之间，ICMP提供移动的出错报告信息，但是他的功能是报告问题而不是纠正问题，他将出错的报文返回发送方，纠正问题的功能由发送方完成；发送方根据ICMP提供的错误类型来确定如何才能更好的重新发送失败的数据包； 应用：Ping命令其实就是ICMP协议的工作过程；Tracert命令，跟踪路由的命令也是基于ICMP协议的； 23.组播和广播的概念，IGMP的用途 组播：主机之间的通讯模式，也就是加入了同一个组的主机可以接收到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。 广播： 是指在IP子网内广播数据包，所有在子网内部的主机都将收到这些数据包。广播意味着网络向子网每一个主机都投递一份数据包，不论这些主机是否乐于接收该数据包。所以广播的使用范围非常小，只在本地子网内有效，通过路由器和网络设备控制广播传输。组播协议与现在广泛使用的单播协议的不同之处在于，一个主机用单播协议向n个主机发送相同的数据时，发送主机需要分别向n个主机发送，共发送n次。一个主机用组播协议向n个主机发送相同的数据时，只要发送1次，其数据由网络中的路由器和交换机逐级进行复制并发送给各个接收方，这样既节省服务器资源也节省网络主干的带宽资源。 IGMP（Internet Group Management Protocol）的用途 它用来在ip主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。组播路由器不需要保存所有主机的成员关系，它只是通过IGMP协议了解每个接口连接的网段上是否存在某个组播组的组成员，而主机只需要保存自己加入了哪些组播组。简而言之，IGMP协议是让连接在本地局域网上的组播路由器知道本局域网上是否有主机上的某个进程参加或退出了某个组播组。 环回地址/广播地址 环回地址：127.0.0.1，通常被称为本地回环地址(Loop back address)，不属于任何一个有类别地址类。它代表设备的本地虚拟接口，所以默认被看作是永远不会宕掉的接口。 作用： a.一是测试本机的网络配置，能PING通127.0.0.1说明本机的网卡和IP协议安装都没有问题； b.某些SERVER/CLIENT的应用程序在运行时需调用服务器上的资源，一般要指定SERVER的IP地址，但当该程序要在同一台机器上运行而没有别的SERVER时就可以把SERVER的资源装在本机，SERVER的IP地址设为127.0.0.1同样也可以运行。 广播地址：是专门用于同时向网络中所有工作站进行发送的一个地址。在使用TCP/IP协议的网络中，主机标识段host ID为全1的IP地址为广播地址，广播的分组传送给host ID段所涉及的所有计算机。例如，对于10.1.1.0 （255.255.255.0 ）网段，其广播地址为10.1.1.255（255 即为2 进制的11111111 ），当发出一个目的地址为10.1.1.255 的分组（封包）时，它将被分发给该网段上的所有计算机。 24.DNS的概念，用途，DNS查询的实现算法 DNS用途：DNS是由解析器以及域名服务器组成的。域名服务器是指保存有该网络中所有主机的域名和对应IP地址，并具有将域名转换为IP地址功能的服务器。DNS使用TCP与UDP端口号都是53，主要使用UDP，服务器之间备份使用TCP。 域名到IP地址的解析过程的要点如下： a.当某一个应用进程需要主机名解析为IP地址时，该应用进程就调用解析程序，并成为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器。 b.本地域名服务器在查找域名后，把对应的IP地址放在回答报文中返回。应用进程获得目的主机的IP地址后即可进行通信。 c.若本地域名服务器不能回答该请求，则此域名服务器就暂时成为DNS中的另一个客户，并向其他域名服务器发出查询请求。这种过程直至找到能够回答该请求的域名服务器为止。 DNS查询算法 主机向本地域名服务器的查询一般都是采用递归查询，即如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步的查询。 因此，递归查询返回的查询结果或是所要查询的IP地址，或是报错。 本地域名服务器向根服务器的查询通常采用迭代查询，即当根域名服务器收到本地域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器“下一次应向哪个域名服务器进行查询”。然后让本地域名服务器进行后续的查询。根域名服务器通常把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪一个权限域名服务器进行查询。本地域名服务器就这样进行迭代查询。 25.TCP的流量控制 1.利用滑动窗口实现流量控制 如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。设A向B发送数据，在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。TCP连接建立时的窗口协商过程在图中没有显示出来。再设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到rwnd=300 ，第二次又减到了rwnd=100 ，最后减到rwnd=0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了ACK=1 ，只有在ACK=1时确认号字段才有意义。TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 2.必须考虑传输速率 可以用不同的机制来控制TCP报文段的发送时机。如： a.TCP维持一个变量，它等于最大报文段长度MSS。只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。 b.由发送方的应用进程指明要求发送报文段，即TCP支持的推送( push )操作。 c.发送方的一个计时器期限到了，这时就把已有的缓存数据装入报文段(但长度不能超过MSS)发送出去。 3.Nagle算法 若发送应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方接收对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段再发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。Nagle算法还规定：当到达的数据已达到 发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。 4.糊涂窗口综合证：TCP接收方的缓存已满，而交互式的应用进程一次只从接收缓存中读取1字节（这样就使接收缓存空间仅腾出1字节），然后向发送方发送确认，并把窗口设置为1个字节（但发送的数据报为40字节的的话）。接收，发送方又发来1个字节的数据（发送方的IP数据报是41字节）。接收方发回确认，仍然将窗口设置为1个字节。这样，网络的效率很低。要解决这个问题，可让接收方等待一段时间，使得或者接收缓存已有足够空间容纳一个最长的报文段，或者等到接收方缓存已有一半空闲的空间。只要出现这两种情况，接收方就发回确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据报积累成足够大的报文段，或达到接收方缓存的空间的一半大小。 26.TCP拥塞控制 1.拥塞：拥塞：即对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，整个网络的吞吐量随之负荷的增大而下降。拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。流量控制：指点对点通信量的控制，是端到端正的问题。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。拥塞控制代价：需要获得网络内部流量分布的信息。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外的开销。拥塞控制还需要将一些资源分配给各个用户单独使用，使得网络资源不能更好地实现共享。 2.几种拥塞控制方法 慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。 3.慢开始和拥塞避免 发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞。发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法：当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd ，可以使分组注入到网络的速率更加合理。每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。另外，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（如何设置ssthresh）。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 拥塞避免算法：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。 a.当TCP连接进行初始化时，把拥塞窗口cwnd置为1。前面已说过，为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即 cwnd = 16 。 b.在执行慢开始算法时，拥塞窗口 cwnd 的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就把拥塞窗口值另1，然后开始下一轮的传输（图中横坐标为传输轮次）。因此拥塞窗口cwnd随着传输轮次按指数规律增长。 当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞控制算法，拥塞窗口按线性规律增长。 c.假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。 当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过一个往返时间增加一个MSS的大小。强调：“拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。 4.快重传和快恢复 快重传：如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文段在网络中的某处被丢弃。这时，TCP马上把拥塞窗口 cwnd 减小到1，并执行慢开始算法，同时把慢开始门限值ssthresh减半。这是不使用快重传的情况。快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。显然，接收方不能确认M4，因为M4是收到的失序报文段。根据可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了接收方的四个对M2的确认，其中后三个都是重复确认。快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必继续等待M3设置的重传计时器到期。由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复： a.当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意：接下去不执行慢开始算法。 b.由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 5.停止等待协议和滑动窗口协议 停止等待协议：是tcp保证传输可靠的重要途径，”停止等待”就是指发送完一个分组就停止发送，等待对方的确认，只有对方确认过，才发送下一个分组. 滑动窗口协议：之所以叫滑动窗口协议，是因为窗口是不断向前走的，该协议允许发送方在停止并等待确认前发送多个数据分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输，还可以控制流量的问题。滑动窗口协议中，允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它受限于在流水线 中为未确认的分组数不能超过某个最大允许数N。滑动窗口协议是TCP使用的一种流量控制方法，此协议能够加速数据的传输。 只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。收发两端的窗口按照以上规律不断地向前滑动，因此这种协议称为滑动窗口协议。当发送窗口和接收窗口的大小都等于1时，就是停止等待协议。 27.TIME_WAIT状态及存在原因 客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口状态为TIME_WAIT； 主动关闭的Socket端会进入TIME_WAIT状态，并且持续2MSL时间长度，MSL就是maximum segment lifetime(最大分节生命期）；这是一个IP数据包能在互联网上生存的最长时间，超过这个时间将在网络中消失。MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒，因而，TIME_WAIT状态一般维持在1-4分钟。 主动关闭的一方在发送最后一个ack后就会进入TIME_WAIT状态停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。 TIME_WAIT状态存在的理由： a.防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失） b.可靠的关闭TCP连接:在进行关闭连接四路握手协议时，最后的ACK是由主动关闭端发出的，如果这个最终的ACK丢失，服务器将重发最终的FIN，因此客户端必须维护状态信息允 许它重发最终的ACK。如果不维持这个状态信息，那么客户端将响应RST分节，服务器将此分节解释成一个错误。因而，要实现TCP全双工连接的正常终止，必须处理终止序列四个分节中任何一个分节的丢失情况，主动关闭 的客户端必须维持状态信息进入TIME_WAIT状态。 28.Http2.0和Http1.0区别 Http2.0采用二进制格式非文本格式； Http2.0是完全多路复用的，非有序并阻塞的只需要一个连接即可实现并行； 使用报头压缩，降低了开销； Http2.0让服务器可以将响应主动推送到客户端缓存中。 29.SMTP和POP3协议的区别 SMTP用来发生邮件的，端口号25；POP3用来接收邮件的，端口号110，使用TCP协议。 参考博客 参考博客]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>TCP/IP协议栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode刷题记录]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2FLeetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[递归方法和循环方法的对比 递归方法代码实现比较简洁，但是性能不如循环方法，还有可能出现栈溢出的问题。一般情况下优先考虑递归方法来实现！ 搜索路径的题目：一般使用回溯法，回溯法很适合使用递归方法的代码来实现！当要求不能使用递归实现的时候，考虑使用栈模拟递归的过程 求某个问题的最优解时，并且该问题可以拆分为多个子问题时：可以尝试使用动态规划的方法！在使用自上而下的递归思路去分析动态规划问题时，会发现子问题之间存在重叠的更小的子问题。为了避免不必要的重复计算，使用自下而上的循环代码来实现，即把子问题的最优解先计算出来并用数组保存下来，然后基于子问题的解计算大问题的解。 特殊情况：在分解子问题的时候存在某个特殊的选择，采用这个特殊的选择将一定那个得到最优解，则此题目可能适用于贪心算法！ 典型题目的解题思路：在一个已经排好序的数组中查找一个数字或者统计某个数字出现的次数，可以尝试使用二分查找算法！ Q1:给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。注意：答案中不可以包含重复的三元组。 自己写的：暴力解决，时间复杂度太大 12345678910111213141516171819202122class Solution(object): def threeSum(self, nums): nums.sort() result = [] temp = [] for i in range(len(nums)): for j in range(i + 1, len(nums)): for k in range(j + 1, len(nums)): if nums[i] + nums[j] + nums[k] == 0: result.append([nums[i], nums[j], nums[k]]) for i in range(len(result)): if result[i] not in temp: temp.append(result[i]) else: continue return tempif __name__ == "__main__": s = Solution() result = s.threeSum([-1, 0, 1, 2, -1, -4, 3, -5, -2, -3]) print(result) 网上大神的解法： 1234567891011121314151617181920212223242526272829303132333435class Solution: def threeSum(self, nums): # 存储结果列表 result = [] # 对nums列表进行排序，无返回值，排序直接改变nums顺序 nums.sort() for i in range(len(nums)): # 因为是升序排列，如果排序后第一个数都大于0，则跳出循环，不可能有为0的三数之和 if nums[i] &gt; 0: break # 排序后相邻两数如果相等，则跳出当前循环继续下一次循环，相同的数只需要计算一次 if i &gt; 0 and nums[i] == nums[i-1]: continue # 记录i的下一个位置 j = i + 1 # 最后一个元素的位置 k = len(nums) - 1 while j &lt; k: # 判断三数之和是否为0 if nums[j] + nums[k] == -nums[i]: # 把结果加入数组中 result.append([nums[i], nums[j], nums[k]]) # 判断j相邻元素是否相等，有的话跳过这个 while j &lt; k and nums[j] == nums[j+1]: j += 1 # 判断后面k的相邻元素是否相等，是的话跳过 while j &lt; k and nums[k] == nums[k-1]: k -= 1 # 没有相等则j+1，k-1，缩小范围 j += 1 k -= 1 # 小于-nums[i]的话还能往后取 elif nums[j] + nums[k] &lt; -nums[i]: j += 1 else: k -= 1 return result Q2:见下图 A2： 123456789101112class Solution:def romanToInt(self, s: str) -&gt; int: d = &#123;'M': 1000,'D': 500 ,'C': 100,'L': 50,'X': 10,'V': 5,'I': 1&#125; result = 0 s_len = len(s) for i in range(s_len-1): if d[s[i]] &lt; d[s[i+1]]: result -= d[s[i]] else: result += d[s[i]] result += d[s[-1]] return result Q3:编写一个函数来查找字符串数组中的最长公共前缀,如果不存在公共前缀，返回空字符串 “”。 A3：仅仅比较最长与最短的字符串，如果存在相同的前缀就返回；不存在就返回一个空字符串。重要的是如何从两个字符串中取相同位置的字符进行比较。 123456789101112131415def longest_str(strs): s1 = min(strs) # 最短字符串 s2 = max(strs) # 最长字符串 for i, v in enumerate(s1): if v != s2[i]: return s2[:i] # 当第一个字符就不相等时,返回s2[:0]=[],执行下面的if语句 if not strs: return ""if __name__ == "__main__": strs = ["dog", "racecar", "car"] strs1 = ["flower", "flow", "flight"] result = longest_str(strs) result1 = longest_str(strs1) print(result) print(result1) Q4:给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。有效字符串需满足：左括号必须用相同类型的右括号闭合;左括号必须以正确的顺序闭合;注意空字符串可被认为是有效字符串 A4:只有完整出现[],{},()的情况才会返回true,同时空字符串也被任何是有效字符串,所以,用空格进行替换[],{},()，然后比较替换后的结果是否是空字符串，不是的话说明不是有效字符串。 123456def is_Valid(s): while("&#123;&#125;" in s or "()" in s or "[]" in s): s = s.replace("&#123;&#125;", "") s = s.replace("()", "") s = s.replace("[]", "") return s == "" Q5:将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 例如，输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4；输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 A5: 1234567891011121314151617181920struct ListNode&#123; int val; struct ListNode *next;&#125;; // 借助归并排序的思路，递归方法实现struct ListNode* mergeTwoLists(struct ListNode *l1, struct ListNode *l2)&#123; struct ListNode *p; if (!l1) retutn l2; if (!l2) return l1; if(l1-&gt;val &lt; l2-&gt;val)&#123; // 将两个链表中小的元素放在新的链表中，用指针p指向它 p = l1; p-&gt;next = mergeTwoLists(l1-&gt;next, l2); &#125;else&#123; p = l2; p-&gt;next = mergeTwoLists(l2-&gt;next,l1); &#125; return p;&#125; Q6:给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 A6: 12345678910int removeDuplicates(int *nums, int numsSize)&#123; if (numsSize &lt; 2) return numsSize; int i, j=0; for (i=1;i&lt;numsSize;i++)&#123; if(nums[j] != nums[i]) nums[++j]=nums[i]; &#125; return j+1;&#125; Q7:给定一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val的元素，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 A7: 12345678int removeElement(int* nums, int numsSize, int val)&#123; int i,j=0; for (i=0;i &lt; numsSize;i++)&#123; if(nums[i] != val) nums[j++] = nums[i]; &#125; return j;&#125; Q8:统计小于非负整数n的质数的个数。例如。n=10,则输出小于10的质数个数是4个，具体是2, 3, 5, 7。 A8:使用厄拉多塞筛法：首先从数字2开始，依次删除2的倍数；接着从3开始，依次删除3的倍数，然后从5开始(因为4是2的倍数，已经被删除了)，依次删除5的倍数。一直循环上面的步骤的n-1即可，然后统计最后剩余的数的个数，即质数的个数。 123456789101112class Solution: def countPrimes(self, n: int) -&gt; int: if n&lt;=2: return 0 isPrime = [1] * n # 生成一个全为1的列表 isPrime[0], isPrime[1] = 0, 0 for i in range(2, int(n**0.5)+1): # 质数：除1和本身外，没有其他的因数。如果有其他因数p,则p*p = n,即p = n**0.5 if isPrime[i] == 1: # 如果i是质数 isPrime[2*i:n:i] = [0] * len(isPrime[i*2:n:i]) # 将i的倍数置为0 # print(i, isPrime) return sum(isPrime) Q9：给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。最高位数字存放在数组的首位， 数组中每个元素只存储一个数字。你可以假设除了整数 0 之外，这个整数不会以零开头。 A9：思路是如果最后一位不是9，而是0到8，就执行普通的最后一位的加1操作；如果最后一位是9，就要考虑向前面一位产生进位标志1，这是此题的关键！ 12345678910111213class Solution: def plusOne(self, digits: List[int]) -&gt; List[int]: flag = False for i in range(len(digits)-1, -1, -1): # 反向遍历list(起点，终点,步长) if digits[i] is 9: flag = True digits[i] = 0 else: digits[i] += 1 return digits if flag: # 防止出现list=[9]的情况 digits.insert(0, 1) return digits Q10:删除链表中等于给定值 val 的所有节点。示例:输入: 1-&gt;2-&gt;6-&gt;3-&gt;4-&gt;5-&gt;6, val = 6 输出: 1-&gt;2-&gt;3-&gt;4-&gt;5 A10: 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeElements(ListNode* head, int val) &#123; // 空链表的情况 if(!head)&#123; return nullptr; &#125; // 删除的节点是头节点 while(head-&gt;val == val)&#123; head = head-&gt;next; if(!head)&#123; return nullptr; &#125; &#125; ListNode* pNode = head; ListNode* pCur = head-&gt;next; // 删除的是中间的某个节点 while(pCur)&#123; if(pCur-&gt;val == val)&#123; pNode-&gt;next = pCur-&gt;next; pCur = pCur-&gt;next; &#125;else&#123; pNode = pCur; pCur = pCur-&gt;next; &#125; &#125; return head; &#125;&#125;; Q11：编写一个算法来判断一个数是不是“快乐数”。一个“快乐数”定义为：对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程直到这个数变为 1，也可能是无限循环但始终变不到 1。如果可以变为 1，那么这个数就是快乐数。 A11: 123456789101112131415161718192021222324252627class Solution&#123;public: bool isHappy(int n)&#123; int sum = 0; // 1到9中只有1和7符合快乐数的定义！ if(n == 1 || n==7)&#123; return true; &#125; // 其余不符合的情况，都不是快乐数! if(n&lt;10)&#123; return false; &#125; sum = isHappyCore(n); return isHappy(sum); // 递归判断 &#125;private: int isHappyCore(int n)&#123; // 下面的代码是取一个整数的各个位置上的数，具有一般性，记忆！ int sum = 0 while(n &gt; 0)&#123; int mod = n % 10; sum += mod * nod; n /= 10; &#125; return sum; &#125;&#125; Q12:给定一个排序链表，删除所有重复的元素，使得每个元素只出现一次。 A12： 123456789101112131415161718192021222324252627282930313233/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; if(!head || head-&gt;next == nullptr)&#123; return head; &#125; ListNode* pNode = head; // 慢指针 ListNode* pCur = head-&gt;next; // 快指针 while(pNode-&gt;next != nullptr)&#123; if(pNode-&gt;val == pCur-&gt;val)&#123; // 找到重复元素 if(pCur-&gt;next == nullptr)&#123; // 快指针后面若没有元素直接剔除 pNode-&gt;next = nullptr; &#125;else&#123; // 快指针后有元素 pNode-&gt;next = pCur-&gt;next; pCur = pCur-&gt;next; &#125; &#125;else&#123; //元素不相等 pNode = pNode-&gt;next; pCur = pCur-&gt;next; &#125; &#125; return head; &#125;&#125;; Q13：给定两个二叉树，编写一个函数来检验它们是否相同。如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。 A13： 123456789101112131415161718192021222324/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool isSameTree(TreeNode* p, TreeNode* q) &#123; if(p==nullptr &amp;&amp; q==nullptr)&#123; return true; &#125; if(p != nullptr &amp;&amp; q != nullptr &amp;&amp; p-&gt;val == q-&gt;val)&#123; return isSameTree(p-&gt;left, q-&gt;left) &amp;&amp; isSameTree(p-&gt;right, q-&gt;right); // 在左右子树上递归实现！ &#125;else&#123; return false; &#125; &#125;&#125;; Q14：给定一个二叉树，检查它是否是镜像对称的。例如，二叉树 [1,2,2,3,4,4,3] 是对称的。 A14： 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */// 如果是对称二叉树，则从左子树开始遍历与从右子树开始遍历时，遍历的结果都相同！class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; return isMirror(root,root); // 递归实现 &#125; bool isMirror(TreeNode* root1, TreeNode* root2)&#123; if(root1 == nullptr &amp;&amp; root2 == nullptr)&#123; return true; &#125; if(root1 == nullptr || root2 == nullptr)&#123; return false; &#125; return (root1-&gt;val == root2-&gt;val) &amp;&amp; isMirror(root1-&gt;left, root2-&gt;right) &amp;&amp; isMirror(root1-&gt;right, root2-&gt;left); &#125;&#125;; A15：给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 Q15： 123456789101112131415class Solution: def majorityElement(self, nums: List[int]) -&gt; int: # nums.sort() # nums_len = len(nums) # return nums[nums_len // 2] # 返回中间的数 candidate = None # 摩尔投票法 count = 0 for num in nums: if num == candidate: # 如果数组中的下一个元素num与candidate相同，就不会碰撞，此时count加1 count += 1 elif count &gt; 0: # 如果数组中的下一个元素num与candidate不同，就会发生碰撞，此时count减1，candidate维持上一次的数据 count -= 1 else: candidate, count = num, 1 # 第一次进入循环，candidate是第一个元素，count加1 return candidate A16：实现一个函数，将字符串中的每个空格替换成%20。例如，输入“hello world.”，则输出”hello%20world.” Q16：解题思路：观察出空格替换后原始字符串变长的关系。在原始字符串的基础上进行修改，利用观察出的关系，使用两个指针从后向前移动将字符串从原始字符串复制到新的字符串中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;// 解题思路：在原始字符串的基础上进行修改，注意原始字符串有足够的空间。使用两个指针，发现空格数量与原始字符串增加的长度关系！class Solution&#123;public: void ReplaceSPace(char* str, int len)&#123; if(str == nullptr || len &lt;= 0)&#123; return; &#125; int original_len = 0; int number_blank = 0; int i=0; // 遍历原始字符串，统计空格的数目 while(str[i] != '\0')&#123; ++original_len; if(str[i] == ' ')&#123; ++number_blank; &#125; ++i; &#125; int new_len = original_len + 2 * number_blank; if(new_len &gt; len)&#123; return; &#125; int original_index = original_len; int new_index = new_len; while(original_index &gt;= 0 &amp;&amp; new_index &gt; original_index)&#123; if(str[original_index] == ' ')&#123; str[new_index--] = '0'; str[new_index--] = '2'; str[new_index--] = '%'; &#125;else&#123; str[new_index--] = str[original_index]; &#125; original_index--; &#125; &#125;&#125;; Q17：单向链表的基础操作：在单向链表的末尾插入一个节点和找到第一个值为value的节点并将其删除 A17：注意不要忘记释放在堆空间上申请的动态内存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;using namespace std;struct ListNode&#123; ListNode* m_pNext; int m_pVal;&#125;;// 在链表的末尾插入一个节点void AddNodeToTail(ListNode** pHead, int value)&#123; // 为新插入的节点分配空间 ListNode* pNew = new ListNode(); pNew-&gt;m_pNext = nullptr; pNew-&gt;m_pVal = value; if(pHead == nullptr)&#123; // 空链表 *pHead = pNew; &#125; else&#123; ListNode* pNode = *pHead; while(pNode-&gt;m_pNext != nullptr)&#123; pNode = pNode-&gt;m_pNext; &#125; pNode-&gt;m_pNext = pNew; &#125;&#125;// 找到第一个含某值value的节点并删除此节点void RemoveNode(ListNode** pHead, int value)&#123; if(pHead == nullptr || *pHead == nullptr)&#123; return; &#125; ListNode* pToDeleted = nullptr; if((*pHead)-&gt;m_pVal == value)&#123; // 头节点就是要删除的那个节点 pToDeleted = *pHead; *pHead = (*pHead)-&gt;m_pNext; &#125;else&#123; // 头节点不是要删除的那个节点 ListNode* pNode = *pHead; while(pNode-&gt;m_pNext != nullptr &amp;&amp; pNode-&gt;m_pNext-&gt;m_pVal != value)&#123; // 头节点不是要删除的那个节点，后面的节点也没有出现value，则一直向后查找 pNode = pNode-&gt;m_pNext; &#125; if(pNode-&gt;m_pNext != nullptr &amp;&amp; pNode-&gt;m_pNext-&gt;m_pVal == value)&#123; // 头节点不是要删除的那个节点,后面的节点找到了value，则执行删除操作 pToDeleted = pNode-&gt;m_pNext; pNode-&gt;m_pNext = pNode-&gt;m_pNext-&gt;m_pNext; &#125; &#125; if(pToDeleted != nullptr)&#123; delete pToDeleted; pToDeleted = nullptr; &#125;&#125; Q18：从尾到头反向打印出单向链表 A18：因为单向链表方向不能反过来，如果将指针反过来来实现改变单向链表的方向。但是，这会改变单向链表的数据结构，故在不改变数据结构的基础上，使用栈来实现！1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;stack&gt;using namespace std;struct ListNode&#123; ListNode* m_pNext; int m_pVal;&#125;;// 利用栈这个数据结构，后进先出！因为单向链表方向不能反过来，如果将指针反过来，从而实现改变链表的方向，但是这会改变链表的数据结构，故在不改变数据结构的基础上，使用栈来实现class Solution&#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* pHead)&#123; stack&lt;int&gt; nodes; vector&lt;int&gt; result; ListNode* pNode = pHead; while(pNode != nullptr)&#123; nodes.push(pNode-&gt;m_pVal); pNode = pNode-&gt;m_pNext; &#125; while(!nodes.empty())&#123; result.push_back(nodes.top()); nodes.pop(); &#125; return result; &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络中的注意力机制总结及PyTorch实战]]></title>
    <url>%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%80%BB%E7%BB%93%E5%8F%8APyTorch%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[0.概述 当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相关，其余都无关的。为了减小神经网络的计算代价，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入到神经网络中。 1.Attention机制基础知识 用$X=\left[\mathbf{x}{1}, \cdots, \mathbf{x}{N}\right]$表示N组输入信息，其中每个向量$\mathbf{x}_{i}, i \in[1, N]$都表示一组输入信息。为了节省计算资源，不需要将所有的信息都输入到神经网络中，只需要从X中选择一些和任务相关的信息。注意力机制的计算可以分为两步： (1)在所有输入信息上计算注意力分布； (2)根据注意力分布来计算输入信息的加权平均 1.1 注意力分布 为了从N个输入向量$\left[\mathbf{x}{1}, \cdots, \mathbf{x}{N}\right]$中选择出与某个特定任务相关的信息，需要引入一个和任务相关的表示，称为查询向量q，并通过一个打分函数来计算每个输入向量和查询向量之间的相关性。 给定一个和任务相关的查询向量q，用注意力变量$z \in[1, N]$来表示被选择信息的索引位置，即z=i表示选择了第i个输入向量。为了方便计算，下面首先介绍Soft Attention注意力机制。首先计算在给定q和X下，选择第i个输入向量的概率$\alpha_{i}$ \begin{aligned} \alpha_{i} &=p(z=i | X, \mathbf{q}) \\ &=\operatorname{softmax}\left(s\left(\mathbf{x}_{i}, \mathbf{q}\right)\right) \\ &=\frac{\exp \left(s\left(\mathbf{x}_{i}, \mathbf{q}\right)\right)}{\sum_{j=1}^{N} \exp \left(s\left(\mathbf{x}_{j}, \mathbf{q}\right)\right)} \end{aligned}其中$\alpha{i}$称为注意力分布，$S\left(\mathbf{x}{i}, \mathbf{q}\right)$是注意力打分函数，可以使用下面的几种方法来计算： 加性模型 $s\left(\mathbf{x}{i}, \mathbf{q}\right)=\mathbf{v}^{\mathrm{T}} \tanh \left(W \mathbf{x}{i}+U \mathbf{q}\right)$ 点积模型 $s\left(\mathbf{x}{i}, \mathbf{q}\right)=\mathbf{x}{i}^{\mathrm{T}} \mathbf{q}$ 缩放点积模型 $s\left(\mathbf{x}{i}, \mathbf{q}\right)=\frac{\mathbf{x}{i}^{\mathrm{T}} \mathbf{q}}{\sqrt{d}}$ 双线性模型 $s\left(\mathbf{x}{i}, \mathbf{q}\right)=\mathbf{x}{i}^{\mathrm{T}} W \mathbf{q}$ 上式中W、U、v是可学习的参数，d是输入向量的维度。理论上，加性模型和点积模型的复杂度差不多，但是点积模型在实现上可以更好地利用矩阵乘积，从而计算效率更高。但当输入向量的维度d比较高，点积模型的值通常有较大的方差，从而导致softmax函数的梯度比较小。因此，缩放点积模型可以很好地解决这个问题。双线性模型可以看做是一种泛化的点积模型。假设 $s\left(\mathbf{x}{i}, \mathbf{q}\right)=\mathbf{x}{i}^{\mathrm{T}} W \mathbf{q}$中$W=U^{\mathrm{T}} V$，则双线性模型可以写为$s\left(\mathbf{x}{i}, \mathbf{q}\right)=\mathbf{x}{i}^{\mathrm{T}} U^{\mathrm{T}} V \mathbf{q}=(U \mathbf{x})^{\mathrm{T}}(V \mathbf{q})$即分别对x和q进行线性变换后计算点积。相比点积模型，双线性模型在计算相似度时引入了非对称性。 1.2 加权平均 注意力分布$\alpha_{i}$可以解释为在给定任务相关的查询q时，第i个输入向量受注意的程度。下面采用一种软性的信息选择机制对输入信息进行汇总。 \begin{aligned} \operatorname{att}(X, \mathbf{q}) &=\sum_{i=1}^{N} \alpha_{i} \mathbf{x}_{i} \\ &=\mathbb{E}_{z \sim p(z | X, \mathbf{q})}\left[\mathbf{x}_{z}\right] \end{aligned}上式称为软注意力机制(Soft Attention Mechanism)。下图给出了软注意力机制的示例图： 2.其他类型的注意力机制 2.1 硬注意力机制 上面的公式$\mathbb{E}{z \sim p(z | X, \mathbf{q})}\left[\mathbf{x}{z}\right]$提到的是软注意力机制，其选择的信息是所有输入向量在注意力分布下的期望。此外还有一种注意力是只关注到某一个输入向量，叫做硬注意力机制(Hard Attention Mechanism)。硬注意力机制有两种方法可以实现： (1)选择最高概率的一个输入向量，即 \operatorname{att}(X, \mathbf{q})=\mathbf{x}_{j}其中j为概率最大的输入向量的下标，即\begin{array}{c}{j=\arg \max _{i=1}^{N} a_{i}}\end{array} (2)通过在注意力分布上随机采样的方式实现 硬注意力的一个缺点是基于最大采样或随机采样的方式来选择信息。因此最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用反向传播算法进行训练。为了使用反向传播算法进行训练，一般使用软注意力机制。 2.2 键值对注意力 可以使用键值对格式来表示输入信息，其中键用来计算注意力分布$\alpha{i}$，值用来计算聚合信息。用$(K, V)=\left[\left(\mathbf{k}{1}, \mathbf{v}{1}\right), \cdots,\left(\mathbf{k}{N}, \mathbf{v}_{N}\right)\right]$来表示N组输入信息，给定任务相关的查询向量q时，注意力函数为： \begin{aligned} \operatorname{att}((K, V), \mathbf{q}) &=\sum_{i=1}^{N} \alpha_{i} \mathbf{v}_{i} \\ &=\sum_{i=1}^{N} \frac{\exp \left(s\left(\mathbf{k}_{i}, \mathbf{q}\right)\right)}{\sum_{j} \exp \left(s\left(\mathbf{k}_{j}, \mathbf{q}\right)\right)} \mathbf{v}_{i} \end{aligned}其中$s\left(\mathbf{k}_{i}, \mathbf{q}\right)$是打分函数，1.2节的图中给出了键值对注意力机制的示意图。当K=V时，键值对模式等于普通模式的注意力机制。 2.3 多头注意力 多头注意力(Multi-head Attention)是利用多个查询 $Q=\left[\mathbf{q}{1}, \cdots, \mathbf{q}{M}\right]$来平行计算从输入信息中选取多组信息。每个注意 力关注输入信息的不同部分。 \operatorname{att}((K, V), Q)=\operatorname{att}\left((K, V), \mathbf{q}_{1}\right) \oplus \cdots \oplus \operatorname{att}\left((K, V), \mathbf{q}_{M}\right)其中⊕表示向量拼接。 2.4 自注意力模型(Self Attention) 当使用神经网络来处理一个变化长度的向量序列时，通过可以使用卷积网络或循环网络进行编码来得到一个相同长度的输出向量序列，如下图所示： 基于卷积或循环网络的序列编码都是可以看做是一种局部的编码方式，只建模了输入信息的局部依赖关系。虽然循环网络理论上可以建立长距离依赖关系，但是由于信息传递的容量以及梯度消失问题，实际上也只能建立短距离依赖关系。 如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互；另一种方法是使用全连接网络。全连接网络是一种非常直接的建模远距离依赖的模型，但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时，就可以利用注意力机制来“动态”地生成不同连接的权重，这就是自注意力模型（Self-Attention Model）。 假设输入序列为$X=\left[\mathbf{x}{1}, \cdots, \mathbf{x}{N}\right] \in \mathbb{R}^{d{1} \times N}$，输出序列为$H=\left[\mathbf{h}{1}, \cdots, \mathbf{h}{N}\right] \in \mathbb{R}^{d{2} \times N}$，则可以通过线性变换得到三组向量序列： \begin{aligned} Q &=W_{Q} X \in \mathbb{R}^{d_{3} \times N} \\ K &=W_{K} X \in \mathbb{R}^{d_{3} \times N} \\ V &=W_{V} X \in \mathbb{R}^{d_{2} \times N} \end{aligned}其中，Q、K、V分别为查询向量序列，键向量序列、值向量序列，$W{Q} \in \mathbb{R}^{d{3} \times d{1}}$、$W{K} \in \mathbb{R}^{d{3} \times d{1}}$、$W{V} \in \mathbb{R}^{d{2} \times d{1}}$分别表示可学习的参数矩阵。根据$\operatorname{att}((K, V), \mathbf{q})=\sum{i=1}^{N} \alpha{i} \mathbf{v}{i}$，可以得到输出向量$\mathbf{h}{i}$：$\mathbf{h}{i}=\operatorname{att}\left((K, V), \mathbf{q}{i}\right)=\sum{j=1}^{N} \alpha{i j} \mathbf{v}{j}=\sum{j=1}^{N} \operatorname{softmax}\left(s\left(\mathbf{k}{j}, \mathbf{q}{i}\right)\right) \mathbf{v}{j}$其中，$i, j \in[1, N]$为输出和输入向量序列的位置，连接权重$\alpha_{i j}$由注意力机制动态生成。如果使用缩放点积来作为注意力打分函数，输出向量序列可以写为： H=V \operatorname{softmax}\left(\frac{K^{\mathrm{T}} Q}{\sqrt{d_{3}}}\right)其中softmax函数为按列进行归一化的函数。 下图给出了全连接模型和自注意力模型的对比，其中实线表示可学习的权重，虚线表示动态生成的权重。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列。 自注意力模型可以作为神经网络中的一层来使用，既可以用来替换卷积层和循环层，也可以和它们一起交替使用(例如输入向量X可以是卷积层或循环层的输出)。自注意模型计算的权重$\alpha{i j}$只依赖于$\mathbf{q}{i}$和$\mathbf{k}_{j}$的相关性，从而忽略了输入信息的位置信息。因此，在单独使用时，自注意模型一般需要加入位置编码信息来进行修正。 3.实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明 利用机器翻译中的经典网络结构Seq2Seq(具体结构见参考资料中的文献)，其中包含Encoder编码网络将输入的法语句子进行编码，然后输入到Decoder解码网络进行解码，输出期望得到的英文句子。整个网络的结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447from __future__ import unicode_literals, print_function, divisionfrom io import openimport unicodedataimport stringimport reimport randomimport torchimport torch.nn as nnfrom torch import optimimport torch.nn.functional as Fdevice = torch.device("cuda" if torch.cuda.is_available() else "cpu")# 将法语翻译成英语SOS_token = 0 # 开始的标注EOS_token = 1 # 结束的标注# 辅助类class Lang: def __init__(self, name): self.name = name self.word2index = &#123;&#125; # word----&gt;index self.index2word = &#123;0: "SOS", 1: "EOS"&#125; # index----&gt;word self.word2count = &#123;&#125; # 稍后用来替换稀有单词，统计每个单词出现的次数 self.n_words = 2 # 统计单词总数 def addSentence(self, sentence): for word in sentence.split(" "): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.n_words self.word2count[word] = 1 self.index2word[self.n_words] = word self.n_words += 1 else: self.word2count[word] += 1 # Turn a Unicode string to plain ASCIIdef unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' )# 小写，修剪和删除非字母字符def normalizeString(s): s = unicodeToAscii(s.lower().strip()) s = re.sub(r"([.!?])", r" \1", s) s = re.sub(r"[^a-zA-Z.!?]+", r" ", s) return s# 加载文件def readLangs(lang1, lang2, reverse=False): print("Reading lines.......") # 读取文件并进行划分成行 lines = open(r"E://DeepLearning//jupyter_code//dataset//corpus//translation_data//%s-%s.txt" % (lang1, lang2), encoding='utf-8').\ read().strip().split("\n") # 将每行切成一组pairs pairs = [[normalizeString(s) for s in l.split("\t")] for l in lines] # 将其他语言翻译成英语 if reverse: pairs = [list(reversed(p)) for p in pairs] input_lang = Lang(lang2) output_lang = Lang(lang1) else: input_lang = Lang(lang1) output_lang = Lang(lang2) return input_lang, output_lang, pairs# 由于有很多例句，为了能快速训练，我们会将数据集修剪成相对简短的句子。这里最大长度是10个单词（包括结束标点符号）MAX_LENGTH = 10# 英语前缀eng_prefixes = ( "i am ", "i m ", "he is", "he s ", "she is", "she s ", "you are", "you re ", "we are", "we re ", "they are", "they re ")def filterPair(p): return len(p[0].split(' ')) &lt; MAX_LENGTH and \ len(p[1].split(' ')) &lt; MAX_LENGTH and \ p[1].startswith(eng_prefixes)def filterPairs(pairs): return [pair for pair in pairs if filterPair(pair)]def prepareData(lang1, lang2, reverse=False): input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) print("Read %s sentence pairs" % len(pairs)) pairs = filterPairs(pairs) print("Trimmed to %s sentence pairs" % len(pairs)) print("Counting words...") for pair in pairs: input_lang.addSentence(pair[0]) output_lang.addSentence(pair[1]) print("Counted words:") print(input_lang.name, input_lang.n_words) print(output_lang.name, output_lang.n_words) return input_lang, output_lang, pairsinput_lang, output_lang, pairs = prepareData('eng', 'fra', True)# print("pairs:\n", pairs) pairs = [法语,英语]print(random.choice(pairs))# Encoder 部分class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size # 隐藏状态a的大小 self.embedding = nn.Embedding(input_size, hidden_size) # 词嵌入层 self.gru = nn.GRU(hidden_size, hidden_size) # 多层的GRU def forward(self, input, hidden): embedded = self.embedding(input).view(1, 1, -1) output = embedded output, hidden = self.gru(output, hidden) return output, hidden def initHidden(self): return torch.zeros(1,1, self.hidden_size, device=device)# Decoder部分class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): output = self.embedding(input).view(1, 1, -1) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.softmax(self.out(output[0])) return output, hidden def initHidden(self): return torch.zeros(1,1,self.hidden_size, device=device)# Attention 部分class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH): super(AttnDecoderRNN, self).__init__() self.hidden_size = hidden_size self.output_size = output_size self.dropout_p = dropout_p self.max_length = max_length self.embedding = nn.Embedding(self.output_size, self.hidden_size) self.attn = nn.Linear(self.hidden_size*2, self.max_length) self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size) self.dropout = nn.Dropout(self.dropout_p) self.gru = nn.GRU(self.hidden_size, self.hidden_size) self.out = nn.Linear(self.hidden_size, self.output_size) def forward(self, input, hidden, encoder_outputs): embedded = self.embedding(input).view(1, 1, -1) embedded = self.dropout(embedded) attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) # 注意力权重 attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) # 两个batch之间的矩阵乘法 output = torch.cat((embedded[0], attn_applied[0]), 1) output = self.attn_combine(output).unsqueeze(0) output = F.relu(output) output, hidden = self.gru(output, hidden) output = F.log_softmax(self.out(output[0]), dim=1) return output, hidden, attn_weights # 隐状态初始化 def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device)# 训练模型# 准备训练数据def indexesFromSentence(lang, sentence): return [lang.word2index[word] for word in sentence.split(" ")]def tensorFromSentence(lang, sentence): indexes = indexesFromSentence(lang, sentence) indexes.append(EOS_token) # EOS作为encoder编码器网络的结束标志， SOS作为Decoder解码器网络的开始标志 return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)def tensorsFromPair(pair): input_tensor = tensorFromSentence(input_lang, pair[0]) # pair[0]是法语 targe_tensor = tensorFromSentence(output_lang, pair[1]) # pair[1]是英语 return (input_tensor, targe_tensor)# 开始训练# “tearcher_forcing_ratio将上一时刻的真实目标输出当作下一个时刻的Encoder网络的输入，而不是使用Encoder网络的上一时刻的预测输出作为下一时刻的输入。tearcher_forcing_ratio = 0.5def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH): encoder_hidden = encoder.initHidden() encoder_optimizer.zero_grad() decoder_optimizer.zero_grad() input_length = input_tensor.size(0) target_length = target_tensor.size(0) encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) loss = 0 # encoder部分 for ei in range(input_length): encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) encoder_outputs[ei] = encoder_output[0, 0] # decoder部分 decoder_input = torch.tensor([[SOS_token]], device=device) decoder_hidden = encoder_hidden use_teacher_foring = True if random.random() &lt; tearcher_forcing_ratio else False # using teacher forcing if use_teacher_foring: for di in range(target_length): decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs) loss += criterion(decoder_output, target_tensor[di]) decoder_input = target_tensor[di] # 不使用teacher forcing,使用上一时刻的输出作为下一时刻的输入 else: for di in range(target_length): decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs) topv, topi = decoder_output.topk(1) decoder_input = topi.squeeze().detach() loss += criterion(decoder_output, target_tensor[di]) if decoder_input.item() == EOS_token: break loss.backward() encoder_optimizer.step() decoder_optimizer.step() return loss.item() / target_length# 辅助函数------记录时间import timeimport mathdef asMinutes(s): m = math.floor(s / 60) s -= m * 60 return "%dm %ds" % (m, s)def timeSince(since, percent): now = time.time() s = now - since es = s / (percent) rs = es - s return "%s (- %s)" % (asMinutes(s), asMinutes(rs))# 整个训练过程如下： # 开启定时器 # 初始化优化器和loss函数 # 创建training pairs # 开始训练并绘图def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01): start = time.time() # 开启定时器 plot_losses = [] print_loss_total = 0 # Reset every print_every plot_loss_total = 0 # Reset every plot_every encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) # 定义优化算法 decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) training_pairs = [tensorsFromPair(random.choice(pairs)) # 创建training pairs for i in range(n_iters)] criterion = nn.NLLLoss() # 定义损失函数 for iter in range(1, n_iters + 1): training_pair = training_pairs[iter - 1] input_tensor = training_pair[0] target_tensor = training_pair[1] loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) print_loss_total += loss plot_loss_total += loss if iter % print_every == 0: print_loss_avg = print_loss_total / print_every print_loss_total = 0 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg)) if iter % plot_every == 0: plot_loss_avg = plot_loss_total / plot_every plot_losses.append(plot_loss_avg) plot_loss_total = 0 showPlot(plot_losses)# 绘制loss曲线import matplotlib.pyplot as pltplt.switch_backend('agg')import matplotlib.ticker as tickerimport numpy as np%matplotlib inlinedef showPlot(points): plt.figure() fig, ax = plt.subplots() # this locator puts ticks at regular intervals loc = ticker.MultipleLocator(base=0.2) ax.yaxis.set_major_locator(loc) plt.plot(points)# 测试阶段--------测试阶段整体与训练阶段类似，但是测试阶段，不用给出target_tensor,只是将decoder网络上一时刻的预测值作为下一时刻的输入值# 当预测值是EOS时，则停止预测def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH): with torch.no_grad(): input_tensor = tensorFromSentence(input_lang, sentence) input_length = input_tensor.size()[0] encoder_hidden = encoder.initHidden() encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) # encoder部分 for ei in range(input_length): encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) encoder_outputs[ei] += encoder_output[0, 0] decoder_input = torch.tensor([[SOS_token]], device=device) # SOS decoder_hidden = encoder_hidden decoded_words = [] decoder_attentions = torch.zeros(max_length, max_length) # decoder部分 for di in range(max_length): decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs) decoder_attentions[di] = decoder_attention.data topv, topi = decoder_output.data.topk(1) if topi.item() == EOS_token: # 结束时的条件 decoded_words.append('&lt;EOS&gt;') break else: decoded_words.append(output_lang.index2word[topi.item()]) decoder_input = topi.squeeze().detach() return decoded_words, decoder_attentions[:di + 1]# 随机地从训练集中选择pairs,然后在测试集上进行评估def evaluateRandomly(encoder, decoder, n=10): for i in range(n): pair = random.choice(pairs) print('输入:&gt;', pair[0]) print('目标:=', pair[1]) output_words, attentions = evaluate(encoder, decoder, pair[0]) output_sentence = ' '.join(output_words) print('预测:&lt;', output_sentence) print('')# 正式训练开始运行hidden_size = 256encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)trainIters(encoder1, attn_decoder1, 75000, print_every=5000)evaluateRandomly(encoder1, attn_decoder1)# 注意力可视化output_words, attentions = evaluate( encoder1, attn_decoder1, "je suis trop froid .")plt.matshow(attentions.numpy());# 增加坐标轴，更加清楚的可视化def showAttention(input_sentence, output_words, attentions): # Set up figure with colorbar fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(attentions.numpy(), cmap='bone') fig.colorbar(cax) # Set up axes ax.set_xticklabels([''] + input_sentence.split(' ') + ['&lt;EOS&gt;'], rotation=90) ax.set_yticklabels([''] + output_words) # Show label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) plt.show()def evaluateAndShowAttention(input_sentence): output_words, attentions = evaluate( encoder1, attn_decoder1, input_sentence) print('input =', input_sentence) print('output =', ' '.join(output_words)) showAttention(input_sentence, output_words, attentions) 4.参考资料 邱锡鹏：《神经网络与深度学习》 Translation with a Sequence to Sequence Network and Attention PyTorch中文文档 Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation Sequence to Sequence Learning with Neural Networks Neural Machine Translation by Jointly Learning to Align and Translate A Neural Conversational Model 本文中的代码及数据下载地址]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻松优化Jupyter Notebook:技巧、诀窍、魔法]]></title>
    <url>%2F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%2F%E8%BD%BB%E6%9D%BE%E4%BC%98%E5%8C%96Jupyter-Notebook-%E6%8A%80%E5%B7%A7%E3%80%81%E8%AF%80%E7%AA%8D%E3%80%81%E9%AD%94%E6%B3%95%2F</url>
    <content type="text"><![CDATA[0.更换主题1234567pip install jupyterthemes# 使用暗黑主题jt -t chesterish# 恢复默认主题jt -r 1.常用技巧1234567ctrl + shift + p # 查看所有的快捷键按钮# 如果在开头加上感叹号，则可以运行bash命令，例如： !pip install numpy# 在某个函数的末尾加上分号来随时限制函数在最后一行代码上的输出ctr + / # 用来注释或者取消代码 2.MarkDown模式在markdown模式下支持latex 例如：$p(A \mid B) = \frac{p(B \mid A)p(A)}{p(B)}$ 3.输出打印1234567# 打印出所有输出from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"# 打印最后一行输出from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "last_expr" 4.安装扩展插件 安装Nbextensions pip安装 12pip install jupyter_contrib_nbextensionsjupyter contrib nbextension install --user Anaconda安装 123conda install -c conda-forge jupyter_contrib_nbextensionsconda install -c conda-forge jupyter_nbextensions_configuratorjupyter contrib nbextension install --user 5.魔法函数 line magic在一条线上使用,以%开头 cell magic # 在整个cell上使用，以%%开头12%lsmagic # 查看所有的魔法函数%env # 查看环境变量 6.文件的导入与导出12345# 在cell中插入外部的py文件%load basic_import.py# 将cell中的代码导出到一个py文件中%%writefile thiscode.py 7.运行与查看导入的文件12345# 运行py文件中的内容%run basic_import.py# 不确定脚本文件中的内容，可以随时显示它%pycat basic_import.py 8.设置自动保存1%autosave 60 # 每60秒自动保存 9.显示图像1%matplotlib inline 10.定时器 %timeit和%%time放在需要指定的语句前，例如：%%time print(“hello python!”)12%%time # 计算给出cell中的代码运行一次所花费的时间%timeit # 多次运行指定的代码计算平均值，使用的是python中的timeit模块 11.运行其他语言的代码 在不同放入kernel中运行代码，在kernel的开头加上下面对应语言的语句才可以使用！12345678910111213%%bash%%HTML%%python%%python2%%python3%%ruby%%perl%%capture%%javascript%%js%%latex%%markdown%%pypy 12.查看变量1234567# 查找全局范围内的所有变量%who%who str # 只查看str类型的变量# 查看执行某个函数花费的实际%prun 语句名# 使用pdb进行调试必须在每个cell的开头，加上%pdb 13.提供高分辨率的图1%config InlineBackend.figure_format = 'retina' 14.选择执行某些cell1%%script false # 在cell的开头加上此句 15.当需要一直运行某段代码时，通过下面的方法提醒我们的代码何时跑完12345678910111213# 预先安装sox：brew install sox (mac上)# Linux/Mac系统上：import osduration = 1 // secondfreq=440os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration,freq))# Windows系统上：import winsoundduration = 1000freq = 440winsound.Beep(freq.duration) 16.参考博客 博客原文]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Ubuntu</tag>
        <tag>Jupyter Notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中虚函数可以是内联函数吗？]]></title>
    <url>%2FC%2FC-%E4%B8%AD%E8%99%9A%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%98%AF%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[1.需要注意的几点： 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译期建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。 2.代码实例如下：123456789101112131415161718192021222324252627282930 #include &lt;iostream&gt; using namespace std; // 基类 class Base&#123; public: inline virtual void who()&#123; cout &lt;&lt; "I am Base\n"; &#125; virtual ~Base()&#123;&#125; &#125;; // 派生类 class Derived:public Base&#123; public: inline void who()&#123; // 不写inline时隐式内联 cout &lt;&lt; "I am Derived\n"; &#125; &#125;;int main()&#123; // 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，编译期间就能确定了，所以它可以是内联的，但最终是否内联取决于编译器。 Base b; b.who(); // 此处的虚函数是通过指针调用的，呈现多态性，需要在运行时期间才能确定，所以不能为内联。 Base *bptr = new Derived(); bptr-&gt;who(); // 因为Base有虚析构函数（virtual ~Base() &#123;&#125;），所以 delete 时，会先调用派生类（Derived）析构函数，再调用基类（Base）析构函数，防止内存泄漏。 delete bptr; bptr = nullptr; return 0; &#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的volatile关键字]]></title>
    <url>%2FC%2FC-%E4%B8%AD%E7%9A%84volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[1.使用1volatile int i = 10; 2.使用volatile时要几个注意的点： volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是 volatile]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++面试知识点总结]]></title>
    <url>%2FC%2FC-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[一.static关键字的作用 1.修饰普通变量，修改变量的存储区域和生命周期，使变量存储在静态区，在 main 函数运行前就分配了空间，如果有初始值就用初始值初始化它，如果没有初始值系统用默认值初始化它。 2.修饰普通函数，表明函数的作用范围，仅在定义该函数的文件内才能使用。在多人开发项目时，为了防止与他人命名空间里的函数重名，可以将函数定位为 static。 3.修饰成员变量，修饰成员变量使所有的对象只保存一个该变量，而且不需要生成对象就可以访问该成员。 4.修饰成员函数，修饰成员函数使得不需要生成对象就可以访问该函数，但是在 static 函数内不能访问非静态成员。 二.C++和C的区别 设计思想上： C++是面向对象的语言，而C是面向过程的结构化编程语言 语法上： C++具有重载、继承和多态三种特性 C++相比C，增加多许多类型安全的功能，比如强制类型转换 C++支持范式编程，比如模板类、函数模板等 三.c++中四种cast转换 C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast 1.const_cast:对于未定义const版本的成员函数，我们通常需要使用const_cast来去除const引用对象的const，完成函数调用。另外一种使用方式，结合static_cast，可以在非const版本的成员函数内添加const，调用完const版本的成员函数后，再使用const_cast去除const限定。 2.static_cast:完成基础数据类型；同一个继承体系中类型的转换；任意类型与空指针类型void* 之间的转换。 3.dynamic_cast:用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上(指的是子类向基类的转换)和向下转化(指的是基类向子类的转换)。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 4.reinterpret_cast:几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 四.C/C++ 中指针和引用的区别？ 1.指针有自己的一块空间，而引用只是一个别名； 2.使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小； 3.指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象 的引用； 4.作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引 用的修改都会改变引用所指向的对象； 5.可以有const指针，但是没有const引用； 6.指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被改变； 7.指针可以有多级指针（**p），而引用只有一级 8.指针和引用使用++运算符的意义不一样； 9.如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露 五.c++中的四个智能指针： shared_ptr,unique_ptr,weak_ptr,auto_ptr 智能指针出现的原因：智能指针的作用是管理一个指针，因为存在以下这种情况：申请的空间在函数结束时忘记释放，造成内存泄漏。使用智能指针可以很大程度上的避免这个问题，因为智能指针就是一个类，当超出了类的作用域是，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。 1.auto_ptr（c++98的方案，c++11已经抛弃）原因是缺乏语言特性如 “针对构造和赋值” 的 std::move 语义，以及其他瑕疵。 2.unique_ptr（替换auto_ptr）：是 C++11 才开始提供的类型，是一种在异常时可以帮助避免资源泄漏的智能指针。采用独占式拥有，意味着可以确保一个对象和其相应的资源同一时间只被一个 pointer 拥有。一旦拥有着被销毁或编程 empty，或开始拥有另一个对象，先前拥有的那个对象就会被销毁，其任何相应资源亦会被释放。实现独占式拥有（exclusive ownership）或严格拥有（strict ownership）概念，保证同一时间内只有一个智能指针可以指向该对象。你可以移交拥有权。它对于避免内存泄漏（resource leak）——如 new 后忘记 delete ——特别有用。unique_ptr 用于取代 auto_ptr 3.shared_ptr：shared_ptr实现共享式拥有概念。多个智能指针指向相同对象，该对象和其相关资源会在 “最后一个 reference 被销毁” 时被释放。为了在结构较复杂的情景中执行上述工作，标准库提供 weak_ptr、bad_weak_ptr 和 enable_shared_from_this 等辅助类。多个智能指针可以共享同一个对象，对象的最末一个拥有着有责任销毁对象，并清理与该对象相关的所有资源。 4.weak_ptr：weak_ptr 允许你共享但不拥有某对象，一旦最末一个拥有该对象的智能指针失去了所有权，任何 weak_ptr 都会自动成空（empty）。因此，在 default 和 copy 构造函数之外，weak_ptr 只提供 “接受一个 shared_ptr” 的构造函数。可打破环状引用（cycles of references，两个其实已经没有被使用的对象彼此互指，使之看似还在 “被使用” 的状态）的问题。 六.野指针 野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针 七.为什么析构函数必须是虚函数？为什么C++默认的析构函数不是虚函数 将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。 C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。 八.函数指针 1.定义：函数指针是指向函数的指针变量。函数指针本身首先是一个指针变量，该指针变量指向一个具体的函数。这正如用指针变量可指向整型变量、字符型、数组一样，这里是指向函数。C在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后，可用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上是大体一致的。 2.用途：调用函数和做函数的参数，比如回调函数。 3.示例： 1234char * fun(char * p) &#123;…&#125; // 指针函数funchar * (*pf)(char * p); // 函数指针pfpf = fun; // 函数指针pf指向函数funpf(p); // 通过函数指针pf调用函数fun 九.fork函数的作用 Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用，如下所示 123#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t fork(void); 成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。 最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 十.C++中析构函数的作用 析构函数与构造函数对应，当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数。 析构函数名也应与类名相同，只是在函数名前面加一个位取反符~，例如~stud( )，以区别于构造函数。它不能带任何参数，也没有返回值（包括void类型）。只能有一个析构函数，不能重载。 如果用户没有编写析构函数，编译系统会自动生成一个缺省的析构函数（即使自定义了析构函数，编译器也总是会为我们合成一个析构函数，并且如果自定义了析构函数，编译器在执行时会先调用自定义的析构函数再调用合成的析构函数），它也不进行任何操作，所以许多简单的类中没有用显式的析构函数。 如果一个类中有指针，且在使用的过程中动态的申请了内存，那么最好显式构造析构函数在销毁类之前，释放掉申请的内存空间，避免内存泄漏。 类析构顺序：1）派生类本身的析构函数；2）对象成员析构函数；3）基类析构函数。 十一.静态函数和虚函数的区别 静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销。 十二.重载和重写 重载：两个函数名相同，但是参数列表不同（个数，类型），返回值类型没有要求，在同一作用域中 重写：子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数，这种情况是重写 十三.虚函数和多态 多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。 虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。 十四.下面四个代码的区别const char * arr = “123”; char * brr = “123”; const char crr[] = “123”; char drr[] = “123”; const char * arr = “123”; // 字符串123保存在常量区，const本来是修饰arr指向的值不能通过arr去修改，但是字符串“123”在常量区，本来就不能改变，所以加不加const效果都一样 char * brr = “123”; // 字符串123保存在常量区，这个brr指针指向的是同一个位置，同样不能通过brr去修改”123”的值 const char crr[] = “123”; // 这里123本来是在栈上的，但是编译器可能会做某些优化，将其放到常量区 char drr[] = “123”; // 字符串123保存在栈区，可以通过drr去修改 十五.const修饰成员函数的目的是什么？ const修饰的成员函数表明函数调用不会对对象做出任何更改，事实上，如果确认不会对对象做更改，就应该为函数加上const限定，这样无论const对象还是普通对象都可以调用该函数。 十六.C++里是怎么定义常量的？常量存放在内存的哪个位置？ 对于局部常量，存放在栈区；对于全局常量，编译期一般不分配内存，放在符号表中以提高访问效率；字面值常量，比如字符串，放在常量区。 十七.new/delete与malloc/free的区别是什么 首先，new/delete是C++的关键字，而malloc/free是C语言的库函数；后者使用必须指明申请内存空间的大小，对于类类型的对象，后者不会调用构造函数和析构函数。 十八.虚函数表具体是怎样实现运行时多态的? 子类若重写父类虚函数，虚函数表中，该函数的地址会被替换，对于存在虚函数的类的对象，在VS中，对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。 十九.C语言是怎么进行函数调用的？ 每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。 二十.C++如何处理返回值？ 生成一个临时变量，把它的引用作为函数参数传入函数内。 二十一.C++中拷贝赋值函数的形参能否进行值传递？ 不能。如果是这种情况下，调用拷贝构造函数的时候，首先要将实参传递给形参，这个传递的时候又要调用拷贝构造函数。。如此循环，无法完成拷贝，栈也会满。 二十二.malloc与new区别 malloc需要给定申请内存的大小，返回的指针需要强转；new会调用构造函数，不用指定内存大小，返回的指针不用强转。 二十三.fork,wait,exec函数的作用 父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写实拷贝机制分配内存；exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。fork从父进程返回子进程的pid，从子进程返回0；调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1。 二十四.C++中类成员的访问权限 C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。在类的内部（定义类的代码内部），无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。在类的外部（定义类的代码之外），只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员。 二十五. C++中struct和class的区别 总的来说，struct 更适合看成是一个数据结构的实现体，class 更适合看成是一个对象的实现体。 区别：最本质的一个区别就是默认的访问控制 默认的继承访问权限。struct 是 public 的，class 是 private 的 struct 作为数据结构的实现体，它默认的数据访问控制是 public 的，而 class 作为对象的实现体，它默认的成员变量访问控制是 private 的。 二十六.C++类的内部可以定义引用数据成员吗？ 可以，必须通过成员函数初始化列表初始化 12345678910class MyClass&#123;public: MyClass(int &amp;i): a(1), b(i)&#123; // 构造函数初始化列表中是初始化工作 // 在这里做的是赋值而非初始化工作 &#125;private: const int a; int &amp;b; // 引用数据成员b,必须通过列表初始化！&#125;; 二十七.什么是右值引用，跟左值又有什么区别？ 左值：能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。 右值：不能对表达式取地址，或匿名对象。一般指表达式结束就不再存在的临时对象。 右值引用和左值引用的区别： 1.左值可以寻址，而右值不可以； 2.左值可以被赋值，右值不可以被赋值，可以用来给左值赋值； 3.左值可变,右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。 二十八.C++源文件从文本到可执行文件经历的过程？ 对于C++源文件，从文本到可执行文件一般需要四个过程： 预处理阶段：对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件。 编译阶段：将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件 汇编阶段：将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件 链接阶段：将多个目标文件及所需要的库连接成最终的可执行目标文件 二十九.include头文件的顺序以及双引号””和尖括号&lt;&gt;的区别？ include头文件的顺序：对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h,否则汇报变量类型未声明错误。 双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。对于使用双引号包含的头文件，查找头文件路径的顺序为：当前头文件目录、编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）、系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径；对于使用尖括号包含的头文件，查找头文件的路径顺序为：编译器设置的头文件路径（编译器可使用-I显式指定搜索路径）、系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径。 三十.什么时候会发生段错误？ 段错误通常发生在访问非法内存地址的时候，具体来说分为以下几种情况： 使用野指针 试图修改字符串常量的内容 三十一.C++11有哪些新特性？ auto关键字：编译器可以根据初始值自动推导出类型，但是不能用于函数传参以及数组类型的推导； nullptr关键字：nullptr是一种特殊类型的字面值，它可以被转换成任意其它的指针类型；而NULL一般被宏定义为0，在遇到重载时可能会出现问题。 智能指针：C++11新增了std::shared_ptr、std::weak_ptr等类型的智能指针，用于解决内存管理的问题。 初始化列表：使用初始化列表来对类进行初始化 右值引用：基于右值引用可以实现移动语义和完美转发，消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率 atomic原子操作用于多线程资源互斥操作 新增STL容器array以及tuple 三十二.const的作用 1.修饰变量，说明该变量不可以被修改 2.修饰指针，分为指向常量的指针(即常量指针)和指针常量 3.常量引用，经常用于形参类型，既避免了拷贝，又避免了函数对值的修改 4.修饰成员函数，说明该成员函数内不能修改成员变量 const用法如下：12345678910111213141516171819202122232425262728293031323334353637383940414243// 类class A&#123;private: const int a; // 常对象成员，只能在初始化列表赋值public: // 构造函数 A() : a(0) &#123; &#125;; A(int x) : a(x) &#123; &#125;; // 初始化列表 // const可用于对重载函数的区分 int getValue(); // 普通成员函数 int getValue() const; // 常成员函数，不得修改类中的任何数据成员的值&#125;;void function()&#123; // 对象 A b; // 普通对象，可以调用全部成员函数、更新常成员变量 const A a; // 常对象，只能调用常成员函数 const A *p = &amp;a; // 常指针 const A &amp;q = a; // 常引用 // 指针 char greeting[] = "Hello"; char* p1 = greeting; // 指针变量，指向字符数组变量 const char* p2 = greeting; // 常量指针即常指针，指针的指向可以改变，但是所存的内容不能变 char const* p2 = greeting; // 与const char* p2 等价 char* const p3 = greeting; // 指针常量，指针是一个常量，即指针的指向不能改变，但是指针所存的内容可以改变 const char* const p4 = greeting; // 指向常量的常指针，指针和指针所存的内容都不能改变，本质是一个常量&#125;// 函数void function1(const int Var); // 传递过来的参数在函数内不可变void function2(const char* Var); // 参数为常量指针即指针所指的内容为常量不能变，指针指向可以改变void function3(char* const Var); // 参数为指针常量void function4(const int&amp; Var); // 引用参数在函数内为常量// 函数返回值const int function5(); // 返回一个常数const int* function6(); // 返回一个指向常量的指针变量即常量指针，使用：const int *p = function6();int* const function7(); // 返回一个指向变量的常指针即指针常量，使用：int* const p = function7(); 三十三.this 指针 this 指针是一个隐含于每一个非静态成员函数中的特殊指针。它指向调用该成员函数的那个对象。 当对一个对象调用成员函数时，编译程序先将对象的地址赋给 this 指针，然后调用成员函数，每次成员函数存取数据成员时，都隐式使用 this 指针。 当一个成员函数被调用时，自动向它传递一个隐含的参数，该参数是一个指向这个成员函数所在的对象的指针。 this 指针被隐含地声明为: ClassName *const this，这意味着不能给 this 指针赋值；在 ClassName 类的 const 成员函数中，this 指针的类型为：const ClassName* const，这说明不能对 this 指针所指向的这种对象是不可修改的（即不能对这种对象的数据成员进行赋值操作）； this 并不是一个常规变量，而是个右值，所以不能取得 this 的地址（不能 &amp;this）。在以下场景中，经常需要显式引用 this 指针： 为实现对象的链式引用； 为避免对同一对象进行赋值操作； 在实现一些数据结构时，如 list。 三十四.inline内联函数 内联函数的特点： 相当于把内联函数里面的内容写在调用内联函数处； 相当于不用执行进入函数的步骤，直接执行函数体； 相当于宏，却比宏多了类型检查，真正具有函数特性； 编译器一般不内联包含循环、递归、switch 等复杂操作的内联函数； 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。 内联函数的使用： 12345678910111213141516171819// 声明1（加 inline，建议使用）inline int functionName(int first, int second,...);// 声明2（不加 inline）int functionName(int first, int second,...);// 定义inline int functionName(int first, int second,...) &#123;/****/&#125;;// 类内定义，隐式内联class A &#123; int doA() &#123; return 0; &#125; // 隐式内联&#125;// 类外定义，需要显式内联class A &#123; int doA();&#125;inline int A::doA() &#123; return 0; &#125; // 需要显式内联 编译器对内联函数的处理步骤: 将 inline 函数体复制到 inline 函数调用点处； 为所用 inline 函数中的局部变量分配内存空间； 将 inline 函数的的输入参数和返回值映射到调用方法的局部变量空间中； 如果 inline 函数有多个返回点，将其转变为 inline 函数代码块末尾的分支（使用 GOTO） 使用内联函数的优缺点: 优点: 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换（同普通函数），而宏定义则不会。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。 缺点: 代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。 是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。 虚函数可以是内联函数吗？ 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。 虚函数内联使用实例如下:12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;using namespace std;class Base&#123;public: inline virtual void who() &#123; cout &lt;&lt; "I am Base\n"; &#125; virtual ~Base() &#123;&#125;&#125;;class Derived : public Base&#123;public: inline void who() // 不写inline时隐式内联 &#123; cout &lt;&lt; "I am Derived\n"; &#125;&#125;;int main()&#123; // 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，编译期间就能确定了，所以它可以是内联的，但最终是否内联取决于编译器。 Base b; b.who(); // 此处的虚函数是通过指针调用的，呈现多态性，需要在运行时期间才能确定，所以不能为内联。 Base *ptr = new Derived(); ptr-&gt;who(); // 因为Base有虚析构函数（virtual ~Base() &#123;&#125;），所以 delete 时，会先调用派生类（Derived）析构函数，再调用基类（Base）析构函数，防止内存泄漏。 delete ptr; ptr = nullptr; system("pause"); return 0;&#125; 三十五.volatile关键字1volatile int i=10; volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是volatile 三十六.assert() 断言是宏，而非函数。assert 宏的原型定义在 （C）、\（C++）中，其作用是如果它的条件返回错误，则终止程序执行。可以通过定义 NDEBUG 来关闭 assert，但是需要在源代码的开头，include 之前。 assert()使用1234#define NDEBUG // 加上这行，则 assert 不可用#include &lt;assert.h&gt;assert( p != NULL ); // assert 不可用 三十七.sizeof()运算符 sizeof 对数组，得到整个数组所占空间大小。 sizeof 对指针，得到指针本身所占空间大小。 三十八.#pragma pack(n) 用途：设定结构体、联合以及类成员变量以 n 字节方式对齐 #pragma pack(n)使用实例：1234567891011#pragma pack(push) // 保存对齐状态#pragma pack(4) // 设定为 4 字节对齐struct test&#123; char m1; double m4; int m3;&#125;;#pragma pack(pop) // 恢复对齐状态 三十九. extern “C” 用途：extern “C” 的作用是让 C++ 编译器将 extern “C” 声明的代码当作 C 语言代码处理，可以避免 C++ 因符号修饰导致代码不能和C语言库中的符号进行链接的问题。 被 extern 限定的函数或变量是 extern 类型的；被 extern “C” 修饰的变量和函数是按照 C 语言方式编译和链接的 extern “C”实例如下：123456789#ifdef __cplusplusextern "C" &#123;#endifvoid *memset(void *, int, size_t);#ifdef __cplusplus&#125;#endif 四十.struct 和 typedef struct C语言中： 123456789// ctypedef struct Student &#123; int age;&#125; S;// 等价于下面struct Student &#123; int age;&#125; ;typedef struct Student S; C++中： 1.如果在类标识符空间定义了 struct Student {…};，使用 Student me; 时，编译器将搜索全局标识符表，Student 未找到，则在类标识符内搜索。即表现为可以使用 Student 也可以使用 struct Student，如下： 123456// cppstruct Student &#123; int age;&#125;;void f( Student me ); // 正确，"struct" 关键字可省略 2.若定义了与 Student 同名函数之后，则 Student 只代表函数，不代表结构体，如下： 12345678910111213typedef struct Student &#123; int age;&#125; S;void Student() &#123;&#125; // 正确，定义后 "Student" 只代表此函数//void S() &#123;&#125; // 错误，符号 "S" 已经被定义为一个 "struct Student" 的别名int main() &#123; Student(); struct Student me; // 或者 "S me"; return 0;&#125; 四十一.union联合体 联合（union）是一种节省空间的特殊的类，一个 union 可以有多个数据成员，但是在任意时刻只有一个数据成员可以有值。当某个成员被赋值后其他成员变为未定义状态。联合有如下特点： 默认访问控制符为 public 可以含有构造函数、析构函数 不能含有引用类型的成员 不能继承自其他类，不能作为基类 不能含有虚函数 匿名 union 在定义所在作用域可直接访问 union 成员 匿名 union 不能包含 protected 成员或 private 成员 全局匿名联合必须是静态（static）的 union使用实例如下： 12345678910111213141516171819202122232425262728293031#include&lt;iostream&gt;union UnionTest &#123; UnionTest() : i(10) &#123;&#125;; int i; double d;&#125;;static union &#123; int i; double d;&#125;;int main() &#123; UnionTest u; union &#123; int i; double d; &#125;; std::cout &lt;&lt; u.i &lt;&lt; std::endl; // 输出 UnionTest 联合的 10 ::i = 20; std::cout &lt;&lt; ::i &lt;&lt; std::endl; // 输出全局静态匿名联合的 20 i = 30; std::cout &lt;&lt; i &lt;&lt; std::endl; // 输出局部匿名联合的 30 return 0;&#125; 四十二.explicit（显式）关键字 explicit 修饰构造函数时，可以防止隐式转换和复制初始化，必须显式初始化 explicit 修饰转换函数时，可以防止隐式转换，但按语境转换 除外 explicit使用实例如下：123456789101112131415161718192021222324252627282930313233343536373839404142struct A&#123; A(int) &#123; &#125; operator bool() const &#123; return true; &#125;&#125;;struct B&#123; explicit B(int) &#123;&#125; explicit operator bool() const &#123; return true; &#125;&#125;;void doA(A a) &#123;&#125;void doB(B b) &#123;&#125;int main()&#123; A a1(1); // OK：直接初始化 A a2 = 1; // OK：复制初始化 A a3&#123; 1 &#125;; // OK：直接列表初始化 A a4 = &#123; 1 &#125;; // OK：复制列表初始化 A a5 = (A)1; // OK：允许 static_cast 的显式转换 doA(1); // OK：允许从 int 到 A 的隐式转换 if (a1); // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a6（a1）; // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a7 = a1; // OK：使用转换函数 A::operator bool() 的从 A 到 bool 的隐式转换 bool a8 = static_cast&lt;bool&gt;(a1); // OK ：static_cast 进行直接初始化 B b1(1); // OK：直接初始化 B b2 = 1; // 错误：被 explicit 修饰构造函数的对象不可以复制初始化 B b3&#123; 1 &#125;; // OK：直接列表初始化 B b4 = &#123; 1 &#125;; // 错误：被 explicit 修饰构造函数的对象不可以复制列表初始化 B b5 = (B)1; // OK：允许 static_cast 的显式转换 doB(1); // 错误：被 explicit 修饰构造函数的对象不可以从 int 到 B 的隐式转换 if (b1); // OK：被 explicit 修饰转换函数 B::operator bool() 的对象可以从 B 到 bool 的按语境转换 bool b6(b1); // OK：被 explicit 修饰转换函数 B::operator bool() 的对象可以从 B 到 bool 的按语境转换 bool b7 = b1; // 错误：被 explicit 修饰转换函数 B::operator bool() 的对象不可以隐式转换 bool b8 = static_cast&lt;bool&gt;(b1); // OK：static_cast 进行直接初始化 return 0;&#125; 四十三.friend友元类和友元函数 能访问私有成员、破坏封装性、友元关系不可传递、友元关系的单向性、友元声明的形式及数量不受限制 四十四.:: 范围解析运算符 种类： 全局作用域符（::name）：用于类型名称（类、类成员、成员函数、变量等）前，表示作用域为全局命名空间 类作用域符（class::name）：用于表示指定类型的作用域范围是具体某个类的 命名空间作用域符（namespace::name）:用于表示指定类型的作用域范围是具体某个命名空间的 使用实例： 1234567891011121314151617int count = 0; // 全局（::）的 countclass A &#123;public: static int count; // 类 A 的 count（A::count）&#125;;int main() &#123; ::count = 1; // 设置全局的 count 的值为 1 A::count = 2; // 设置类 A 的 count 为 2 int count = 0; // 局部的 count count = 3; // 设置局部的 count 的值为 3 return 0;&#125; 四十五.enum枚举类型 限定作用域的枚举类型: 1enum class open_modes &#123; input, output, append &#125;; 不限定作用域的枚举类型: 12enum color &#123; red, yellow, green &#125;;enum &#123; floatPrec = 6, doublePrec = 10 &#125;; 四十六.decltype关键字 作用和用法：用于检查实体的声明类型或表达式的类型及值分类。语法：decltype ( expression ) decltype实例如下： 1234567891011121314// 尾置返回允许我们在参数列表之后声明返回类型template &lt;typename It&gt;auto fcn(It beg, It end) -&gt; decltype(*beg)&#123; // 处理序列 return *beg; // 返回序列中一个元素的引用&#125;// 为了使用模板参数成员，必须用 typenametemplate &lt;typename It&gt;auto fcn2(It beg, It end) -&gt; typename remove_reference&lt;decltype(*beg)&gt;::type&#123; // 处理序列 return *beg; // 返回序列中一个元素的拷贝&#125; 四十七.引用和宏 左值引用：常规引用，一般表示对象的身份 右值引用：右值引用就是必须绑定到右值（一个临时对象、将要销毁的对象）的引用，一般表示对象的值；右值引用可实现转移语义（Move Sementics）和精确传递（Perfect Forwarding），它的主要目的有两个方面： 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。 能够更简洁明确地定义泛型函数。 引用折叠： X&amp; &amp;、X&amp; &amp;&amp;、X&amp;&amp; &amp; 可折叠成 X&amp;；X&amp;&amp; &amp;&amp; 可折叠成 X&amp;&amp; 宏：宏定义可以实现类似于函数的功能，但是它终归不是函数，而宏定义中括弧中的“参数”也不是真的参数，在宏展开的时候对 “参数” 进行的是一对一的替换。 四十八.必须使用成员初始化列表的场合 好处：更高效：少了一次调用默认构造函数的过程。 有些场合必须要用初始化列表： 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面 没有默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化 四十九.面向对象三大特征 封装：把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。关键字：public, protected, private。不写默认为 private。 public 成员：可以被任意实体访问 protected 成员：只允许被子类及本类的成员函数访问 private 成员：只允许被本类的成员函数、友元类或友元函数访问 继承：基类（父类）——&gt; 派生类（子类） 多态：即多种状态（形态）。简单来说，我们可以将多态定义为消息以多种形式显示的能力。多态是以封装和继承为基础的。 C++ 多态分类及实现： 重载多态（Ad-hoc Polymorphism，编译期）：函数重载、运算符重载 子类型多态（Subtype Polymorphism，运行期）：虚函数 参数多态性（Parametric Polymorphism，编译期）：类模板、函数模板 强制多态（Coercion Polymorphism，编译期/运行期）：基本类型转换、自定义类型转换 静态多态(编译期/早绑定) 函数重载实例: 123456class A&#123;public: void do(int a); void do(int a, int b);&#125;; 动态多态(运行期/晚绑定) 虚函数：用 virtual 修饰成员函数，使其成为虚函数 注意： 普通函数（非类成员函数）不能是虚函数 静态函数（static）不能是虚函数 构造函数不能是虚函数（因为在调用构造函数时，虚表指针并没有在对象的内存空间中，必须要构造函数调用完成后才会形成虚表指针） 内联函数不能是表现多态性时的虚函数 动态多态实例 123456789101112131415161718192021222324252627282930313233class Shape // 形状类&#123;public: virtual double calcArea() &#123; ... &#125; virtual ~Shape();&#125;;class Circle : public Shape // 圆形类&#123;public: virtual double calcArea(); ...&#125;;class Rect : public Shape // 矩形类&#123;public: virtual double calcArea(); ...&#125;;int main()&#123; Shape * shape1 = new Circle(4.0); Shape * shape2 = new Rect(5.0, 6.0); shape1-&gt;calcArea(); // 调用圆形类里面的方法 shape2-&gt;calcArea(); // 调用矩形类里面的方法 delete shape1; shape1 = nullptr; delete shape2; shape2 = nullptr; return 0;&#125; 五十.虚析构函数 虚析构函数是为了解决基类的指针指向派生类对象，并用基类的指针删除派生类对象。 虚析构函数的使用如下: 123456789101112131415161718192021class Shape&#123;public: Shape(); // 构造函数不能是虚函数 virtual double calcArea(); virtual ~Shape(); // 虚析构函数&#125;;class Circle : public Shape // 圆形类&#123;public: virtual double calcArea(); ...&#125;;int main()&#123; Shape * shape1 = new Circle(4.0); shape1-&gt;calcArea(); delete shape1; // 因为Shape有虚析构函数，所以delete释放内存时，先调用子类析构函数，再调用基类析构函数，防止内存泄漏。 shape1 = NULL; return 0；&#125; 五十一.纯虚函数 定义：纯虚函数是一种特殊的虚函数，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做。 用法： virtual int A() = 0; 五十二.虚函数、纯虚函数 类里如果声明了虚函数，这个函数是实现的，哪怕是空实现，它的作用就是为了能让这个函数在它的子类里面可以被覆盖，这样的话，编译器就可以使用后期绑定来达到多态了。纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。 虚函数在子类里面也可以不重载的；但纯虚函数必须在子类去实现。 虚函数的类用于 “实作继承”，继承接口的同时也继承了父类的实现。当然大家也可以完成自己的实现。纯虚函数关注的是接口的统一性，实现由子类完成。 带纯虚函数的类叫抽象类，这种类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用。抽象类被继承后，子类可以继续是抽象类，也可以是普通类。 虚基类是虚继承中的基类。 五十三.虚函数指针、虚函数表 虚函数指针：在含有虚函数类的对象中，指向虚函数表，在运行时确定。 虚函数表：在程序只读数据段，存放虚函数指针，如果派生类实现了基类的某个虚函数，则在虚函数表中覆盖原本基类的那个虚函数指针，在编译时根据类的声明创建。 五十四.虚继承 用途：用于解决多继承条件下的菱形继承问题（浪费存储空间、存在二义性） 底层实现原理与编译器相关，一般通过虚基类指针和虚基类表实现，每个虚继承的子类都有一个虚基类指针（占用一个指针的存储空间，4字节）和虚基类表（不占用类对象的存储空间）（需要强调的是，虚基类依旧会在子类里面存在拷贝，只是仅仅最多存在一份而已，并不是不在子类里面了）；当虚继承的子类被当做父类继承时，虚基类指针也会被继承。实际上，vbptr 指的是虚基类表指针（virtual base table pointer），该指针指向了一个虚基类表（virtual table），虚表中记录了虚基类与本类的偏移地址；通过偏移地址，这样就找到了虚基类成员，而虚继承也不用像普通多继承那样维持着公共基类（虚基类）的两份同样的拷贝，节省了存储空间。 五十五.虚继承、虚函数 相同点：都利用了虚指针（均占用类的存储空间）和虚表（均不占用类的存储空间） 不同点： 虚继承： 虚基类依旧存在继承类中，只占用存储空间 虚基类表存储的是虚基类相对直接继承类的偏移 虚函数： 虚函数不占用存储空间 虚函数表存储的是虚函数地址 五十六.模板类、成员模板、虚函数 模板类中可以使用虚函数 一个类（无论是普通类还是类模板）的成员模板（本身是模板的成员函数）不能是虚函数 五十七.抽象类、接口类、聚合类 抽象类：含有纯虚函数的类 接口类：仅含有纯虚函数的抽象类 聚合类：用户可以直接访问其成员，并且具有特殊的初始化语法形式。满足如下特点： 所有成员都是 public 没有定义任何构造函数 没有类内初始化 没有基类，也没有 virtual 函数 五十八.内存分配和管理 malloc、calloc、realloc、alloca malloc：申请指定字节数的内存。申请到的内存中的初始值不确定。 calloc：为指定长度的对象，分配能容纳其指定个数的内存。申请到的内存的每一位（bit）都初始化为 0。 realloc：更改以前分配的内存长度（增加或减少）。当增加长度时，可能需将以前分配区的内容移到另一个足够大的区域，而新增区域内的初始值则不确定。 alloca：在栈上申请内存。程序在出栈的时候，会自动释放内存。但是需要注意的是，alloca 不具可移植性, 而且在没有传统堆栈的机器上很难实现。alloca 不宜使用在必须广泛移植的程序中。C99 中支持变长数组 (VLA)，可以用来替代 alloca。 malloc和free 用途：用于分配、释放内存 使用： 申请内存，确认是否申请成功 12char *str = (char*) malloc(100);assert(str != nullptr); 释放内存后指针置空 12free(p);p = nullptr; new和delete new / new[]：完成两件事，先底层调用 malloc 分配了内存，然后调用构造函数（创建对象）。 delete/delete[]：也完成两件事，先调用析构函数（清理资源），然后底层调用 free 释放空间。 new 在申请内存时会自动计算所需字节数，而 malloc 则需我们自己输入申请内存空间的字节数。 使用： 123456int main()&#123; T* t = new T(); // 先内存分配 ，再构造函数 delete t; // 先析构函数，再内存释放 return 0;&#125; 五十九.delete this 合法吗？ 合法，但是： 必须保证 this 对象是通过 new（不是 new[]、不是 placement new、不是栈上、不是全局、不是其他对象成员）分配的 必须保证调用 delete this 的成员函数是最后一个调用 this 的成员函数 必须保证成员函数的 delete this 后面没有调用 this 了 必须保证 delete this 后没有人使用了 六十.如何定义一个只能在堆上（栈上）生成对象的类？ 只能在堆上 方法： 将析构函数设置为私有 原因：C++ 是静态绑定语言，编译器管理栈上对象的生命周期，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性。若析构函数不可访问，则不能在栈上创建对象。 只能在栈上 方法：将 new 和 delete 重载为私有 原因： 在堆上生成对象，使用 new 关键词操作，其过程分为两阶段：第一阶段，使用 new 在堆上寻找可用内存，分配给对象；第二阶段，调用构造函数生成对象。将 new 操作设置为私有，那么第一阶段就无法完成，就不能够在堆上生成对象。 六十一.强制类型转换运算符(4种) static_cast 特点：静态转换，在编译处理期间。 应用场合： 主要用于C++中内置的基本数据类型之间的转换，但是没有运行时类型的检测来保证转换的安全性。 a.用于基类和子类之间的指针或引用之间的转换，这种转换把子类的指针或引用转换为基类表示是安全的；进行下行转换，把积累的指针或引用转换为子类表示时，由于没有进行动态类型检测，所以是不安全的。 b.把void类型的指针转换成目标类型的指针（不安全） c.不能用于两个不相关的类型转换 d.不能把const对象转换成非const对象 const_cast 特点：去常转换，编译时执行。 应用场合： const_cast操作不能在不同的种类间转换。相反，它仅仅把它作用的表达式转换成常量。它可以使一个本来不是const类型的数据转换成const类型的，或者把const属性去掉。 reinterpret_cast: 特点：重解释类型转换 应用场合： 它有着和c风格强制类型转换同样的功能；它可以转化任何的内置数据类型为其他的类型，同时它也可以把任何类型的指针转化为其他的类型；它的机理是对二进制进行重新的解释，不会改变原来的格式。 dynamic_cast &lt; type-id &gt; ( expression ) 特点：该运算符将expression转换成type_id类型的对象。type_id必须是类的指针，类的引用或者空类型的指针。 应用场合： a.如果type_id是一个指针类型，那么expression也必须是一个指针类型，如果type_id是一个引用类型，那么expression也必须是一个引用类型。 b.如果type_id是一个空类型的指针，在运行的时候，就会检测expression的实际类型，结果是一个由expression决定的指针类型。 c.如果type_id不是空类型的指针，在运行的时候指向expression对象的指针能否可以转换成type_id类型的指针 d.在运行的时候决定真正的类型，如果向下转换是安全的，就返回一个转换后的指针，若不安全，则返回一个空指针 e.主要用于上下行之间的转换，也可以用于类之间的交叉转换。上行转换时和static_cast效果一样，下行转换时，具有检测功能，比static_cast更安全。 六十二.new delete和malloc free的联系和区别 malloc与free是C语言的标准库函数， new/delete是C++的运算符。它们都可用于申请动态内存和释放内存; 对于非内部数据类型的对象而言，光用maloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free; C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以一个能完成清理与释放内存工作的运算符delete，注意new/delete不是库函数。 六十三.hash冲突及解决方法 关键字值不同的元素可能会映射到哈希表的同一地址上就会发生哈希冲突。解决办法： 开放定址法：当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探查到开放的 地址则表明表中无待查的关键字，即查找失败。 再哈希法：同时构造多个不同的哈希函数 链地址法：将所有哈希地址为 i 的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第 i 个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况 建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。 六十四.多态是什么,多态的作用？ 定义：同一个对象，在不同时刻体现出来的不同状态。 多态的前提： 要有继承关系或实现关系（接口） 要有方法重写； 要有父类或者父接口引用指向子类Base b= new Derived()； 作用：提高了代码的维护性（继承保证）；提高了代码的扩展性 六十五. 继承含有纯虚函数的父类，子类能否实例化？ 如果父类中存在纯虚函数，子类继承父类时，必须重写父类的纯虚函数，函数名、返回类型、参数个数和类型都不能改。若父类中的虚函数自己有定义，子类也可以不重写。之后便可以实例化子类。 六十六.构造函数是否可以用private修饰，如果可以，会有什么效果？ 如果一个类的构造函数只有一个且为private，这是可以编译通过的； 如果一个类的构造函数只有一个且是private，如果类的内部没有专门创建实例的代码，则是无法创建任何实例的； 如果一个类的构造函数只有一个且是private，如果类的内部有专门创建实例的代码，则只能创建一个或多个实例（根据类内部声明的成员对象个数来定）； 如果一个类的构造函数不止一个，private 构造函数如果参数 为void(无参)，则子类无法编译；换言之，如果一个类构造函数只有private且存在子类，则无法编译，除非父类构造函数为public。 六十七.子类的指针能否转换为父类的指针？父类指针能否访问子类成员？ 当自己的类指针指向自己类的对象时，无论调用的是虚函数还是实函数，其调用的都是自己的 当指向父类对象的父类指针被强制转换成子类指针时候，子类指针调用函数时，只有非重写函数是自己的，虚函数是父类的； 当指向子类对象的子类指针被强制转换成父类指针的时候，也就是父类指针指向子类对象，此时，父类指针调用的虚函数都是子类的，而非虚函数都是自己的； 六十八.虚函数的实现机制 虚函数实现机制]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++常用参考资料]]></title>
    <url>%2F%E5%B8%B8%E7%94%A8%E8%B5%84%E6%96%99%2FC-%E5%B8%B8%E7%94%A8%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[1.常用参考资料 STL标准模板库的使用 C++参考手册]]></content>
      <categories>
        <category>常用资料</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络中的批量归一化Batch Normalization(BN)原理总结]]></title>
    <url>%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96Batch-Normalization-BN-%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[0.概述 深层神经网络存在的问题(从当前层的输入的分布来分析)：在深层神经网络中，中间层的输入是上一层神经网络的输出。因此，之前的层的神经网络参数的变化会导致当前层输入的分布发生较大的差异。在使用随机梯度下降法来训练神经网络时，每次参数更新都会导致网络中每层的输入分布发生变化。越是深层的神经网络，其输入的分布会改变的越明显。 解决方法(归一化操作)：从机器学习角度来看，如果某层的输入分布发生了变化，那么其参数需要重新学习，这种现象称为内部协变量偏移。为了解决内部协变量偏移问题，就要使得每一层神经网络输入的分布在训练过程中要保持一致。最简单的方法是对每一层神经网络都进行归一化操作，使其分布保持稳定。 1.批量归一化 协变量偏移介绍 在传统机器学习中，一个常见的问题是协变量偏移。协变量是一个统计学概念，是可能影响预测结果的统计变量。在机器学习中，协变量可以看作是输入。一般的机器学习算法都要求输入在训练集和测试集上的分布式相似的。如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差，如下图所示： BN原理介绍 批量归一化方法是一种有效的逐层归一化的方法，可以对神经网络中任意的中间层进行归一化操作。对一个深层神经网络来说，令第l层的净输入为$\mathbf{z}^{(l)}$， 经过激活函数后的输出是$\mathbf{a}^{(l)}$，即 \mathbf{a}^{(l)}=f\left(\mathbf{z}^{(l)}\right)=f\left(W \mathbf{a}^{(l-1)}+\mathbf{b}\right)其中，$f(\cdot)$是激活函数，W和b是权重和偏置参数。 为了减少内部协变量偏移问题，就要使得净输入$\mathbf{z}^{(l)}$的分布一致，比如都归一化到标准正态分布。虽然归一化操作可以应用在输入$\mathbf{a}^{(l-1)}$上，但其分布性质不如$\mathbf{z}^{(l)}$稳定。因此，在实践中归一化操作一般应用在仿射变换之后，在下一次激活函数之前。利用数据预处理方法对$\mathbf{z}^{(l)}$进行归一化，相当于每一层都进行一次数据预处理，从而加速收敛速度。但是，逐层归一化需要在中间层进行操作，要求效率比较高，因此复杂度比较高的白话方法就不太合适。为了提高归一化效率，一般使用标准归一化，将净输入$\mathbf{z}^{(l)}$的每一维都归一到标准正态分布。 \hat{\mathbf{z}}^{(l)}=\frac{\mathbf{z}^{(l)}-\mathbb{E}\left[\mathbf{z}^{(l)}\right]}{\sqrt{\operatorname{var}\left(\mathbf{z}^{(l)}\right)+\epsilon}}其中，$\mathbb{E}\left[\mathbf{z}^{(l)}\right]$和$\operatorname{var}\left(\mathbf{z}^{(l)}\right)$是当前参数下，$\mathbf{z}^{(l)}$的每一维度在整个训练集上的期望和方差。因为目前主要的训练方法是基于Mini-Batch的随机梯度下降算法，所以准确地计算$\mathbf{z}^{(l)}$的期望和方差是不可行的。因此，$\mathbf{z}^{(l)}$的期望和方差通常用当前小批量Mini-Batch样本集的均值和方差近似估计。 给定一个包含K个样本的小批量样本集合，第l层神经元的净输入$\mathbf{z}^{(1,l)}$，….，$\mathbf{z}^{(K,l)}$的均值和方差为： \begin{aligned} \mu_{\mathcal{B}} &=\frac{1}{K} \sum_{k=1}^{\mathrm{N}} \mathbf{z}^{(k, l)} \\ \sigma_{\mathcal{B}}^{2} &=\frac{1}{K} \sum_{k=1}^{K}\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right) \odot\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right) \end{aligned} 对净输入$\mathbf{z}^{(l)}$的标准归一化会使得其取值集中到0附近，如果使用sigmoid激活函数时，这个取值区间刚好是接近线性变换区间，从而减弱了神经网络非线性变换的性质。因此，为了使归一化操作不对网络的表示能力造成负面影响，可以通过一个附加的缩放和平移变换改变取值区间。$\hat{\mathbf{z}}^{(l)}=\frac{\mathbf{z}^{(l)}-\mu{\mathcal{B}}}{\sqrt{\sigma{\mathcal{B}}^{2}+\epsilon}} \odot \gamma+\beta\triangleq \mathrm{BN}{\gamma, \beta}\left(\mathbf{z}^{(l)}\right)$其中，$\gamma$、$\beta$分别表示缩放和平移的参数向量。从最保守的角度考虑，可以通过标准归一化的逆变换来使得归一化的变量可以被还原为原来的值。即：当$\gamma=\sqrt{\sigma{\mathcal{B}}^{2}}$，$\beta=\mu_{\mathcal{B}}$时，$\hat{\mathbf{z}}^{(l)}=\mathbf{z}^{(l)}$。 批量归一化操作可以看作是一个特殊的神经网络层，该层是加在每一层非线性激活函数之前，即： \mathbf{a}^{(l)}=f\left(\mathbf{B} \mathbf{N}_{\gamma, \beta}\left(\mathbf{z}^{(l)}\right)\right)=f\left(\mathbf{B} \mathbf{N}_{\gamma, \beta}\left(W \mathbf{a}^{(l-1)}\right)\right)其中，因为批量归一化本身具有平移变换，因此非线性变换$W \mathbf{a}^{(l-1)}$就不再需要偏置参数b。 注意：每次小批量样本的$\mu{\mathcal{B}}$和$\sigma{\mathcal{B}}^{2}$是净输入$\mathbf{z}^{(l)}$的函数，而不是常量。因此，在计算参数梯度时，需要考虑$\mu{\mathcal{B}}$和$\sigma{\mathcal{B}}^{2}$的影响。当训练完成时，用整个数据集上的均值$\mu$和方差$\sigma^{2}$来分别替代每次小批量样本的$\mu{\mathcal{B}}$和$\sigma{\mathcal{B}}^{2}$。在实际中，$\mu{\mathcal{B}}$和$\sigma{\mathcal{B}}^{2}$也可以使用移动平均来计算。 2.参考资料 邱锡鹏：《神经网络与深度学习》]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>人工智能</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的数据预处理方法总结]]></title>
    <url>%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[0.概述 一般而言，样本的原始特征中的每一维特征由于来源以及度量单位不同，其特征取值的分布范围往往差异很大。当我们计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。这样，对于基于相似度比较的机器学习方法（比如最近邻分类器KNN），必须先对样本进行预处理，将各个维度的特征归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理想的结果。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但是会导致训练效率比较低。 假设一个只有一层的网络 $y=\tanh \left(w{1} x{1}+w{2} x{2}+b\right)$，其中$x{1} \in[0,10]$，$x{2} \in[0,1]$。因为tanh函数的导数在区间 [−2, 2]上是敏感的，其余地方的导数接近于 0。因此，如果 $w{1} x{1}+w{2} x{2}+b$过大或过小，都会导致梯度过小，难以训练。为了提高训练效率，我们需要使$w{1} x{1}+w{2} x{2}+b$在 [−2, 2]区间，我们需要将w1设得小一点，比如在 [−0.1,0.1]之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数。因此，如果每一个特征的取值范围都在相似的区间，比如 [0, 1]或者 [−1, 1]，我们就不太需要区别对待每一个参数，减少人工干预。 当不同输入特征的取值范围差异比较大时，梯度下降法的效率也会受到影响。下图给出了数据归一化对梯度的影响。其中，图a为未归一化数据的等高线图。取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛。如果我们把数据归一化为取值范围相同，如图b所示，大部分位置的梯度方向近似于最优搜索方向。这样，在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高。 1.常用的归一化方法 1.1 缩放归一化：通过缩放将每一个特征的取值范围归一到 [0, 1]或 [−1, 1]之间。假设有 N 个样本$\left{\mathbf{x}^{(n)}\right}_{n=1}^{N}$，对每一维特征x， \hat{x}^{(n)}=\frac{x^{(n)}-\min _{n}\left(x^{(n)}\right)}{\max _{n}\left(x^{(n)}\right)-\min _{n}\left(x^{(n)}\right)}其中，min(x)和max(x)分别是特征x在所有样本上的最小值和最大值。 1.2 标准归一化：将每一个维特征都处理为符合标准正态分布（均值为 0，标准差为 1）。假设有 N 个样本$\left{\mathbf{x}^{(n)}\right}_{n=1}^{N}$，对每一维特征x，先计算它的均值和标准差： \begin{aligned} \mu &=\frac{1}{N} \sum_{n=1}^{N} x^{(n)} \\ \sigma^{2} &=\frac{1}{N} \sum_{n=1}^{N}\left(x^{(n)}-\mu\right)^{2} \end{aligned}然后，将特征$x^{(n)}$减去均值，并除以标准差，得到新的特征$\hat{x}^{(n)}$。 \hat{x}^{(n)}=\frac{x^{(n)}-\mu}{\sigma}这里$\sigma$不能为0，如果标准差为0，则说明这一维度的特征没有任务的区分性，可以直接删除。在标准归一化之后，每一维特征都服从标准正态分布。 1.3 白化：是一种重要的预处理方法，用来降低输入数据特征之间的冗余性。输入数据经过白化处理后，特征之间相关性较低，并且所有特征具有相同的方差。白化的一个主要实现方式是使用主成分分析PCA方法去除掉各个成分之间的相关性。 2. 参考资料 邱锡鹏：《神经网络与深度学习》]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复习02统计学习方法(感知机perceptron machine)---图片版]]></title>
    <url>%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%A4%8D%E4%B9%A002%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%84%9F%E7%9F%A5%E6%9C%BAperceptron-machine-%E5%9B%BE%E7%89%87%E7%89%88%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复习01统计学习方法概论(机器学习中的重要概念)---图片版]]></title>
    <url>%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E5%A4%8D%E4%B9%A001%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5-%E5%9B%BE%E7%89%87%E7%89%88%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库中的基本概念]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[1.基本概念 数据（data）：描述事物的符号记录称为数据 数据库（DataBase，DB）：是长期存储在计算机内、有组织的、可共享的大量数据的集合，具有永久存储、有组织、可共享三个基本特点。 数据库管理系统（DataBase Management System，DBMS）：是位于用户与操作系统之间的一层数据管理软件。 数据库系统（DataBase System，DBS）：是有数据库、数据库管理系统（及其应用开发工具）、应用程序和数据库管理员（DataBase Administrator DBA）组成的存储、管理、处理和维护数据的系统。 实体（entity）：客观存在并可相互区别的事物称为实体。 属性（attribute）：实体所具有的某一特性称为属性。 码（key）：唯一标识实体的属性集称为码。 实体型（entity type）：用实体名及其属性名集合来抽象和刻画同类实体，称为实体型。 实体集（entity set）：同一实体型的集合称为实体集。 联系（relationship）：实体之间的联系通常是指不同实体集之间的联系。 模式（schema）：模式也称逻辑模式，是数据库全体数据的逻辑结构和特征的描述，是所有用户的公共数据视图。 外模式（external schema）：外模式也称子模式（subschema）或用户模式，它是数据库用户（包括应用程序员和最终用户）能够看见和使用的局部数据的逻辑结构和特征的描述，是数据库用户的数据视图，是与某一应用有关的数据的逻辑表示。 内模式（internal schema）：内模式也称为存储模式（storage schema），一个数据库只有一个内模式。他是数据物理结构和存储方式的描述，是数据库在数据库内部的组织方式。2.常用数据模型 层次模型（hierarchical model） 网状模型（network model） 关系模型（relational model） 关系（relation）：一个关系对应通常说的一张表 元组（tuple）：表中的一行即为一个元组 属性（attribute）：表中的一列即为一个属性 码（key）：表中可以唯一确定一个元组的某个属性组 域（domain）：一组具有相同数据类型的值的集合 分量：元组中的一个属性值 关系模式：对关系的描述，一般表示为 关系名(属性1, 属性2, …, 属性n) 面向对象数据模型（object oriented data model） 对象关系数据模型（object relational data model） 半结构化数据模型（semistructure data model）3.常用SQL操作 更多操作请参见我之前总结的数据库基本操作4.关系型数据库 基本关系操作：查询（选择、投影、连接（等值连接、自然连接、外连接（左外连接、右外连接））、除、并、差、交、笛卡尔积等）、插入、删除、修改 关系模型中的三类完整性约束：实体完整性、参照完整性、用户定义的完整性5.索引 数据库索引：顺序索引、B+ 树索引、hash 索引 更多信息: MySQL 索引背后的数据结构及算法原理6.数据库完整性 数据库的完整性是指数据的正确性和相容性。 完整性：为了防止数据库中存在不符合语义（不正确）的数据。 安全性：为了保护数据库防止恶意破坏和非法存取。 触发器：是用户定义在关系表中的一类由事件驱动的特殊过程。7.关系数据理论 数据依赖是一个关系内部属性与属性之间的一种约束关系，是通过属性间值的相等与否体现出来的数据间相关联系。 最重要的数据依赖：函数依赖、多值依赖。8.范式 第一范式（1NF）：属性（字段）是最小单位不可再分。 第二范式（2NF）：满足 1NF，每个非主属性完全依赖于主键（消除 1NF 非主属性对码的部分函数依赖）。 第三范式（3NF）：满足 2NF，任何非主属性不依赖于其他非主属性（消除 2NF 主属性对码的传递函数依赖）。 鲍依斯-科得范式（BCNF）：满足 3NF，任何非主属性不能对主键子集依赖（消除 3NF 主属性对码的部分和传递函数依赖）。 第四范式（4NF）：满足 3NF，属性之间不能有非平凡且非函数依赖的多值依赖（消除 3NF 非平凡且非函数依赖的多值依赖）。9.数据库恢复 事务：是用户定义的一个数据库操作序列，这些操作要么全做，要么全不做，是一个不可分割的工作单位。 事物的 ACID 特性：原子性、一致性、隔离性、持续性。 恢复的实现技术：建立冗余数据 -&gt; 利用冗余数据实施数据库恢复。 建立冗余数据常用技术：数据转储（动态海量转储、动态增量转储、静态海量转储、静态增量转储）、登记日志文件。10.并发控制 事务是并发控制的基本单位。 并发操作带来的数据不一致性包括：丢失修改、不可重复读、读 “脏” 数据。 并发控制主要技术：封锁、时间戳、乐观控制法、多版本并发控制等。 基本封锁类型：排他锁（X 锁 / 写锁）、共享锁（S 锁 / 读锁）。 活锁和死锁： 活锁：事务永远处于等待状态，可通过先来先服务的策略避免。 死锁：事物永远不能结束 预防：一次封锁法、顺序封锁法； 诊断：超时法、等待图法； 解除：撤销处理死锁代价最小的事务，并释放此事务的所有的锁，使其他事务得以继续运行下去。 可串行化调度：多个事务的并发执行是正确的，当且仅当其结果与按某一次序串行地执行这些事务时的结果相同。可串行性时并发事务正确调度的准则。参考博客 数据库简明教程]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
</search>
