<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习,NLP,PyTorch,">





  <link rel="alternate" href="/atom.xml" title="Curry_Coder的空间" type="application/atom+xml">






<meta name="description" content="0.概述 当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相">
<meta name="keywords" content="深度学习,NLP,PyTorch">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络中的注意力机制总结及PyTorch实战">
<meta property="og:url" content="https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/index.html">
<meta property="og:site_name" content="Curry_Coder的空间">
<meta property="og:description" content="0.概述 当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-8f9c246814375066?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-0bf4dfb1fbcf218a?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-510d0c5391bc8ed5?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-91259671c5a6e418?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-2df3b1f7ccdc066e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-faefaa607c75a828?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-310f3d39f7a9fc4d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-be8ea154c2fc28a9?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-4f8c1d8d22ea5719?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-31b166d4bcdeea3f?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/13407176-aac78b93c36adfa7?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2019-07-29T12:56:37.646Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神经网络中的注意力机制总结及PyTorch实战">
<meta name="twitter:description" content="0.概述 当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/13407176-8f9c246814375066?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/">





  <title>神经网络中的注意力机制总结及PyTorch实战 | Curry_Coder的空间</title>
  








</head>
<script type="text/javascript" src="/lib/clipboard/clipboard.js"></script>
<script type="text/javascript" src="/js/src/custom.js"></script>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/cdlwhm1217096231" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Curry_Coder的空间</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">好好学习，天天向上！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-主页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            主页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-categories" itemscope itemtype="http://schema.org/Article">
  
  
  


  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Curry_Coder">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/curry.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Curry_Coder的空间">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">神经网络中的注意力机制总结及PyTorch实战</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-29T19:29:05+08:00">
                2019-07-29
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-07-29T20:56:37+08:00">
                2019-07-29
              </time>
            
          </span>

          
            <span id="busuanzi_container_page_pv">  |  阅读量 <span id="busuanzi_value_page_pv"></span> 次</span>
          

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/深度学习/神经网络中的注意力机制总结及PyTorch实战/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/深度学习/神经网络中的注意力机制总结及PyTorch实战/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  21
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h4 id="0-概述"><a href="#0-概述" class="headerlink" title="0.概述"></a>0.概述</h4><ul>
<li>当神经网络来处理大量的输入信息时，也可以借助人脑的注意力机制，只选择一些关键的信息输入进行处理，用来提高神经网络的效率。在目前的神经网络模型中，可以将max pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。此外，自上而下的聚焦式注意力也是一种有效的信息选择方法。例如：给定一篇很长的文章，然后就此文章的内容进行提问，提出的问题只和文章中某个段落中的一两个句子相关，其余都无关的。为了减小神经网络的计算代价，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入到神经网络中。</li>
</ul>
<h4 id="1-Attention机制基础知识"><a href="#1-Attention机制基础知识" class="headerlink" title="1.Attention机制基础知识"></a>1.Attention机制基础知识</h4><ul>
<li>用$X=\left[\mathbf{x}_{1}, \cdots, \mathbf{x}_{N}\right]$表示N组输入信息，其中每个向量$\mathbf{x}_{i}, i \in[1, N]$都表示一组输入信息。为了节省计算资源，不需要将所有的信息都输入到神经网络中，只需要从X中选择一些和任务相关的信息。注意力机制的计算可以分为两步：<ul>
<li>(1)在所有输入信息上计算注意力分布；</li>
<li>(2)根据注意力分布来计算输入信息的加权平均</li>
</ul>
</li>
<li>1.1 <strong>注意力分布</strong><ul>
<li>为了从N个输入向量$\left[\mathbf{x}_{1}, \cdots, \mathbf{x}_{N}\right]$中选择出与某个特定任务相关的信息，需要引入一个和任务相关的表示，称为<strong>查询向量q</strong>，并通过一个打分函数来计算每个输入向量和查询向量之间的相关性。</li>
<li>给定一个和任务相关的查询向量q，用注意力变量$z \in[1, N]$来表示被选择信息的索引位置，即z=i表示选择了第i个输入向量。为了方便计算，下面首先介绍<strong>Soft Attention注意力机制</strong>。首先计算在给定q和X下，选择第i个输入向量的概率$\alpha_{i}$<script type="math/tex; mode=display">
\begin{aligned} \alpha_{i} &=p(z=i | X, \mathbf{q}) \\ &=\operatorname{softmax}\left(s\left(\mathbf{x}_{i}, \mathbf{q}\right)\right) \\ &=\frac{\exp \left(s\left(\mathbf{x}_{i}, \mathbf{q}\right)\right)}{\sum_{j=1}^{N} \exp \left(s\left(\mathbf{x}_{j}, \mathbf{q}\right)\right)} \end{aligned}</script>其中$\alpha_{i}$称为注意力分布，$S\left(\mathbf{x}_{i}, \mathbf{q}\right)$是注意力打分函数，可以使用下面的几种方法来计算：<ul>
<li>加性模型       $s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\mathbf{v}^{\mathrm{T}} \tanh \left(W \mathbf{x}_{i}+U \mathbf{q}\right)$</li>
<li>点积模型  $s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\mathbf{x}_{i}^{\mathrm{T}} \mathbf{q}$</li>
<li>缩放点积模型 $s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\frac{\mathbf{x}_{i}^{\mathrm{T}} \mathbf{q}}{\sqrt{d}}$</li>
<li>双线性模型  $s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\mathbf{x}_{i}^{\mathrm{T}} W \mathbf{q}$</li>
</ul>
</li>
<li>上式中W、U、v是可学习的参数，d是输入向量的维度。理论上，加性模型和点积模型的复杂度差不多，但是点积模型在实现上可以更好地利用矩阵乘积，从而计算效率更高。但当输入向量的维度d比较高，点积模型的值通常有较大的方差，从而导致softmax函数的梯度比较小。因此，缩放点积模型可以很好地解决这个问题。双线性模型可以看做是一种泛化的点积模型。假设 $s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\mathbf{x}_{i}^{\mathrm{T}} W \mathbf{q}$中$W=U^{\mathrm{T}} V$，则双线性模型可以写为$s\left(\mathbf{x}_{i}, \mathbf{q}\right)=\mathbf{x}_{i}^{\mathrm{T}} U^{\mathrm{T}} V \mathbf{q}=(U \mathbf{x})^{\mathrm{T}}(V \mathbf{q})$即分别对x和q进行线性变换后计算点积。相比点积模型，双线性模型在计算相似度时引入了非对称性。</li>
</ul>
</li>
<li><strong>1.2 加权平均</strong><ul>
<li>注意力分布$\alpha_{i}$可以解释为在给定任务相关的查询q时，第i个输入向量受注意的程度。下面采用一种<strong>软性</strong>的信息选择机制对输入信息进行汇总。<script type="math/tex; mode=display">
\begin{aligned} \operatorname{att}(X, \mathbf{q}) &=\sum_{i=1}^{N} \alpha_{i} \mathbf{x}_{i} \\ &=\mathbb{E}_{z \sim p(z | X, \mathbf{q})}\left[\mathbf{x}_{z}\right] \end{aligned}</script>上式称为<strong>软注意力机制(Soft Attention Mechanism)</strong>。下图给出了软注意力机制的示例图：<br>  <img src="https://upload-images.jianshu.io/upload_images/13407176-8f9c246814375066?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="软注意力机制"></li>
</ul>
</li>
</ul>
<h4 id="2-其他类型的注意力机制"><a href="#2-其他类型的注意力机制" class="headerlink" title="2.其他类型的注意力机制"></a>2.其他类型的注意力机制</h4><ul>
<li><strong>2.1 硬注意力机制</strong><ul>
<li>上面的公式$\mathbb{E}_{z \sim p(z | X, \mathbf{q})}\left[\mathbf{x}_{z}\right]$提到的是软注意力机制，其选择的信息是所有输入向量在注意力分布下的期望。此外还有一种注意力是只关注到某一个输入向量，叫做<strong>硬注意力机制(Hard Attention Mechanism)</strong>。硬注意力机制有两种方法可以实现：<ul>
<li>(1)选择最高概率的一个输入向量，即<script type="math/tex; mode=display">
\operatorname{att}(X, \mathbf{q})=\mathbf{x}_{j}</script>其中j为概率最大的输入向量的下标，即<script type="math/tex">\begin{array}{c}{j=\arg \max _{i=1}^{N} a_{i}}\end{array}</script></li>
<li>(2)通过在注意力分布上随机采样的方式实现</li>
</ul>
</li>
<li>硬注意力的一个缺点是基于最大采样或随机采样的方式来选择信息。因此最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用反向传播算法进行训练。为了使用反向传播算法进行训练，一般使用软注意力机制。</li>
</ul>
</li>
<li><strong>2.2 键值对注意力</strong><ul>
<li>可以使用键值对格式来表示输入信息，其中键用来计算注意力分布$\alpha_{i}$，值用来计算聚合信息。用$(K, V)=\left[\left(\mathbf{k}_{1}, \mathbf{v}_{1}\right), \cdots,\left(\mathbf{k}_{N}, \mathbf{v}_{N}\right)\right]$来表示N组输入信息，给定任务相关的查询向量q时，注意力函数为：<script type="math/tex; mode=display">
\begin{aligned} \operatorname{att}((K, V), \mathbf{q}) &=\sum_{i=1}^{N} \alpha_{i} \mathbf{v}_{i} \\ &=\sum_{i=1}^{N} \frac{\exp \left(s\left(\mathbf{k}_{i}, \mathbf{q}\right)\right)}{\sum_{j} \exp \left(s\left(\mathbf{k}_{j}, \mathbf{q}\right)\right)} \mathbf{v}_{i} \end{aligned}</script>其中$s\left(\mathbf{k}_{i}, \mathbf{q}\right)$是打分函数，1.2节的图中给出了键值对注意力机制的示意图。当K=V时，键值对模式等于普通模式的注意力机制。</li>
</ul>
</li>
<li><strong>2.3 多头注意力</strong><ul>
<li>多头注意力(Multi-head Attention)是利用多个查询 $Q=\left[\mathbf{q}_{1}, \cdots, \mathbf{q}_{M}\right]$来平行计算从输入信息中选取多组信息。每个注意 力关注输入信息的不同部分。<script type="math/tex; mode=display">
\operatorname{att}((K, V), Q)=\operatorname{att}\left((K, V), \mathbf{q}_{1}\right) \oplus \cdots \oplus \operatorname{att}\left((K, V), \mathbf{q}_{M}\right)</script>其中⊕表示向量拼接。</li>
</ul>
</li>
<li><strong>2.4 自注意力模型(Self Attention)</strong><ul>
<li>当使用神经网络来处理一个变化长度的向量序列时，通过可以使用卷积网络或循环网络进行编码来得到一个相同长度的输出向量序列，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/13407176-0bf4dfb1fbcf218a?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="基于卷积神经网络和循环神经网络的变长序列编码"></li>
<li>基于卷积或循环网络的序列编码都是可以看做是一种局部的编码方式，只建模了输入信息的局部依赖关系。虽然循环网络理论上可以建立长距离依赖关系，但是由于信息传递的容量以及梯度消失问题，实际上也只能建立短距离依赖关系。</li>
<li>如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互；另一种方法是使用全连接网络。全连接网络是一种非常直接的建模远距离依赖的模型，但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时，就可以利用注意力机制来“动态”地生成不同连接的权重，这就是<strong>自注意力模型（Self-Attention Model）</strong>。</li>
<li>假设输入序列为$X=\left[\mathbf{x}_{1}, \cdots, \mathbf{x}_{N}\right] \in \mathbb{R}^{d_{1} \times N}$，输出序列为$H=\left[\mathbf{h}_{1}, \cdots, \mathbf{h}_{N}\right] \in \mathbb{R}^{d_{2} \times N}$，则可以通过线性变换得到三组向量序列：<script type="math/tex; mode=display">
\begin{aligned} Q &=W_{Q} X \in \mathbb{R}^{d_{3} \times N} \\ K &=W_{K} X \in \mathbb{R}^{d_{3} \times N} \\ V &=W_{V} X \in \mathbb{R}^{d_{2} \times N} \end{aligned}</script>其中，Q、K、V分别为查询向量序列，键向量序列、值向量序列，$W_{Q} \in \mathbb{R}^{d_{3} \times d_{1}}$、$W_{K} \in \mathbb{R}^{d_{3} \times d_{1}}$、$W_{V} \in \mathbb{R}^{d_{2} \times d_{1}}$分别表示可学习的参数矩阵。根据$\operatorname{att}((K, V), \mathbf{q})=\sum_{i=1}^{N} \alpha_{i} \mathbf{v}_{i}$，可以得到输出向量$\mathbf{h}_{i}$：<br>$\mathbf{h}_{i}=\operatorname{att}\left((K, V), \mathbf{q}_{i}\right)=\sum_{j=1}^{N} \alpha_{i j} \mathbf{v}_{j}=\sum_{j=1}^{N} \operatorname{softmax}\left(s\left(\mathbf{k}_{j}, \mathbf{q}_{i}\right)\right) \mathbf{v}_{j}$<br>其中，$i, j \in[1, N]$为输出和输入向量序列的位置，连接权重$\alpha_{i j}$由注意力机制动态生成。<br>如果使用缩放点积来作为注意力打分函数，输出向量序列可以写为：<script type="math/tex; mode=display">
H=V \operatorname{softmax}\left(\frac{K^{\mathrm{T}} Q}{\sqrt{d_{3}}}\right)</script>其中softmax函数为按列进行归一化的函数。</li>
<li>下图给出了全连接模型和自注意力模型的对比，其中实线表示可学习的权重，虚线表示动态生成的权重。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列。<br><img src="https://upload-images.jianshu.io/upload_images/13407176-510d0c5391bc8ed5?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="全连接模型与自注意力模型"></li>
<li>自注意力模型可以作为神经网络中的一层来使用，既可以用来替换卷积层和循环层，也可以和它们一起交替使用(例如输入向量X可以是卷积层或循环层的输出)。自注意模型计算的权重$\alpha_{i j}$只依赖于$\mathbf{q}_{i}$和$\mathbf{k}_{j}$的相关性，从而忽略了输入信息的位置信息。因此，在单独使用时，自注意模型一般需要加入位置编码信息来进行修正。</li>
</ul>
</li>
</ul>
<h4 id="3-实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明"><a href="#3-实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明" class="headerlink" title="3.实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明"></a>3.实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明</h4><ul>
<li>利用机器翻译中的经典网络结构Seq2Seq(具体结构见参考资料中的文献)，其中包含Encoder编码网络将输入的法语句子进行编码，然后输入到Decoder解码网络进行解码，输出期望得到的英文句子。整个网络的结构如下：<br><img src="https://upload-images.jianshu.io/upload_images/13407176-91259671c5a6e418?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Seq2Seq网络结构"><br><img src="https://upload-images.jianshu.io/upload_images/13407176-2df3b1f7ccdc066e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Encoder部分"><br><img src="https://upload-images.jianshu.io/upload_images/13407176-faefaa607c75a828?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Decoder部分"><br><img src="https://upload-images.jianshu.io/upload_images/13407176-310f3d39f7a9fc4d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="注意力权重可视化"></li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/13407176-be8ea154c2fc28a9?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="增加坐标轴的注意力权重可视化1"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/13407176-4f8c1d8d22ea5719?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="增加坐标轴的注意力权重可视化2"><br><img src="https://upload-images.jianshu.io/upload_images/13407176-31b166d4bcdeea3f?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="增加坐标轴的注意力权重可视化3"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/13407176-aac78b93c36adfa7?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="增加坐标轴的注意力权重可视化4"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> open</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将法语翻译成英语</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SOS_token = <span class="number">0</span>  <span class="comment"># 开始的标注</span></span><br><span class="line">EOS_token = <span class="number">1</span>  <span class="comment"># 结束的标注</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 辅助类</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lang</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.word2index = &#123;&#125;   <span class="comment"># word----&gt;index</span></span><br><span class="line">        self.index2word = &#123;<span class="number">0</span>: <span class="string">"SOS"</span>, <span class="number">1</span>: <span class="string">"EOS"</span>&#125;  <span class="comment"># index----&gt;word</span></span><br><span class="line">        self.word2count = &#123;&#125;   <span class="comment"># 稍后用来替换稀有单词，统计每个单词出现的次数</span></span><br><span class="line">        self.n_words = <span class="number">2</span>  <span class="comment"># 统计单词总数</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addSentence</span><span class="params">(self, sentence)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">" "</span>):</span><br><span class="line">            self.addWord(word)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addWord</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2index:</span><br><span class="line">            self.word2index[word] = self.n_words</span><br><span class="line">            self.word2count[word] = <span class="number">1</span></span><br><span class="line">            self.index2word[self.n_words] = word</span><br><span class="line">            self.n_words += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.word2count[word] += <span class="number">1</span></span><br><span class="line"> <span class="comment"># Turn a Unicode string to plain ASCII</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicodeToAscii</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">'NFD'</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">'Mn'</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 小写，修剪和删除非字母字符</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizeString</span><span class="params">(s)</span>:</span></span><br><span class="line">    s = unicodeToAscii(s.lower().strip())</span><br><span class="line">    s = re.sub(<span class="string">r"([.!?])"</span>, <span class="string">r" \1"</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">r"[^a-zA-Z.!?]+"</span>, <span class="string">r" "</span>, s)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"><span class="comment"># 加载文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readLangs</span><span class="params">(lang1, lang2, reverse=False)</span>:</span></span><br><span class="line">    print(<span class="string">"Reading lines......."</span>)</span><br><span class="line">    <span class="comment"># 读取文件并进行划分成行</span></span><br><span class="line">    lines = open(<span class="string">r"E://DeepLearning//jupyter_code//dataset//corpus//translation_data//%s-%s.txt"</span> % (lang1, lang2), encoding=<span class="string">'utf-8'</span>).\</span><br><span class="line">                read().strip().split(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将每行切成一组pairs</span></span><br><span class="line">    pairs = [[normalizeString(s) <span class="keyword">for</span> s <span class="keyword">in</span> l.split(<span class="string">"\t"</span>)] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="comment"># 将其他语言翻译成英语</span></span><br><span class="line">    <span class="keyword">if</span> reverse:</span><br><span class="line">        pairs = [list(reversed(p)) <span class="keyword">for</span> p <span class="keyword">in</span> pairs]</span><br><span class="line">        input_lang = Lang(lang2)</span><br><span class="line">        output_lang = Lang(lang1)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_lang = Lang(lang1)</span><br><span class="line">        output_lang = Lang(lang2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于有很多例句，为了能快速训练，我们会将数据集修剪成相对简短的句子。这里最大长度是10个单词（包括结束标点符号）</span></span><br><span class="line"></span><br><span class="line">MAX_LENGTH = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 英语前缀</span></span><br><span class="line">eng_prefixes = (</span><br><span class="line">    <span class="string">"i am "</span>, <span class="string">"i m "</span>,</span><br><span class="line">    <span class="string">"he is"</span>, <span class="string">"he s "</span>,</span><br><span class="line">    <span class="string">"she is"</span>, <span class="string">"she s "</span>,</span><br><span class="line">    <span class="string">"you are"</span>, <span class="string">"you re "</span>,</span><br><span class="line">    <span class="string">"we are"</span>, <span class="string">"we re "</span>,</span><br><span class="line">    <span class="string">"they are"</span>, <span class="string">"they re "</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPair</span><span class="params">(p)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(p[<span class="number">0</span>].split(<span class="string">' '</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        len(p[<span class="number">1</span>].split(<span class="string">' '</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        p[<span class="number">1</span>].startswith(eng_prefixes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPairs</span><span class="params">(pairs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [pair <span class="keyword">for</span> pair <span class="keyword">in</span> pairs <span class="keyword">if</span> filterPair(pair)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepareData</span><span class="params">(lang1, lang2, reverse=False)</span>:</span></span><br><span class="line">    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)</span><br><span class="line">    print(<span class="string">"Read %s sentence pairs"</span> % len(pairs))</span><br><span class="line">    pairs = filterPairs(pairs)</span><br><span class="line">    print(<span class="string">"Trimmed to %s sentence pairs"</span> % len(pairs))</span><br><span class="line">    print(<span class="string">"Counting words..."</span>)</span><br><span class="line">    <span class="keyword">for</span> pair <span class="keyword">in</span> pairs:</span><br><span class="line">        input_lang.addSentence(pair[<span class="number">0</span>])</span><br><span class="line">        output_lang.addSentence(pair[<span class="number">1</span>])</span><br><span class="line">    print(<span class="string">"Counted words:"</span>)</span><br><span class="line">    print(input_lang.name, input_lang.n_words)</span><br><span class="line">    print(output_lang.name, output_lang.n_words)</span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_lang, output_lang, pairs = prepareData(<span class="string">'eng'</span>, <span class="string">'fra'</span>, <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print("pairs:\n", pairs)  pairs = [法语,英语]</span></span><br><span class="line">print(random.choice(pairs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoder 部分</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderRNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size)</span>:</span></span><br><span class="line">        super(EncoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size   <span class="comment"># 隐藏状态a的大小</span></span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size)  <span class="comment"># 词嵌入层</span></span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)   <span class="comment"># 多层的GRU</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, hidden)</span>:</span></span><br><span class="line">        embedded = self.embedding(input).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        output = embedded</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>,<span class="number">1</span>, self.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoder部分</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderRNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size, output_size)</span>:</span></span><br><span class="line">        super(DecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(output_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size)</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, hidden)</span>:</span></span><br><span class="line">        output = self.embedding(input).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        output = self.softmax(self.out(output[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>,<span class="number">1</span>,self.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Attention 部分</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnDecoderRNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size, output_size, dropout_p=<span class="number">0.1</span>, max_length=MAX_LENGTH)</span>:</span></span><br><span class="line">        super(AttnDecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.dropout_p = dropout_p</span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(self.output_size, self.hidden_size)</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size*<span class="number">2</span>, self.max_length)</span><br><span class="line">        self.attn_combine = nn.Linear(self.hidden_size*<span class="number">2</span>, self.hidden_size)</span><br><span class="line">        self.dropout = nn.Dropout(self.dropout_p)</span><br><span class="line">        self.gru = nn.GRU(self.hidden_size, self.hidden_size)</span><br><span class="line">        self.out = nn.Linear(self.hidden_size, self.output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, hidden, encoder_outputs)</span>:</span></span><br><span class="line">        embedded = self.embedding(input).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line"></span><br><span class="line">        attn_weights = F.softmax(self.attn(torch.cat((embedded[<span class="number">0</span>], hidden[<span class="number">0</span>]), <span class="number">1</span>)), dim=<span class="number">1</span>)  <span class="comment"># 注意力权重</span></span><br><span class="line">        attn_applied = torch.bmm(attn_weights.unsqueeze(<span class="number">0</span>), encoder_outputs.unsqueeze(<span class="number">0</span>))  <span class="comment"># 两个batch之间的矩阵乘法</span></span><br><span class="line"></span><br><span class="line">        output = torch.cat((embedded[<span class="number">0</span>], attn_applied[<span class="number">0</span>]), <span class="number">1</span>)</span><br><span class="line">        output = self.attn_combine(output).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line"></span><br><span class="line">        output = F.log_softmax(self.out(output[<span class="number">0</span>]), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 隐状态初始化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备训练数据</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">indexesFromSentence</span><span class="params">(lang, sentence)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [lang.word2index[word] <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">" "</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorFromSentence</span><span class="params">(lang, sentence)</span>:</span></span><br><span class="line">    indexes = indexesFromSentence(lang, sentence)</span><br><span class="line">    indexes.append(EOS_token)   <span class="comment"># EOS作为encoder编码器网络的结束标志，  SOS作为Decoder解码器网络的开始标志</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorsFromPair</span><span class="params">(pair)</span>:</span></span><br><span class="line">    input_tensor = tensorFromSentence(input_lang, pair[<span class="number">0</span>])   <span class="comment"># pair[0]是法语</span></span><br><span class="line">    targe_tensor = tensorFromSentence(output_lang, pair[<span class="number">1</span>])  <span class="comment"># pair[1]是英语</span></span><br><span class="line">    <span class="keyword">return</span> (input_tensor, targe_tensor)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># “tearcher_forcing_ratio将上一时刻的真实目标输出当作下一个时刻的Encoder网络的输入，而不是使用Encoder网络的上一时刻的预测输出作为下一时刻的输入。</span></span><br><span class="line">tearcher_forcing_ratio = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH)</span>:</span></span><br><span class="line">    encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.zero_grad()</span><br><span class="line">    decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    input_length = input_tensor.size(<span class="number">0</span>)</span><br><span class="line">    target_length = target_tensor.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># encoder部分</span></span><br><span class="line">    <span class="keyword">for</span> ei <span class="keyword">in</span> range(input_length):</span><br><span class="line">        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)</span><br><span class="line">        encoder_outputs[ei] = encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># decoder部分</span></span><br><span class="line">    decoder_input = torch.tensor([[SOS_token]], device=device)</span><br><span class="line"></span><br><span class="line">    decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">    use_teacher_foring = <span class="literal">True</span> <span class="keyword">if</span> random.random() &lt; tearcher_forcing_ratio <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># using teacher forcing</span></span><br><span class="line">    <span class="keyword">if</span> use_teacher_foring:</span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> range(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            decoder_input = target_tensor[di]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 不使用teacher forcing,使用上一时刻的输出作为下一时刻的输入</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> range(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            topv, topi = decoder_output.topk(<span class="number">1</span>)</span><br><span class="line">            decoder_input = topi.squeeze().detach()</span><br><span class="line"></span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> decoder_input.item() == EOS_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.step()</span><br><span class="line">    decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item() / target_length</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 辅助函数------记录时间</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">asMinutes</span><span class="params">(s)</span>:</span></span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"%dm %ds"</span> % (m, s)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeSince</span><span class="params">(since, percent)</span>:</span></span><br><span class="line">    now = time.time()</span><br><span class="line">    s = now - since</span><br><span class="line">    es = s / (percent)</span><br><span class="line">    rs = es - s</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"%s (- %s)"</span> % (asMinutes(s), asMinutes(rs))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 整个训练过程如下：</span></span><br><span class="line"> <span class="comment"># 开启定时器</span></span><br><span class="line"> <span class="comment"># 初始化优化器和loss函数</span></span><br><span class="line"> <span class="comment"># 创建training pairs</span></span><br><span class="line"> <span class="comment"># 开始训练并绘图</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainIters</span><span class="params">(encoder, decoder, n_iters, print_every=<span class="number">1000</span>, plot_every=<span class="number">100</span>, learning_rate=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">    start = time.time()  <span class="comment"># 开启定时器</span></span><br><span class="line">    plot_losses = []</span><br><span class="line">    print_loss_total = <span class="number">0</span>  <span class="comment"># Reset every print_every</span></span><br><span class="line">    plot_loss_total = <span class="number">0</span>  <span class="comment"># Reset every plot_every</span></span><br><span class="line"></span><br><span class="line">    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)  <span class="comment"># 定义优化算法</span></span><br><span class="line">    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)</span><br><span class="line">    training_pairs = [tensorsFromPair(random.choice(pairs))  <span class="comment"># 创建training pairs</span></span><br><span class="line">                      <span class="keyword">for</span> i <span class="keyword">in</span> range(n_iters)]</span><br><span class="line">    criterion = nn.NLLLoss()  <span class="comment"># 定义损失函数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> iter <span class="keyword">in</span> range(<span class="number">1</span>, n_iters + <span class="number">1</span>):</span><br><span class="line">        training_pair = training_pairs[iter - <span class="number">1</span>]</span><br><span class="line">        input_tensor = training_pair[<span class="number">0</span>]</span><br><span class="line">        target_tensor = training_pair[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        loss = train(input_tensor, target_tensor, encoder,</span><br><span class="line">                     decoder, encoder_optimizer, decoder_optimizer, criterion)</span><br><span class="line">        print_loss_total += loss</span><br><span class="line">        plot_loss_total += loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iter % print_every == <span class="number">0</span>:</span><br><span class="line">            print_loss_avg = print_loss_total / print_every</span><br><span class="line">            print_loss_total = <span class="number">0</span></span><br><span class="line">            print(<span class="string">'%s (%d %d%%) %.4f'</span> % (timeSince(start, iter / n_iters),</span><br><span class="line">                                         iter, iter / n_iters * <span class="number">100</span>, print_loss_avg))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> iter % plot_every == <span class="number">0</span>:</span><br><span class="line">            plot_loss_avg = plot_loss_total / plot_every</span><br><span class="line">            plot_losses.append(plot_loss_avg)</span><br><span class="line">            plot_loss_total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    showPlot(plot_losses)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制loss曲线</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.switch_backend(<span class="string">'agg'</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showPlot</span><span class="params">(points)</span>:</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># this locator puts ticks at regular intervals</span></span><br><span class="line">    loc = ticker.MultipleLocator(base=<span class="number">0.2</span>)</span><br><span class="line">    ax.yaxis.set_major_locator(loc)</span><br><span class="line">    plt.plot(points)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试阶段--------测试阶段整体与训练阶段类似，但是测试阶段，不用给出target_tensor,只是将decoder网络上一时刻的预测值作为下一时刻的输入值</span></span><br><span class="line"><span class="comment"># 当预测值是EOS时，则停止预测</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(encoder, decoder, sentence, max_length = MAX_LENGTH)</span>:</span></span><br><span class="line">     <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_tensor = tensorFromSentence(input_lang, sentence)</span><br><span class="line">        input_length = input_tensor.size()[<span class="number">0</span>]</span><br><span class="line">        encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># encoder部分</span></span><br><span class="line">        <span class="keyword">for</span> ei <span class="keyword">in</span> range(input_length):</span><br><span class="line">            encoder_output, encoder_hidden = encoder(input_tensor[ei],</span><br><span class="line">                                                     encoder_hidden)</span><br><span class="line">            encoder_outputs[ei] += encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        decoder_input = torch.tensor([[SOS_token]], device=device)  <span class="comment"># SOS</span></span><br><span class="line"></span><br><span class="line">        decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">        decoded_words = []</span><br><span class="line">        decoder_attentions = torch.zeros(max_length, max_length)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decoder部分</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> range(max_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            decoder_attentions[di] = decoder_attention.data</span><br><span class="line">            topv, topi = decoder_output.data.topk(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> topi.item() == EOS_token:  <span class="comment"># 结束时的条件</span></span><br><span class="line">                decoded_words.append(<span class="string">'&lt;EOS&gt;'</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                decoded_words.append(output_lang.index2word[topi.item()])</span><br><span class="line"></span><br><span class="line">            decoder_input = topi.squeeze().detach()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> decoded_words, decoder_attentions[:di + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机地从训练集中选择pairs,然后在测试集上进行评估</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateRandomly</span><span class="params">(encoder, decoder, n=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        pair = random.choice(pairs)</span><br><span class="line">        print(<span class="string">'输入:&gt;'</span>, pair[<span class="number">0</span>])</span><br><span class="line">        print(<span class="string">'目标:='</span>, pair[<span class="number">1</span>])</span><br><span class="line">        output_words, attentions = evaluate(encoder, decoder, pair[<span class="number">0</span>])</span><br><span class="line">        output_sentence = <span class="string">' '</span>.join(output_words)</span><br><span class="line">        print(<span class="string">'预测:&lt;'</span>, output_sentence)</span><br><span class="line">        print(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正式训练开始运行</span></span><br><span class="line"></span><br><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line">encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)</span><br><span class="line">attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">trainIters(encoder1, attn_decoder1, <span class="number">75000</span>, print_every=<span class="number">5000</span>)</span><br><span class="line"></span><br><span class="line">evaluateRandomly(encoder1, attn_decoder1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意力可视化</span></span><br><span class="line"></span><br><span class="line">output_words, attentions = evaluate(</span><br><span class="line">    encoder1, attn_decoder1, <span class="string">"je suis trop froid ."</span>)</span><br><span class="line">plt.matshow(attentions.numpy());</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加坐标轴，更加清楚的可视化</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showAttention</span><span class="params">(input_sentence, output_words, attentions)</span>:</span></span><br><span class="line">    <span class="comment"># Set up figure with colorbar</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    cax = ax.matshow(attentions.numpy(), cmap=<span class="string">'bone'</span>)</span><br><span class="line">    fig.colorbar(cax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set up axes</span></span><br><span class="line">    ax.set_xticklabels([<span class="string">''</span>] + input_sentence.split(<span class="string">' '</span>) +</span><br><span class="line">                       [<span class="string">'&lt;EOS&gt;'</span>], rotation=<span class="number">90</span>)</span><br><span class="line">    ax.set_yticklabels([<span class="string">''</span>] + output_words)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Show label at every tick</span></span><br><span class="line">    ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateAndShowAttention</span><span class="params">(input_sentence)</span>:</span></span><br><span class="line">    output_words, attentions = evaluate(</span><br><span class="line">        encoder1, attn_decoder1, input_sentence)</span><br><span class="line">    print(<span class="string">'input ='</span>, input_sentence)</span><br><span class="line">    print(<span class="string">'output ='</span>, <span class="string">' '</span>.join(output_words))</span><br><span class="line">    showAttention(input_sentence, output_words, attentions)</span><br></pre></td></tr></table></figure></p>
<h4 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4.参考资料"></a>4.参考资料</h4><ul>
<li><a href="https://nndl.github.io/" target="_blank" rel="noopener">邱锡鹏：《神经网络与深度学习》</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener">Translation with a Sequence to Sequence Network and Attention</a></li>
<li><a href="https://pytorch-cn.readthedocs.io/zh/latest/" target="_blank" rel="noopener">PyTorch中文文档</a></li>
<li><a href="https://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
<li><a href="https://arxiv.org/abs/1506.05869" target="_blank" rel="noopener">A Neural Conversational Model</a></li>
<li><a href="https://github.com/cdlwhm1217096231/Machine_Learning/tree/master/%E4%B8%AD%E6%96%87NLP%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/05_Attention_Mechanism" target="_blank" rel="noopener">本文中的代码及数据下载地址</a></li>
</ul>

      
    </div>
    
    
    



    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">

  <p><span>本文标题:</span>神经网络中的注意力机制总结及PyTorch实战</p>
  <p><span>文章作者:</span>Curry_Coder</p>
  <p><span>发布时间:</span>2019年07月29日 - 19:29:05</p>
  <p><span>最后更新:</span>2019年07月29日 - 20:56:37</p>
  <p><span>原始链接:</span><a href="/深度学习/神经网络中的注意力机制总结及PyTorch实战/" title="神经网络中的注意力机制总结及PyTorch实战">https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>
</div>
<script>
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({
          title: "",
          text: '复制成功',
          html: false,
          timer: 500,
          showConfirmButton: false
        });
      });
    }));
</script>


      
    </div>

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:16px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>


      
    </div>

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>觉得对您有所帮助，请我喝杯可乐吧!</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="Curry_Coder 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="Curry_Coder 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Curry_Coder
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/" title="神经网络中的注意力机制总结及PyTorch实战">https://cdlwhm1217096231.github.io/深度学习/神经网络中的注意力机制总结及PyTorch实战/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    





    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
          
            <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          
            <a href="/tags/PyTorch/" rel="tag"><i class="fa fa-tag"></i> PyTorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/开发工具/轻松优化Jupyter-Notebook-技巧、诀窍、魔法/" rel="next" title="轻松优化Jupyter Notebook:技巧、诀窍、魔法">
                <i class="fa fa-chevron-left"></i> 轻松优化Jupyter Notebook:技巧、诀窍、魔法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/数据结构与算法/Leetcode刷题记录/" rel="prev" title="Leetcode刷题记录">
                Leetcode刷题记录 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/curry.jpg" alt="Curry_Coder">
            
              <p class="site-author-name" itemprop="name">Curry_Coder</p>
              <p class="site-description motion-element" itemprop="description">怕什么真理无穷，进一寸有一寸的欢喜。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/cdlwhm1217096231" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/cdlwhm1217096231" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-android"></i>CSDN</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/2677530011/profile?topnav=1&wvr=6&is_all=1" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:1217096231cdl@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.baidu.com/" title="百度" target="_blank">百度</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.liujiangblog.com/course/python/4" title="Python" target="_blank">Python</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.52nlp.cn/" title="我爱自然语言处理" target="_blank">我爱自然语言处理</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://leetcode-cn.com/problemset/all/" title="LeetCode" target="_blank">LeetCode</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.nowcoder.com/224349141" title="牛客网" target="_blank">牛客网</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.huaxiaozhuan.com/" title="AI算法工程师手册" target="_blank">AI算法工程师手册</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://c.biancheng.net/stl/" title="STL手册" target="_blank">STL手册</a>
                  </li>
                
              </ul>
            </div>
          

          <div id="music163player">
    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=28285910&auto=1&height=66"></iframe>
</div>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#0-概述"><span class="nav-number">1.</span> <span class="nav-text">0.概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-Attention机制基础知识"><span class="nav-number">2.</span> <span class="nav-text">1.Attention机制基础知识</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-其他类型的注意力机制"><span class="nav-number">3.</span> <span class="nav-text">2.其他类型的注意力机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明"><span class="nav-number">4.</span> <span class="nav-text">3.实战———以Seq2Seq网络进行法语到英语的翻译为例进行说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-参考资料"><span class="nav-number">5.</span> <span class="nav-text">4.参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Curry_Coder</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">37.8k</span>
  
</div>









|  本页点击 <span id="busuanzi_value_page_pv"></span> 次
  |  本站总点击 <span id="busuanzi_value_site_pv"></span> 次
  |  您是第 <span id="busuanzi_value_site_uv"></span> 位访客
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>


        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'joaeuuc4hsqudUUwx4gIvGF6-gzGzoHsz',
        appKey: 'E9UJsJpw1omCHuS22PdSpKoh',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <!-- 小红心 -->
  <script type="text/javascript" src="/js/src/love.js"></script>
  <script type="text/javascript" src="/js/src/particle.js" count="50" zindex="-2" opacity="1" color="0,104,183"></script>
  <!--卖萌-->
  <script type="text/javascript" src="/js/src/dytitle.js"></script>
</body>
</html>

